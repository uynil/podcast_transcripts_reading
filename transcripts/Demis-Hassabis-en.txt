Speaker 1  00:00:00
The following is a conversation with demas Mesaba's Ceo and co founder of Deepmind, a company that has published and built some of the most incredible artificial intelligence systems in the history of computing, including Alfred Zero that learned all by itself to play the game of go better than any human in the world. And ALfa fold too. That solved protein folding. Both tasks considered nearly impossible for a very long time demos is widely considered to be one of the most brilliant and impactful humans in the history of artificial intelligence and science and engineering in general. This was truly an honor and a pleasure for me to finally sit down with him for this conversation and I'm sure we will talk many times again in the future. And now a quick view. 2nd mention of the sponsor. Check them out in the description. That's the best way to support this podcast. We got mail gun for email campaigns inside tracker for longevity on it for supplements. Indeed for hiring and magic spoon for breakfast. She was wise to my friends and now I want to.

The full out reads as always no ads in the middle. I try to make this interesting but if you skip them, please still check out our sponsors. I enjoy their stuff. Maybe you will too. This show is brought to you by mail gun by cinch an email delivery service that I've used for many, many years to have an A. P. I that allows you to programmatically send emails If you don't know what an API is.

Speaker 2  00:01:32
The point is.

Speaker 1  00:01:33
It's a way for programs for code to interact with the service. You have an api for both transactional and marketing emails. Those are terms used by people much smarter about this stuff than me. But I think transactional means specific to the person emails which is what I've I guess used. It's a way to email certain people to notify them about the status of whatever the heck they're doing on the website. And then there's marketing emails which is when you send an email to a lot of people like the same email I guess transactional is super customized to an action that a person took. And marketing is like a push email that you sent a lot of people. And both of those two categories of how people often use email. And so Megan is a service that makes it super easy for you to do that kind of thing. You can go to lex Friedman dot com slash mail gun to learn more. This show is also brought to you by inside tracker. A service that used to track biological data data that comes from my body.

A lot of their plans. They can send out for include blood tests, why blood tests because a lot of really useful data comes from your blood. And then they use

Speaker 2  00:02:48
machine

Speaker 1  00:02:48
learning algorithms to analyze that data. So that includes blood data, DNA data and even data from your fitness tracker to provide you a clear picture of what's going on inside your body, this is

Speaker 2  00:03:00
the future.

Speaker 1  00:03:01
Anything you decide to do in your life should be based on data from your entity from your being. That means your biological body. Maybe one day. That means from your brain as well. There will be brain computer interface device like neuralink that collects data from your brain and is able to

Speaker 2  00:03:20
make

Speaker 1  00:03:21
suggestions

Speaker 2  00:03:23
what

Speaker 1  00:03:23
kind of supplements to take, what kind of diet changes to make. You can go to inside tracker dot com slash lex and for a limited time you get special savings for being a listener of this very podcast. This episode is also brought to you by on it, a nutrition supplement and fitness company. They have a thing called Alpha Brain which is a new tropic that helps you with the memory, mental speed and focus. You might know it because of Mr joe Rogan, which is probably the first time

Speaker 2  00:03:52
I

Speaker 1  00:03:53
heard an honored read. It's one of the first podcasts actually joe's that I listened to religiously.

Speaker 2  00:04:03
I'm a

Speaker 1  00:04:03
huge fan of audio books and podcasts in general. But there's something about

Speaker 2  00:04:07
the

Speaker 1  00:04:07
authenticity that joe projects that immediately connected with me and

Speaker 2  00:04:12
over

Speaker 1  00:04:13
time his ability to be curious and empathetic, a good listener but also be able to change his mind. Keep an open mind to some crazy ideas.

Speaker 2  00:04:23
Anyway, I

Speaker 1  00:04:23
mentioned that because the joe Rogan experience introduced me to a lot of these kinds of products like on it that quickly became part of my life. I guess podcast ad reads

Speaker 2  00:04:33
work

Speaker 1  00:04:34
anyway, you can get a special discount on Alpha Brain if you go to lex Friedman dot com slash on

Speaker 2  00:04:40
it.

Speaker 1  00:04:42
This show is also brought to you by indeed a hiring website. I've used them as part of many hiring efforts I've done for the teams I've led in the past. They have indeed is the match that gives you quality candidates whose resumes that indeed figure job description immediately. I've said this before, I'll say it again. There's very few things in life as important as the people you surround yourself with. I'm somebody for whom the work I've done brings a lot of meaning and joy to my life. Even when I sold shoes at Sears shoes in the women's section,

Speaker 2  00:05:15
that little

Speaker 1  00:05:15
community that you have as you try to figure out this new skill, those people are

Speaker 2  00:05:22
so

Speaker 1  00:05:23
instrumental to your happiness and to your effectiveness to your growth as a human being. So hiring is really, really, really important and um that's why you should use the best tools for the job. Indeed

Speaker 2  00:05:34
is one such

Speaker 1  00:05:35
tool. They have a special offer for listeners of this podcast only available for a limited time. Check it out at indeed dot com slash lex This episode is also brought to you by an oldie, but a goodie magic spoon, a low carb keto friendly cereal. They were there from the beginning, I really love magic

Speaker 2  00:05:56
spoon.

Speaker 1  00:05:57
It brings so much joy to my heart. I don't care

Speaker 2  00:06:01
if this is not your thing. Please get it

Speaker 1  00:06:04
and make it your thing because it's freaking delicious.

Speaker 2  00:06:07
It

Speaker 1  00:06:07
has all the deliciousness of a cereal without any of the negative stuff. Like all the sugar.

Speaker 2  00:06:12
It has zero

Speaker 1  00:06:13
grams of sugar, 13 to 14 g of protein, only 49 g of carbs, 100 and 40 calories in each

Speaker 2  00:06:20
serving.

Speaker 1  00:06:21
It's like I said, keto friendly. It's magic. I don't understand how it works. I don't understand how it can be so delicious, but they have a lot of flavors. Uh I would say peanut butter is up there for me. Maybe top three, Maybe it's my second favorite. But by far my favorite is Coco magic spoon has a 100% happiness guarantee. So if you don't like it, they'll refund it. Get a discount on your order. If you go to magic spoon dot com slash lex and use code lex. This is lux Friedman podcast. To support it, please check out our sponsors in the description and now dear friends, Here's demas Mesaba's mhm.

Let's start with a bit of a personal question. Am I an Ai program you wrote to interview people until I get good enough to interview you.

Speaker 2  00:07:27
Well, I'd be impressed if if you were, I'd be impressed by myself. If you were. I don't think we're quite up to that yet. But maybe you're from the future. Lex.

Speaker 1  00:07:34
if you did, Would you tell me, Is that is that a good thing to tell? A language model that's tasked with interviewing that? It is in fact, a I

Speaker 2  00:07:43
maybe we're in a kind of meta turing test, probably, probably it would be a good idea not to tell you. So it doesn't change your behavior, right?

Speaker 1  00:07:49
This is a kind of

Speaker 2  00:07:50
Heisenberg uncertainty principle situation. If I told you you behave differently, maybe that's what's happening with us. Of course this

Speaker 1  00:07:57
is a benchmark from the future where they replay 2022 as a year before a eyes were good enough yet. And now we want to see is it gonna pass if I was such a program, would you be able to tell do you think so too? The touring test question you've you've talked about mm the benchmark for solving intelligence, what would be the impressive thing you talked about winning a Nobel prize and a system. Winning a Nobel prize, but I still return to the touring test as a compelling test. The spirit of the turing test is a compelling test.

Speaker 2  00:08:33
Yeah, the turing test, of course it's been unbelievably influential and turing is one of my all time heroes. But I think if you look back at the 1950 papers, original paper and read the original, you'll see, I don't think he meant it to be a rigorous formal test? I think it was more like a thought experiment, almost a bit of philosophy he was writing if you look at the style of the paper and you can see he didn't specify it very rigorously. So for example, he didn't specify the knowledge that the expert or judge would have. Um not, you know, how much time would they have to investigate this. So these important parameters if you were gonna make it a true sort of formal test um and you know, some by some measures, people claim the turing test passed several, you know, a decade ago, remember someone claiming that with with a kind of very bog standard normal logic model because they pretended it was it was a kid. So the judges thought that the machine, you know, was was was a child, so that would be very different from an expert ai person interrogating machine and knowing how it was built and so on. So I think um you know, we should probably move away from that as as a formal test and move more towards uh general test where we test the ai capabilities on a range of tasks and see if it reaches human level or above performance on maybe thousands, perhaps even millions of tasks eventually And cover the entire sort of cognitive space. So I think for its time it was an amazing thought experiment and also 1950s, obviously there's barely the dawn of the computer age. So of course he only thought about text and now we have a lot more different inputs.

Speaker 1  00:10:10
So yeah, maybe the better thing to test is the generalize ability so, across multiple tasks, but I think it's also possible as as systems like God or show that eventually that might map right back to language. So you might be able to demonstrate your ability to generalize across tasks by then communicating your ability to generalize across tasks, which is kind of what we do through conversation anyway, when we jump around ultimately what's in there in that conversation is not just you moving around knowledge, it's you moving around like these entirely different modalities of understanding that ultimately map to your ability to to uh operate successfully in all of these domains which you can think of as tasks.

Speaker 2  00:10:58
Yeah, I think certainly we as humans use language as our main generalization communication tools, so I think we end up thinking in language and expressing our solutions in language um so it's gonna be very powerful uh mode in which to explain, you know, the system to explain what it's doing, but I don't think it's the only uh modality that matters. So I think there's going to be a lot of, you know, there's there's a lot of different ways to express capabilities other than just language.

Speaker 1  00:11:31
Yeah, visual robotics, body language, um yeah, actions, the interactive aspect of all that, that's all part of it.

Speaker 2  00:11:40
But what's interesting with Gateau is that it's it's it's it's sort of pushing prediction to the maximum in terms of like you know mapping arbitrary sequences to other sequences and sort of just predicting what's gonna happen next prediction seems to be fundamental to intelligence

Speaker 1  00:11:56
and what you're predicting doesn't so much matter.

Speaker 2  00:12:00
Yeah it seems like you can generalize that quite well. So obviously language models predict the next word. Um Gato predicts potentially any action or any token. Uh And it's just the beginning really. It's our most general agent one could call it so far but you know that itself can be scaled up massively more than we've done so far. And obviously we're in the middle of doing that.

Speaker 1  00:12:20
But a big part of solving A. G. I. Is creating benchmarks that help us get closer and closer creating benchmarks that test the journal eyes ability. And it's just still interesting that this fella alan turing was one of the first and probably still one of the only people that was trying maybe philosophically but was trying to formulate a benchmark that could be followed. It is even though it's fuzzy, it's still sufficiently rigorous to where you can run that test and I still think something like the touring test will and at the end of the day be the thing that truly impresses other humans so that you can have a close friend who is an ai system for that friend to be a good friend, they're going to have to be able to uh play Starcraft and they're gonna have to do all of these tasks um get you a beer so that the robotics tasks, play games with you use language humor, all those kinds of things, but that ultimately can boil down to language. It feels like not in terms of the Ai community but in terms of the actual impact of general intelligence on the world, it feels like language will be the place where it truly shines.

Speaker 2  00:13:34
I think so because it's such an important kind of input output for us. I think you're right. I think the turing test that what the kind of the philosophy behind it, which is the idea of can can a machine mimic the behaviors of a human and then and I would say wider than just language and text. Um then, you know, in terms of actions and everything else, creativity, all these things then um if it can sort of match or exceed human cognitive capabilities then I think we have a, you know, a true intelligence. So from that perspective you're right. I think he did formulate the right kind of setup.

Speaker 1  00:14:11
I just I think there will be a kind of humor in the Ai systems, the future. Looking back to this conversation and thinking about the touring test and also thinking about by that time they would know which year they were finally able to sort of cross the threshold of human level intelligence and think how funny it is that we humans were still confused about this whole problem long ago been solved. Hello to the Ai agents of the future. Anyway, so going back to your To your journey, when did you fall in love with programming 1st?

Speaker 2  00:14:49
Well, it's pretty a pretty young age actually. So um you know, I started off actually games was my first love. So starting to play chess when I was around four years old. And then um is actually with winnings from a chess competition that I managed to buy. My first chess computer when I was about eight years old, was a ZX spectrum, which was hugely popular in the UK at the time. And it was amazing machine because I think it trained a whole generation of programmers in the UK because it was so accessible. You know, you literally switched it on and there was the basic prompt and you could just get going and my parents didn't really know anything about computers. So, but because it was my money from a chess competition, I could I could say I wanted to buy it. Uh and then, you know, I just went to bookstores, got books on programming and started typing in, you know, the programming code. And then of course, um once you start doing that, you start adjusting it and then making your own games. And that's when I fell in love with computers and realized that they were very magical device. Um in a way I kind of would have been able to explain this at the time.

But I felt that there was sort of almost a magical extension of your mind? I always had this feeling and I've always loved this about computers that you can set them off doing something some task for you, You can go to sleep, come back the next day and it's solved um you know, that feels magical to me. So I mean all machines do that to some extent, they all enhance our natural capabilities. Obviously cars make us allow us to move faster than we can run. But this was a machine to extend the mind and uh and then of course AI is the ultimate expression of what a machine may be able to do or learn. So very naturally for me that thought extended into into Ai quite quickly

Speaker 1  00:16:32
remember the programming language that was first started special to the machine. It was just

Speaker 2  00:16:38
it was just I think it was just basic on the ZX spectrum, I don't know what specific form it was. And then later on I got a commodore Amiga, which was a fantastic machine,

Speaker 1  00:16:48
you're just showing off.

Speaker 2  00:16:49
So yeah, well lots of my friends had Atari sts and I managed to get it because it was a bit more powerful and that was incredible and used to do programming in assembler and and also Amos basic this this this specific form of basic, it was incredible actually. So I love all my coding skills.

Speaker 1  00:17:06
And when did you fall in love with ai, So when did you first start to gain an understanding that you can not just write programs that do some mathematical operations for you while you sleep, but something that's keen to bringing an entity to life sort of a thing that can figure out something more complicated than a than a simple mathematical operation. Yeah,

Speaker 2  00:17:32
so there was a few stages for me or when I was very young, so first of all, as I was trying to improve at playing chess, I was captaining various England junior chess teams and at the time when I was about, you know, maybe 10, 11 years old, I was going to become a professional chess player, That was my first a thought

Speaker 1  00:17:47
that dream was there

Speaker 2  00:17:49
to try

Speaker 1  00:17:50
to get to the highest level.

Speaker 2  00:17:51
So I was you know, I got to, when I was about 12 years old I got to master standard, I was second highest rate of play in the world to Judith Polgar, who obviously ended up being an amazing chess player and uh world women's Champion. And when I was trying to improve a chess, where you know what you do is you obviously, first of all you're trying to improve your own thinking processes. So that leads you to thinking about thinking how is your brain coming up with these ideas? Why is it making mistakes? How can you how can you improve that thought process? But the second thing is that you it was just the beginning, this was like in the in the early eighties, mid eighties of chess computers, if you remember, they were physical boards, like the one we have in front of us and you press down the, you know, the squares and I think Kasparov had a branded version of it that I I got and you were, you know, used to they're not as strong as they are today, but they were they were pretty strong and used to practice against them um to try and improve your openings and other things. And so I remember, I think I probably got my first one was around 11 or 12. And I remember thinking um this is amazing, you know, how someone programmed uh this this chess board to play chess. Uh and it was very formative book I bought, which was called the chess computer handbook by David Levy came out in 1984 or something. So I must have got it when I was about 11, 12. And it explained fully how these chess programs were made. I remember my first day I program being programmed my Amiga, it couldn't it wasn't powerful enough to play chess.

I couldn't write a whole chess program, but I wrote a program for it to play Othello reverse. It is sometimes called I think in the US. And so a slightly simpler game than chess. But I used all of the principles that chess programs had alphabet to search all of that. And that was my first AI program. Remember that very well was around 12 years old. So that that that brought me into A I. And then the second part was later on was around 16, 17. And I was writing games professionally designing games, writing a game called theme park, which had a I as a core gameplay component as part of the simulation um and sold, you know, millions of copies around the world. And people loved the way that the Ai, even though it's relatively simple by today's AI standards um was was reacting to the way you as the player played it. So it was called a sandbox game. So it's one of the first types of games like that along with Sim City and it meant that every game you played was unique.

Speaker 1  00:20:11
Is there something you could say just on a small tangent about really impressive ai from a game design, human enjoyment perspective, really impressive ai that you've seen in games and maybe what does it take to create a I. System? And how hard of a problem is that? So a million questions, just as a brief tangent.

Speaker 2  00:20:34
Well look, I think games games have been significant in my life for three reasons. So first of all to I was playing them and training myself on games when I was a kid. Then I went through a phase of designing games and writing aI four games. So all the games I I professionally wrote had a I as a core component And that was mostly in the in the 90s. And the reason I was doing that in games industry was at the time, the games industry I think was the cutting edge of technology. So whether it was graphics with people like john Carmack and quake and those kind of things or or a I I think actually all the action was going on in games and and we've seen we're still reaping the benefits of that even with things like G P. U. S which I find ironic was obviously invented for graphics, computer graphics but then turns out to be amazingly useful for AI just turns out everything is a matrix multiplication appears appears in the way in the whole world. So, so I think games at the time had the most cutting edge AI. And a lot of the games we you know, I was involved in writing. So there was a game called black and white which was one game I was involved with in the early stages of which I still think is the most um impressive example of reinforcement learning in a computer game. So in that game, you know you trained a little pet animal and

Speaker 1  00:21:50
yeah

Speaker 2  00:21:51
and it sort of learned from how you were treating it. So if you treated it badly, then it became mean and then it would be mean to to your villages and your and your population, the sort of the little tribe that you were running. But if you were kind to it then it would be kind and people fascinated by how that works. And and so was I to be honest with the way it kind of developed and especially

Speaker 1  00:22:11
the mapping to good and evil. You made you made you realize made me realize that you can sort of in the way in the choices you make can define the where you end up and that means all of us are capable of the good evil. It all matters in the different choices along the trajectory to those places that you make. It's fascinating. I mean games can do that philosophical to you and it's rare. It seems rare.

Speaker 2  00:22:38
Yeah. Well games, I think a unique medium because you as the player, you're not just passively consuming the the entertainment, right? You're you're actually actively involved as an as an agent. So I think that's what makes it in some ways can be more visceral than other other mediums like, you know, films and books. So the second, so that was, you know, designing ai in games. And then the third use uh we've used of AI is in deep mind from the beginning which is using games as a testing ground for proving out ai algorithms and developing ai algorithms and that was that was a sort of a core component of our vision at the start of Deepmind was that we would use games very heavily as our main testing ground certainly to begin with because it's super efficient to use games. And also, you know, it's very easy to have metrics to see how well your systems are improving and what direction your ideas are going in and whether you're making incremental improvements.

Speaker 1  00:23:34
And because those games are often rooted in something that humans did for a long time beforehand, there's already a strong set of rules, like it's already a damn good benchmark.

Speaker 2  00:23:44
Yes, it's really good for so many reasons because you've got you've got you've got clear measures of how good humans can be at these things and in some cases like go, we've been playing it for thousands of years. Um and and often they have scores or at least wind conditions, so it's very easy for reward learning systems to get a reward. It's very easy to specify what that reward is. Um and also at the end it's easy to, you know, to test externally, you know, how strong is your system by of course playing against, you know, the world's strongest players at those games. So it's it's so good for so many reasons and it's also very efficient to run potentially millions of simulations in parallel on the cloud. So um I think there's a huge reason why we were so successful back in, you know, starting out 2010, how come we were able to progress so quickly, because we've utilized games and, you know, at the beginning of Deepmind, we also hired some amazing game engineers who I knew from my previous lives in the games industry. And uh and that helped to bootstrap us very quickly.

Speaker 1  00:24:46
And plus it's somehow super compelling almost at a philosophical level of man versus machine, over over over chess board or a go board. And especially given that the entire history of AI is defined by people saying it's going to be impossible to make a machine that beats a human being in chess. And then once that happened, people were certain when I was coming up in a I they go is not a game that can be solved because of the combinatorial complexity. It's just too, it's it's it's, you know, no matter how much moore's law, you have compute, it's just never going to be able to crack the game of go. And so that then there's something compelling about facing sort of taking on the impossibility of that task from the ai researcher perspective, engineer perspective. And then as a human being, just observing this whole thing, um your beliefs about what you thought was impossible being broken apart. It's humbling to realize we're not as smart as we thought. It's humbling to realize that the things we think are impossible now, perhaps will be done in the future, there's something really powerful about a game ai system being a human being in a game that drives that message home for like millions, billions of people, especially in the case of go,

Speaker 2  00:26:16
well, look, I think it's I mean it has been a fascinating journey and and especially as I I think about it from, I can understand it from both sides, both as the ai, you know, creators of the Ai, but also as a games player originally. So, you know, it was a it was a really interesting, no, I mean, it was a fantastic but also somewhat bittersweet moment, the Alphago match for me, um seeing that and being obviously heavily, heavily involved in that. Um but you know, as you say, chess has been the, I mean, Kasparov, I think rightly called it the Drosophila of, of intelligence. Right? So it's sort of, I love that phrase and I think he's right because chess has been hand in hand with ai from the beginning of the whole field. Right? So I think every Ai practitioners starting with touring in Claude Shannon and all those, the sort of forefathers of the field um tried their hand at writing a chess program. I've got original audition of Claude Shannon's first chess program, it was 1949 the original sort of paper and they all did that ensuring famously wrote a chess program that, but all the computers around then were obviously too slow to run it. So he had to run, he had to be the computer, right? So he literally, I think spent two or three days running his own program by hand with pencil and paper and playing, playing a friend of his with his chess program. So

Speaker 1  00:27:41
of course

Speaker 2  00:27:42
Deep Blue was a huge moment beating Kasparov. Um but actually when that happened, I remember that very, very vividly of course, because it was, you know, chess and computers and ai all the things I loved and I was at college at the time, but I remember coming away from that, being more impressed by Kasparov's mind than I was by deep Blue, because here was Kasparov with his human mind, not only could he play chess more or less to the same level as this brute of a calculation machine, but of course Kasparov can do everything else. Humans can do ride a bike, talk, many languages, do politics, all the rest of the amazing things that Kasparov does, and so with the same brain and yet deep blue uh brilliant as it was at chess, had been hand coded for chess and um actually had distilled the knowledge of chess grandmasters into, into a cool program, but it couldn't do anything else. Like it couldn't even play a strictly simpler game like tic tac toe. So um something to me was missing from um intelligence from that system that that we would regard as intelligence. And I think it was this idea of generality and and also learning. Um so

Speaker 1  00:28:49
I try

Speaker 2  00:28:50
to do out with Alphago

Speaker 1  00:28:52
Yeah, with Alphago and Alpha zero, mu zero and then got on all the things that we'll get into some parts of there's just a fascinating trajectory here. But let's just stick on chest briefly on the human side of chest. You've proposed that from a game design perspective. The thing that makes chess compelling as a game is that there's a creative tension between a bishop and the night. Can you explain this first all? It's really interesting to think about what makes game compelling. Makes it stick across centuries.

Speaker 2  00:29:27
Yeah, I was sort of thinking about this and actually a lot of even amazing chess players don't think about it necessarily from a games designer point of view. So with my game design hat on that, I was thinking about this, why is chest so compelling? And I think a critical reason is the dynamic nous of of of the different kind of chess positions you can have whether they're closed or open and other things comes from the bishop and the knight. So if you think about how different the capabilities of the bishop and knight are in terms of the way they move and then somehow chess has evolved to balance those two capabilities more or less equally. So they're both roughly worth three points each. So

Speaker 1  00:30:04
you think that dynamics was always there and then the rest of the rules are kind of trying to stabilize the game?

Speaker 2  00:30:09
Well maybe, I mean it's sort of, I don't know, it's chicken and egg situation, probably both came together, but the fact that it's got to this beautiful equilibrium where you can have the bishop and knight, they're so different in power. Um but so equal in value across the set of the universe of all positions. Right? Somehow they've been balanced by humanity over hundreds of years. Um I think gives gives the game the creative tension that you can swap the bishop and knight for bishop for a night and you there more or less the worth the same, but now you aim for a different type of position, if you have the night, you want a closed position, if you have the bishop, you want an open position. So I think that creates a lot of the creative tension in chess.

Speaker 1  00:30:46
So some kind of controlled creative tension from an ai perspective, do you think ai systems, convention design games that are optimally compelling to humans?

Speaker 2  00:30:57
Well, that's an interesting question. You know, sometimes I get asked about ai and creativity and and and this and the way I answered that is relevant to that question, which is that I think there's different levels of creativity, one could say. So I think if we define creativity is coming up with something original, right, that's that's useful for a purpose, then, you know, I think the kind of lowest level of creativity is like an interpolation. So an averaging of all the examples you see. So maybe very basic ai system could say you could have that. So you show it millions of pictures of cats and then you say give me an average looking cat, right, generate me an average looking cat. I would call that interpolation. Then there's extrapolation which something like Alphago showed. So Alphago played, you know, millions of games of go against itself. Um and then it came up with brilliant new ideas like move 37 in game two brilliant motif strategies and go that that no humans have ever thought of even though we've played it for thousands of years and professionally for hundreds of years. So that that I call the extrapolation, but then that's still there's still a level above that which is, you know, you could call out of the box thinking or true innovation, which is, could you invent go right, could you invent chess and not just come up with a brilliant chess move or brilliant go move. But can you, can you actually invent chess or something as good as chess or go.

And I think one day a I could but what's missing is how would you even specify that task to a program right now and the way I would do it if if I was telling a human to do it or or games designer. Human games designer to do it is I would say something like go I would say um Come up with a game that only takes five minutes to learn which God has got simple rules, but many lifetimes to master, right? Or impossible to master in one lifetime because so deep and so complex. Um and then it's aesthetically beautiful and also it can be completed in three or four hours of gameplay time, which is, you know, useful for our us, you know, in a in a human day. And so you might specify these side of high level concepts like that and then, you know with that and maybe a few other things, one could imagine that go satisfies those those constraints. But the problem is is that we were not able to specify abstract notions like that high level abstract notions like that yet to our ai systems. Um and I think there's still something missing there in terms of high level concepts or abstractions that they truly understand and you know, combine nable and compositional. Um So for the moment I think Ai is capable of doing interpolation, extrapolation, but not true invention.

Speaker 1  00:33:29
So coming up with rule sets uh and optimizing with complicated objectives around those rule sets we can't currently do, but you could take a specific rule set and then run a kind of self play experiment to see how long, just observe how an Ai system from scratch learns, how long is that journey of learning and maybe if it satisfies some of those other things you mentioned in terms of quickness to learn so on, and you could see a long journey to master for even an Ai system, then you could say that this is a promising game. Um but it would be nice to do almost like alpha codes or programming rules, so generating rules that kind of uh that that automate even that part of the generation of rules.

Speaker 2  00:34:16
So I have thought about systems actually. Um I think the amazing in in for a games designer, if you could have a system that takes your game plays it tens of millions of times, maybe overnight and then self balances the rules better. So it tweaks the rules and the, maybe the equations and the and the and the parameters so that the game is more balanced, the units in the game, or some of the rules could be tweaked. So it's a bit of like giving a base set and then allowing monte Carlo tree search or something like that to sort of explore it. Right? And I think that would be super super powerful tool actually for for balancing auto balancing a game, which usually takes thousands of hours from hundreds of games, human games testers normally to to balance some one, you know, games like Starcraft, which is, you know, Blizzard are amazing at balancing their games, but it takes them years and years and years. So one could imagine at some point when this stuff becomes efficient enough to, you know, you might better do that like overnight,

Speaker 1  00:35:15
do you think a game that is optimal designed by N. A. I. System would look very much like Planet Earth,

Speaker 2  00:35:25
maybe, maybe it's only the sort of game I would love to make is, and I've tried, you know, my in my in my games career, the game's design career, you know, my first big game was designing a theme park, an amusement park. Then with games like Republic, I tried to, you know, have games where we designed whole cities and and allows you to play in. So, and of course people will write have written games like Sim Earth trying to simulate the whole of Earth. Pretty tricky. But

Speaker 1  00:35:52
I haven't actually played that one. So what is it, does it incorporate of evolutionary?

Speaker 2  00:35:56
Yeah, it has evolution. And it sort of tries to it sort of treats it as an entire biosphere, but from quite high level, so be

Speaker 1  00:36:04
nice to be able to sort of zoom in zoom in.

Speaker 2  00:36:07
Exactly. So obviously he couldn't do that was in the night, I think he wrote that in the 90s, so it couldn't, you know, it wasn't it wasn't able to do that, but that that would be obviously the ultimate sandbox game of course

Speaker 1  00:36:17
on that topic. Do you think we're living in a simulation?

Speaker 2  00:36:20
Yes, well, so, okay, so I'm

Speaker 1  00:36:22
gonna jump around from the absurdly philosophical to the

Speaker 2  00:36:26
very, very happy too. So I think my answer to that question is a little bit complex because there is simulation theory which obviously Nicb Ostrom, I think famously first proposed. Um and I don't quite believe it in in in that sense. So, um in the in the sense that are we in some sort of computer game or have our descendants somehow re created earth in the 21st century and and and some for some kind of experimental reason. I think that. Um but I do think that we that that that we might be that the best way to understand physics and the universe is from a computational perspective. So, understanding as an information universe and actually information being the most fundamental unit of reality rather than matter or energy. So physicists would say, you know, matter or energy, you know, e equals M C squared. These are the things that are are the fundamentals of the universe. I would actually say information, um which of course itself can be, can specify energy or matter, right. Matter is actually just, you know, we're just out the way our bodies and or the molecules in our body arranges information. So I think information may be the most fundamental way to describe the universe and therefore, you could say we're in some sort of simulation because of that.

Um but I don't, I do, I'm not, I'm not really a subscriber to the idea that, you know, these are sort of throw away billions of simulations around. I think this is actually very critical and possibly unique. This simulation particular

Speaker 1  00:37:58
one. And you just mean treating the universe as a computer that's processing and modifying information is a good way to solve the problems of physics, of chemistry, of biology and perhaps of humanity and so on.

Speaker 2  00:38:15
Yes, I think understanding physics in terms of information theory might be the best way to to really understand what's going on here,

Speaker 1  00:38:25
from our understanding of universal turing machine, from our understanding of a computer. Do you think there's something outside of the capabilities of a computer that is present in our universe? You have a disagreement with Roger Penrose, the nature of consciousness. He he thinks that consciousness is more than just a computation. Do you think all of it, the whole shebang can be, can be a complicated.

Speaker 2  00:38:50
I've had many fascinating debates with Sir Roger Penrose and obviously he's famously, and I read, you know, Emperor's new mind and and and his books, his classical books, and they were pretty influential in the, in the 90s and um he believes that there's something more something quantum that is needed to explain consciousness in the brain. Um I think about what we're doing, actually, a deep mind and what my career is being, we're almost like touring champion. So we are pushing touring machines or classical computation to the limits, what are the limits of what classical computing can do now. Um and at the same time, I've also studied neuroscience to see. And that's why I did my PhD in was to see also to look at, you know, is there anything quantum in the brain from a neuroscience or biological perspective? And um and so far I think most neuroscientists and most mainstream biologists, neuroscientists would say there's no evidence of any quantum systems or effects in the brain as far as we can see, it can be mostly explained by classical classical theories. So and then so there's sort of the the search from the biology side. And then at the same time there's the raising of the water at the bar from what classical turing machines can do. Uh And and and you know, including our new Ai systems and as you alluded to earlier, um you know, I think ai especially in the last decade plus has been a continual story now of surprising events and surprising successors, knocking over one theory after another. What was thought to be impossible, you know, from go to protein folding and so on. And so I think um I would be very hesitant to bet against how far the universal turing machine and classical computation paradigm can go. And and my betting would be that all of certainly what's going on in our brain can probably be mimicked or or approximated on a on a classical machine.

Um not, you know, not requiring something metaphysical or quantum.

Speaker 1  00:40:54
And we'll get there with some of the work with alpha fold, which I think begins the journey of modeling this beautiful and complex world of biology. So you think all the magic of the human mind comes from this, just a few pounds of mush of of biological computational mush. That's akin to some of the neural networks, not directly but in spirit that deepmind has been working with.

Speaker 2  00:41:22
Well look, I think it's you say it's a few, you know, of course this is the I think the biggest miracle of the universe is that it is just a few pounds of mush in our skulls. And yet it's also our brains are the most complex objects in that that we know of in the universe. So there's something profoundly beautiful and amazing about our brains and I think that it's an incredibly incredible efficient machine. And and uh and it's it's you know, phenomenon basically. And I think that building a I one of the reasons I want to build a I and I've always wanted to is I think by building an intelligent artifact like ai and then comparing it to the human mind that will help us unlock the uniqueness and the true secrets of the mind that we've always wondered about since the dawn of history, like consciousness dreaming, creativity, uh emotions, what are all these things right? We've we've we've wondered about them since, since the dawn of humanity and I think one of the reasons and you know, I love philosophy and philosophy of mind is we found it difficult is there haven't been the tools for us to really, other than introspection to from very clever people in in history, very clever philosophers to really investigate this scientifically. But now suddenly we have a plethora of tools firstly, we have all of the neuroscience tools, Fmri machines, single cell recording all of this stuff, but we also have the ability computers and ai to build intelligence systems. So I think that uh you know, I think it is amazing what the human mind does and and and I'm kind of in awe of it really, and uh and I think it's amazing that without human minds were able to build things like computers and and actually even, you know, think and investigate about these questions. I think that's also a testament to the human mind.

Speaker 1  00:43:08
Yeah, the universe built the human mind that now is building computers that help us understand both the universe and our own human mind

Speaker 2  00:43:17
is exactly it. I mean, I think that's one, you know, one could say we we are, maybe we're the mechanism by which the universe is going to try and understand itself.

Speaker 1  00:43:25
Yeah, it's beautiful. So let's let's go to the basic building blocks of biology that I think is another angle at which you can start to understand the human mind the human body, which is quite fascinating, which is from the basic building blocks start to simulate, start to model how from those building blocks you can construct bigger and bigger, more complex systems, maybe one day the entirety of the human biology. So here's another problem that thought to be impossible to solve, which is protein folding and alpha fold or specific alfa fall to did just that it's solved protein folding. I think it's one of the biggest breakthroughs certainly in the history of structural biology, but in general in science um maybe from a high level, what is it and how does it work? And then we can ask some fascinating questions after

Speaker 2  00:44:24
sure. So maybe to explain it to people not familiar with protein folding is you know, first of all explain proteins which is you know proteins are essential to all life. Every function in your body depends on proteins. Sometimes they're called the workhorses of biology. And if you look into them and you know obviously as part of alpha fold, I've been researching proteins and structural biology for the last few years. You know, they're amazing little bio nano machines, proteins, incredible if you actually watch videos of how they work animations of how they work and proteins are specified by their genetic sequence called amino acid sequence. So you can think their genetic makeup and then in the body in nature they when they when when they fold up into a three D. Structure. So you can think of it as a string of beads and then they fold up into a ball. Now, the key thing is you want to know what that three D. Structure is because the structure, the three D structure of a protein is what helps to determine what does it do, the function it does in your body. And also, if you're interested in drug, drugs or disease, you need to understand that three D.

Structure because if you want to target something with a drug compound about to block something the protein is doing, you need to understand where it's going to bind on the surface of the protein. Obviously in order to do that, you need to understand the three D structure.

Speaker 1  00:45:42
So the structure is mapped to the function.

Speaker 2  00:45:44
The structure is mapped to the function and the structure is obviously somehow specified by the by the amino acid sequence. And that's in essence the protein folding problem is can you just from the amino acid sequence, the one dimensional string of letters, can you immediately computational predict the three D structure? And this has been a grand challenge in biology for over 50 years. So, I think it was first articulated by christian and Hansen a Nobel prize winner in 1972 as part of his Nobel prize winning lecture. And he just speculated this should be possible to go from the amino acid sequence to the three D structure. He didn't say how. So I you know, I've been it's been described to me as equivalent to Fermat's last theorem, but for biology

Speaker 1  00:46:28
you should as somebody that very well might win the Nobel prize in the future. But outside of that you should do more of that kind of thing. And the margins just put random

Speaker 2  00:46:37
things like

Speaker 1  00:46:38
200 years to set

Speaker 2  00:46:40
People off for 200 years

Speaker 1  00:46:42
should be passed. Exactly, and just don't give any

Speaker 2  00:46:44
exactly. I think everyone exactly should be. I'll have to remember that for future. So yeah, so he said, you know, with this one throwaway remark, just like Fermat, you know, he he set off this whole 50 years uh field really of computational biology and and they had, you know, they got stuck, they hadn't really got very far with doing this. And and until now, until alpha fold came along this is done experimentally right? Very painstakingly. So the rule of thumb is and you have to like crystallized the protein, which is really difficult. Some proteins can't be crystallized like membrane proteins. And then you have to use very expensive electron microscopes or X ray crystallography machines really painstaking work to get the three D structure and visualize the three D structure. So the rule of thumb in in in experimental biology is that it takes one PhD student, their entire PhD to do one protein. Uh And with alpha fall two were able to predict the three D structure in a matter of seconds. Um And so we were, you know, over christmas, we did the whole human proteome or every protein in the human body or 20,000 proteins.

So the human protein is like the equivalent of the human genome but on protein space and uh and sort of revolutionized really what uh structural biologists can do because now they don't have to worry about these painstaking experimental, should they put all of their effort in or not, they can almost just look up the structure of their proteins like a google search.

Speaker 1  00:48:09
And so there's a data set on which it's trained and how to map this amino acids. First of all, it's incredible that approaching this little chemical computer is able to do that computation itself into some kind of distributed way and do it very quickly. That's a weird thing. And they evolved that way because you know, in the beginning, I mean that's a great invention, just the protein itself.

Speaker 2  00:48:31
I mean and

Speaker 1  00:48:31
then there's I think probably a history of like they evolved to have many of these proteins and these proteins figure out how to be computers themselves in such a way that you can create structures that can interact in complexes with each other in order to form high level functions. I mean it's a weird system that they figured it out.

Speaker 2  00:48:51
Well for sure. I mean we you know, maybe we should talk about the origins of life too, but proteins themselves I think are magical and incredible. Uh as I said, little little bio nano machines and and and actually let Leventhal, who was another scientist, a contemporary of am johnson, he coined this Leventhal, what became known as Leventhal paradox, which is exactly what you're saying. He calculated roughly an average protein, which is maybe 2000 amino acids bases long is um Is can fold in maybe 10 to the power 300 Different confirmations. So there's 10 to the power 300 different ways that protein could fold up. And yet somehow in nature, physics solves this solves this in a matter of milliseconds. So proteins fold up in your body in, you know, sometimes in fractions of a second. So physics is somehow solving that search problem.

Speaker 1  00:49:45
And just to be clear in many of these cases, maybe correct me if I'm wrong, there's often a unique way for the sequence to form itself. So among that huge number of possibilities, it figures out a way how to stay billy uh in some cases there might be a miss function mr So on, which leads to a lot of the disorders and stuff like that. But most of the time it's a unique mapping. And that unique mapping is not obvious,

Speaker 2  00:50:10
know exactly

Speaker 1  00:50:12
what the problem is

Speaker 2  00:50:13
exactly. So there's a unique mapping, usually in a healthy if it's healthy and as you say, in disease.

Speaker 1  00:50:19
So for

Speaker 2  00:50:20
Example, Alzheimer's 111 conjecture is that it's because of misfolded protein protein that folds in the wrong way. Amyloid beta protein. So um and then because it folds in the wrong way, it gets tangled up right in your in your neurons. So um it's super important to understand both healthy functioning and and also disease is to understand, you know, what what these things are doing and how they're structuring. Of course the next step is sometimes proteins change shape when they interact with something, so they're not just static necessarily in in in biology.

Speaker 1  00:50:53
Maybe you can give some interesting sort of beautiful things to you about these early days of alpha fold of of solving this problem because unlike games, this is real physical systems that are less amenable to self play type of mechanisms, the size of the dataset is smaller that you might otherwise like, you have to be very clever about certain things. Is there something you can speak to? Um what was very hard to solve and what are some beautiful aspects about the solution?

Speaker 2  00:51:25
Yeah, I would say a four fold is the most complex and also probably most meaningful system we've built so far. So it's been amazing time actually, the last, you know, 23 years to see that come through because um as we talked about earlier games is what we started on building things like Alphago and Alpha zero, but really the ultimate goal was to not just to crack games, it was just to to to build, use them to bootstrap general learning systems. We could then apply to real world challenges. Specifically my passion is scientific challenges like protein folding and then alpha fold of course is our first big proof point of that. And so um you know, in terms of the data and the amount of innovations that had to go into it, we, you know, it was like more than 30 different component algorithms needed to be put together to crack the protein folding. Um I think some of the big innovations were that um kind of building in some hard coded constraints around physics and evolutionary biology um to constrain sort of things like the bond angles uh in the in the in the protein and things like that um a lot but not to impact the learning system. So still allowing the system to be able to learn the physics itself from the examples that we had. And the examples as you say, there are only about 100 and 50,000 proteins. Even after 40 years of experimental biology, only around 100 50,000 proteins have been the structures have been found out about. So that was our training set, which is much less than normally we would like to use. Um but using various tricks things like self distillation. So actually using alpha fold predictions, um some of the best predictions that it thought was highly confident in, We put them back into the training set right to make the training set bigger, That was critical to alpha fold working.

So there was actually a huge number of different um innovations like that that were required to ultimately crack the problem. Alpha Fold one. What it produced was dissed a gram. So a kind of a matrix of the pair wise distances between all of the molecules in the in the in the protein. And then there had to be a separate optimization process to create the three d structure. And what we did for alpha fold too is make it truly end to end. So we went straight from the amino acid sequence of bases to the three D structure directly without going through this intermediate step. And in machine learning what we've always found is that the more end to end, you can make it, the better the system. And it's probably because um we, you know, the in the end the system is better at learning what the constraints are than than than we are as the human designers of specifying it. So any time you can let it flow end to end and actually just generate what it is you're really looking for in this case, the three D structure. You're better off than having this intermediate step, which you then have to handcraft the next step for. So it's better to let the gradients and the learning flow all the way through the system from the end point, the end output.

You want to the inputs.

Speaker 1  00:54:26
So that's a good way to start on a new problem. Handcraft a bunch of stuff at a bunch of manual constraints with a small intend learning piece or a small learning piece and grow that learning piece until it consumes the whole thing.

Speaker 2  00:54:38
That's right. And so you can also see, you know, this is a bit of a method we've developed over doing many sort of successful outfits, we call them Alpha X projects, right? Is, and the easiest way to see that is the evolution of Alpha go to Alpha Zero. So, Alphago was a learning system, but it was specifically trained to only play go, Right? So, and what we wanted to do and with the first version of Alphago is just get to World Champion performance, no matter how we did it. Right? And then, and then of course Alphago zero. We we we remove the need to use human games as a starting point, right? So it could just play against itself from random starting point from the beginning, so that removes the need for human knowledge about go. And then finally Alpha Zero then generalized it. So that any things we had in there, the system, including things like symmetry of the go board were removed, so that Alpha Zero could play from scratch any to play a game. And then mu zero, which is the final, our latest version of that set of things, was then extending it so that you didn't even have to give it the rules of the game.

It would learn that for itself. So it could also deal with computer games as well as board games.

Speaker 1  00:55:43
So that line of Alphago, Alphago zero, Alpha zero mu zero, that's the full trajectory of what you can take from uh imitation learning to full self supervised learning.

Speaker 2  00:55:56
Yeah, exactly. And learning learning the entire structure of the environment you put in from scratch, right? And and and and bootstrapping it through self play yourself. But the thing is it would have been impossible, I think, or very hard for us to build Alpha Zero or mu zero first out of the box.

Speaker 1  00:56:14
Even psychologically because you have to believe in yourself for a very long time, you're you're constantly dealing with doubt because a lot of people say that it's impossible. Exactly.

Speaker 2  00:56:23
So it's hard enough just to do go as you were saying, everyone thought that was impossible or at least a decade away from when we when we did it back in 2015, 24, 2016. And and so yes, it would have been psychologically probably very difficult as well as the fact that of course we learned a lot by building out to go first. Right? So I think this is why I call ai an engineering science, it's one of the most fascinating science disciplines, but it's also an engineering science in the sense that unlike natural sciences, the phenomenon you're studying doesn't exist out in nature, you have to build it first, you have to build the artifact first and then you can study how, how and pull it apart and how it works.

Speaker 1  00:57:02
This is tough to ah ask you this question because you probably will say it's everything. But let's let's try, let's try to think of this because you're in a very interesting position where Deepmind is a place of some of the most brilliant ideas in the history of AI but it's also a place of brilliant engineering. So how much of solving intelligence? This big goal for Deepmind? How much of it is science, how much is engineering? So how much is the algorithms, how much is the data, how much is the hardware compute infrastructure? How much is it the software, computer infrastructure, um what else is there? How much is the human infrastructure and like just the humans interacting certain kinds of ways, you know, all the space of all those ideas and how much is maybe like philosophy? How much, what's the key if um Um if you were to sort of look back like if we go forward 200 years look back, what was the key thing that solved intelligence? I think

Speaker 2  00:58:04
it's a combination I first of all of course it's a combination of all those things but the ratios of them changed over over time. So so even in the last 12 years. So we started deep mine in 2010, which is hard to imagine now because 2010 it's only 12 short years ago, but nobody was talking about a I you know I don't remember back to your M. I. T. Days and no one was talking about it. I did a postdoc at M. I. T back around then and it was sort of thought of as well look we know ai doesn't well we tried this hard in the nineties at places like M. I. T. Mostly losing using logic systems and old fashioned sort of good old fashioned ai we would call it now people like Minsky and and and and Patrick Winston and you know all these characters right?

And used to debate a few of them and they used to think I was mad thinking about that some new advance could be done with learning systems. And um I was actually pleased to hear that because at least you know you're on a unique track at that point, right? Even if every all of your you know professors, you're mad. And of course in industry you couldn't we couldn't get you know difficult to get two cents together and which is hard to imagine now as well given that's the biggest sort of buzzword in in Vcs and and and fundraising is easy and all these kind of things today. So Back in 2010 it was very difficult and what we the reason we started then and Shane. And I used to discuss um what were the sort of founding tenants of deepmind and it was very various things. One was algorithmic advances. So deep learning, you know Geoff Hinton and Koa just had just sort of invented that in academia but no one in industry knew about it. We love reinforcement learning. We thought that could be scaled up but also understanding about the human brain had advanced quite a lot in the in the decade prior with Fmri machines and other things. So we could get some good hints about architectures and algorithms and and and sort of representations may be that the brain uses so as at a systems level, not at a implementation level. Um And then the other big things were compute and gpu s right so we could see a compute was going to be really useful and it got to a place where it become commoditized mostly through the games industry and and that could be taken advantage of.

And then the final thing was also mathematical and theoretical definitions of intelligence. So things like a I X I A ICSI which Shane worked on with his supervisor, Marcus Hutter which is sort of theoretical uh proof really of universal intelligence which is actually a reinforcement learning system. Um In the limit I mean assumes infinite computing infinite memory in the way you know like a turing machine proof. But I was also waiting to see something like that to to you know like turing machines and and computation theory that people like turing and Shannon came up with underpins modern computer science. Um you know I was waiting for a theory like that to sort of underpin A. G. I. Research. So when I met Shane and saw he was working on something like that. You know that to me was a sort of final piece of the jigsaw. So In the early days I would say that ideas were the most important. You know for us it was deep reinforcement learning scaling up deep learning of course we've seen transformers so huge leaps.

I would say three or four from if you think from 2010 until now huge evolutions things like alphago. Um and um and and maybe there's a few more still needed but as we get closer to A I A. G. I um I think engineering becomes more and more important and data because scale and of course the recent you know results of GPT three and all the big language models and large models including our ones has shown that scale is and large models are clearly going to be unnecessary but perhaps not sufficient part of an A G. I. Solution.

Speaker 1  01:01:38
And throughout that like you said I'd like to give you a big thank you. You're one of the pioneers in this is sticking by ideas like reinforcement learning that this can actually work given actually limited success in the past and also which we still don't know but proudly having the best researchers in the world and talking about solving intelligence, so talking about whatever you call it A. G. I. Or something like this that speaking of M. I. T. That's that's just something that you wouldn't bring up. Uh not not maybe you did in like 40 50 years ago but that was um ai was a place where you do tinkering very small scale, not very ambitious projects and um maybe the biggest ambitious projects were in the space of robotics and doing like the DARPA challenge. But the task of solving intelligence and believing you can that's really really powerful. So in order for engineering to do its work to to have great engineers build great systems, you have to have that belief that threats throughout the whole thing that you can actually solve some of these impossible challenges.

Speaker 2  01:02:52
Yeah that's right. And and back in 2010, you know our mission statement um and still is today, you know, is it was used to be a Solving step one solve intelligence step to use it to solve everything else. So if you can imagine pitching that to a VC in 2010, you know the kind of looks we we got we managed to you know find a few kooky people to back us but it was it was tricky and and I and I got to the point where we wouldn't mention it to any of our professors because they were just, I roll and I think we, you know, committed career suicide and and uh and and you know, so it was a lot of things that we had to do, but we always believed it. And one reason, you know, by the way, one reason we, I believe I've always believed in reinforcement learning is that that if you look at neuroscience, that is the way that the primate brain learns. One of the main mechanisms is the dopamine system implement some form of tD learning is very famous result in the late nineties where they saw this in monkeys and uh and as you know, propagating prediction error. So, you know, again in the limit, this is this is what I think you can use neuroscience for is is you know, in any mathematics when you're when you're doing something as ambitious as trying to solve intelligence and your your you know, it's blue sky research, no one knows how to do it. You you you need to use any evidence or any source of information, you can to help guide you in the right direction or give you confidence you're going in the right direction. So, so that that was one reason we pushed so hard on that and that's just going back to your earlier question about organization, The other big thing that I think we innovated with a deep mind to encourage invention and and uh and innovation was the multidisciplinary organization we built and we still have today. So Deepmind originally was a confluence of the of the most cutting edge knowledge in neuroscience with machine learning, engineering and mathematics, right? And and gaming. And then since then we've built that out even further. So we have philosophers here and and by, you know, ethicists, but also other types of scientists, physicists and so on.

Um and that's what brings together, I try to build a sort of a new type of bell labs but in its golden era. Right. Uh and and a new expression of that to try and foster this incredible sort of innovation machine. So talking about the humans in the machine, the mind itself is a learning machine with a lot of amazing human minds in it, coming together to try and build these learning systems,

Speaker 1  01:05:15
if we return to the big ambitious dream of ALFA fold, that maybe the early steps on a very long journey in um in biology, do you think the same kind of approach can used to predict the structure and function of more complex biological systems? So multi protein interaction. And then, I mean you can go out from there just simulating bigger and bigger systems that eventually simulate something like the human brain or the human body. Just the big mush the mess of the beautiful resilient method Biology, do you do you see that as a long term vision?

Speaker 2  01:05:55
I do and I think you know, if you think about what are the things top things I wanted to apply ai to once we had powerful enough systems biology and curing diseases and understanding biology was right up there, you know, top of my list. That's one of the reasons I personally pushed that myself and with alpha fold. But I think alpha fold amazing as it is, is just the beginning. Um and and I hope it's evidence of what could be done with computational methods. So um you know, alpha fall, solve this, this huge problem of the structure of proteins. But biology is dynamic. So really what I imagine from here and we're working on all these things now is protein, protein interaction, protein ligand binding. So reacting with molecules, then you want to build up two pathways and then eventually a virtual cell. That's my dream. Maybe in the next 10 years. And I've been talking actually to a lot of biologist friends of mine, poor nurse who runs the quick institute. Amazing biologist Nobel, Prize winning biologist we've been discussing for 20 years now.

Virtual cells. Could you build a virtual simulation of a cell. And if you could, that would be incredible for biology and disease discovery because you could do loads of experiments on the virtual cell and then only at the last stage validated in the wet lab. So you could, you know, in terms of the search space of discovering new drugs, you know, takes 10 years roughly to go from uh to go from a, you know, identifying a target to uh, having a drug candidate, maybe that could be shortened to, you know, by an order of magnitude with if you could do most of that, that that work in silicone. So in order to get to a virtual cell, we have to build up understanding of different parts of biology and the interactions and and so, you know, every every few years we talk about this with, I talked about this with paul. And then finally, last year after alpha fold, I said, now is the time we can finally go for it and and alpha folds. The first proof point that this might be possible. And he's very exciting. We have some collaborations with his with his lab and they're just across the road actually from us. It's a wonderful being here in King's Cross with the Crick Institute across the road. And and I think the next steps, you know, I think there's gonna be some amazing advances in biology built on top of things like Alpha fold. We're already seeing that with the community doing that after we've open sourced it and released it.

Um, and uh, you know, I I often say that, I think if you think of mathematics is the perfect description language for physics, I think aI might be end up being the perfect description language for Biology because biology is so messy. It's so emergent, so dynamic and complex. Um, I think I find it very hard to believe we'll ever get to something as elegant as Newton's laws, emotions to describe a cell. Right? It's just too complicated. Um so I think ai is the right tool for this.

Speaker 1  01:08:42
You have to you have to start at the basic building blocks and use ai to run the simulation for all those building blocks. So have a very strong way to do prediction of what given these building blocks, What kind of biologic, how the function and the evolution of that biological system. It's almost like a cellular automata. You have to run it. You can't analyze it from a high level. You have to take the basic ingredients, figure out the rules and let it run. But in this case the rules are very difficult to figure out. Yes, learn them.

Speaker 2  01:09:12
That's exactly it. So it's the biology is too complicated to figure out the rules. It's it's to emergent to dynamic, say, compared to a physics system, like the motion of a planet. Right? And so you have to learn the rules. And that's exactly the type of systems that we're building.

Speaker 1  01:09:27
So you, you mentioned open source alpha fold and even the data involved. To me personally, also really happy and a big thank you for open sourcing with Joko the physics simulation engine. That's um that's often used for robotics research and so on. So I think that's a pretty gangster move. Uh so what, what's the, what's, I mean, this uh, very few companies or people would do that kind of thing. What's the philosophy behind that?

Speaker 2  01:09:57
You know, it's a case by case basis. And in both those cases we felt that was the maximum benefit to humanity to do that. And the scientific community, in one case the robotics physics community with cocoa. So yes, we purchased it for the express principle to open source it. So, um, so, you know, people appreciate that. It's great to hear that that you do. And then the second thing was mostly we did it because the person building, it is uh, not able not able to cope with supporting it anymore because it was, it got too big for him is an amazing professor who built it in the first place. So we helped him out with that and then with alpha folds even bigger I would say. And I think in that case we decided that there were so many downstream applications of alpha fold, um, that we couldn't possibly even imagine what they all were. So the best way to accelerate drug discovery and also fundamental research would be to, to give all that data away and and, and the and the and the system itself. Um, you know, it's been so gratifying to see what people have done that within just one year, which is a short amount of time in science and it's been used by over 500,000 researchers have used it. We think that's almost every biologist in the world, I think there's roughly 500,000 biologists in the world.

Professional biologists have used it to look at their proteins of interest. We've seen amazing fundamental research done. So a couple of weeks ago. Front cover, there was a whole special issue of science, including the front cover which had the nuclear pore complex on it, which is one of the biggest proteins in the body. The nuclear pore complex is a protein that governs all the nutrients going in and out of your cell nucleus. So they're like little hole gateways that open and close to let things go in and out of your cell nucleus. So they're really important. But they're huge because their massive donut ring shaped things and they've been looking to try and figure out that structure for decades and they have lots of, you know, experimental data but it's too low resolution, there's bits missing. And they were able to like a giant lego jigsaw puzzle. Use alpha fall predictions plus experimental data and combined those two independent sources information. Actually, four different groups around the world were able to put it together the more or less simultaneously using alpha fold predictions. So that's been amazing to see.

And pretty much every farmer company, every drug company executive I've spoken to has said that their teams are using alpha fold to accelerate whatever drugs uh they're they're trying to discover. So I think the knock on effect has been enormous in terms of the impact that alpha fold has made

Speaker 1  01:12:31
and it's probably bringing in, it's creating biologists, it's bringing more people into the field um both on the excitement and both on the technical skills involved. And it's almost like a gateway drug to biology.

Speaker 2  01:12:44
Yes, it is more computational people involved to hopefully, and I think for us, you know, the next stage, as I said, you know, in future, we have to have other considerations too. We're building on top of alpha fold and these other ideas I discussed with you about protein protein interactions and and genomics and other things and not everything will be open. So some of it will will do commercially because that would be the best way to actually get the most resources and impact behind it in other ways. Some other projects will do nonprofit style. Um and also we have to consider for future things as well. Safety and ethics as well. Like, you know, synthetic biology, there are, you know, there is dual use And we have to think about that as well with alpha fold. We, you know, we consulted with 30 different bioethicists and other people expert in this field to make sure it was safe before we released it. So there'll be other considerations in future. But for right now, you know, I think alpha fold is a kind of a gift from us to to to the scientific community.

Speaker 1  01:13:36
So I'm pretty sure that something like Alpha fold would be part of nobel prizes in the future, but us humans of course are horrible with credit assignment, so we'll of course give it to the humans. Um do you think there will be a day when Ai system Can't be denied that it earned that Nobel Prize? Do you think we'll see that in 21st century?

Speaker 2  01:14:03
It depends what type of AI is we end up building, right? Whether there, you know, goal seeking agents who specifies the goals, who comes up with the hypotheses who, you know, who determines which problems to tackle. Right? So I think

Speaker 1  01:14:17
it's about announcement

Speaker 2  01:14:19
results exactly as part of it. Um So I think right now of course it's it's it's it's amazing human ingenuity that's behind these systems. And then the system in my opinion is just a tool, you know, be a bit like saying with Galileo and his telescope, you know, the ingenuity, the credit should go to the telescope, I mean it's clearly Galileo building the tool which he then uses. So I still see that in the same way today, even though these tools learn for themselves um there I think I think of things like alpha fold and that the things we're building as the ultimate tools for science and for acquiring new knowledge to help us as scientists acquire new knowledge, I think one day there will come a point where an Ai system may solve or come up with something like general relativity of its own bat, not just by averaging everything on the internet or averaging everything on pub med, that would be interesting to see what that would come up with. Um so that to me is a bit like our earlier debate about creativity, you know, inventing go rather than just coming up with a good go move, and so I think solving, I think to to, you know, if we wanted to give it the credit of like a nobel type of thing, then it would need to invent, go and sort of invent that new conjecture out of the blue um rather than being specified by the human scientists or the human creators. So I think right now that's it's definitely just a tool,

Speaker 1  01:15:42
although it is interesting how far you get by averaging everything on the internet, like you said, because, you know, a lot of people do see science is you're always standing on the shoulders of giants. And the question is, how much are you really reaching up above the shoulders of giants? Maybe it's just a simulating different kinds of results of the past with ultimately this new perspective that gives you this breakthrough idea, but that idea may not be novel in the way that we can be already discovered on the internet, maybe the nobel prizes of the next 100 years already, all there on the internet to be discovered,

Speaker 2  01:16:18
They could be, they could be. I mean, I think um this is one of the big mysteries, I think is that I first of all, I believe a lot of the big new breakthroughs that are going to come in the next few decades and even in the last decade are gonna come out the intersection between different subject areas where there'll be some new connection that's found between what seemingly are disparate areas. And one can even think of Deepmind, as I said earlier, as a sort of interdisciplinary between neuroscience ideas and ai engineering ideas originally. And so, um so I think there's that and then one of the things we can't imagine today is, and one of the reasons I think people we were so surprised by how well large models worked is that actually it's very hard for our human minds, our limited human minds to understand what it would be like to read the whole internet, right? I think we can do a thought experiment and I used to do this of like, well what if I read the whole of Wikipedia, what would I know, and I think our minds can just about comprehend maybe what that would be like, but the whole internet is beyond comprehension. So, I think we just don't understand what it would be like to be able to hold all of that in mind potentially. Right? And then active at once and then maybe what are the connections that are available there. So I think no doubt there are huge things to be discovered just like that, but I do think there is this other type of creativity of true spark of new knowledge, new idea. Never thought before about can't be average from things that are known um that really of course everything come, you know, nobody creates in a vacuum so there must be clues somewhere, but just a unique way of putting those things together. I think some of the greatest scientists in history have displayed that, I would say, although it's very hard to know going back to their time what was exactly known when they came up

Speaker 1  01:18:03
with. Although you're making me really think because just the thought experiment of deeply knowing 100 Wikipedia

Speaker 2  01:18:11
pages.

Speaker 1  01:18:13
I don't think I can, I've been really impressed by Wikipedia for for technical topics. So if you know 100 pages or 1000 pages, I don't think you can vision truly comprehend what's what kind of intelligence that is. It's a pretty powerful if you know how to use that and integrate that information correctly. I think you can go really far. You can probably construct thought experiments based on that. Like simulate different ideas. So if this is true, let me run this thought experiment then maybe this is true. It's not really invention, It's like just taking literally the knowledge and using it to construct the very basic simulation of the world. I mean some argue it's romantic in part but Einstein would do the same kind of things with thought experiments.

Speaker 2  01:18:59
One could imagine doing that systematically across millions of Wikipedia pages plus pub made all these things. I think there are many, many things to be discovered like that they're hugely useful, you know, you could imagine and I want us to do some of these things in material science like room temperature superconductors or something on my list one day I'd like to like you know have an AI system to help build better optimized batteries, all of these sort of mechanical things. I think a systematic sort of search could be guided by a model could be could be extremely powerful.

Speaker 1  01:19:33
So speaking of which you have a paper on nuclear fusion magnetic control of Tokamak plasmas to deep reinforcement learning. So you you're seeking to solve nuclear fusion with deep RL uh so it's doing control of high temperature plasmas. Can you explain this work and can ai eventually solve nuclear fusion?

Speaker 2  01:19:52
It's been very fun last year or two. Very productive because we've been taking off a lot of my dream projects if you like of things that I've collected over the years of areas of science that I would like to I think could be very transformative if we helped accelerate and a really interesting problems scientific challenges in of themselves

Speaker 1  01:20:12
energy.

Speaker 2  01:20:12
So energy. Yes, exactly. So energy and climate. So we talked about disease and biology is being one of the biggest places I think AI can help with. I think energy and climate is another one. So maybe they would be my top two. Um And fusion is 11 area I think AI can help with. Now fusion has many challenges, mostly physics, material science and engineering challenges as well to build these massive fusion reactors and contain the plasma. And what we try to do and whenever we go into a new field to apply our systems is we look for we talk to domain experts, we try and find the best people in the world to collaborate with um in this case infusion we we collaborated with the Pfl in Switzerland, the Swiss Technical Institute who are amazing. They have a test reactor they were willing to let us use which you know, I double checked with the team we were going to use carefully and safely. I was impressed. They managed to persuade them to let us use it.

And and it's a it's an amazing test reactor. They have their and they try all sorts of pretty crazy experiments on it. And the what we tend to look at is if we go into a new domain like fusion, what are all the bottleneck problems like thinking from first principles, you know what all the bottleneck problems that still stopping fusion working today. And then we look at we you know, we get fusion expert to tell us and then we look at those bottlenecks and we look at the ones which ones are amenable to our ai methods today. Right? And and and then and would be interesting from a research perspective from our point of view, from an ai point of view and that would address one of their bottlenecks and in this case plasma control was perfect. So you know, the plasma, it's a million degrees Celsius, something like that's hotter than the sun. Um and there's obviously no material that can contain it. So they have to be containing these magnetic, very powerful superconducting magnetic fields. But the problem is plasma is pretty unstable as you imagine, you're you're kind of holding a mini sun mini star in a reactor. So, you know, you you kind of want to predict ahead of time what the plasma is going to do. So you can move the magnetic field within a few milliseconds, you know, to to basically contain what it's gonna do next.

So it seems like a perfect problem if you think of it for like a reinforcement learning prediction problem. So, you know, you got controller, you're gonna move the magnetic field and until we came along, you know, they were they were doing with with traditional operational research type of controllers which are kind of handcrafted and the problem is of course they can't react in the moment to something the plasma is doing that. They have to be hard coded. And again, knowing that that's normally our go to solution is we would like to learn that instead. And they also had a simulator of these plasma. So there were lots of criteria that matched what we like to to to use.

Speaker 1  01:22:50
So can ai eventually solve nuclear fusion?

Speaker 2  01:22:54
Well, so we with this problem and we published in the nature paper last year, we held the fusion that we held the plasma in a specific shapes. So actually it's almost like carving the plasma into different shapes and control and hold it there for the record amount of time. So, so that's one of the problems of fusion sort of solved

Speaker 1  01:23:13
So have a controller that's able to no matter the shape,

Speaker 2  01:23:17
contain it, contain it and hold it in structure and there's different shapes that are better for for the energy productions called droplets and and and so on. So, so that was huge. And now we're looking we're talking to lots of fusion startups to see what's the next problem we can tackle in the fusion area.

Speaker 1  01:23:35
So, another fascinating place um in a paper title pushing the frontiers of density functional by solving the fractional electron problem. So, you're taking on modeling and simulating the quantum mechanical behavior of electrons. Can you explain this work and can ai model and simulate arbitrary quantum mechanical systems in the future? Yeah,

Speaker 2  01:23:58
so this is another problem I've had my eye on for, you know, a decade or more, which is um sort of simulating the properties of electrons. If you can do that, you can basically describe how elements and materials and substances work. So it's kind of like fundamental if you wanna advance material science, um and, you know, we have Schrodinger's equation and then we have approximations to that density functional theory. These things are, you know, are famous and people try and write approximations to to these, to these functional and and kind of come up with descriptions of the electron clouds where they're gonna go, how they're gonna interact when you put two elements together and what we try to do is learn a simulation, learn a functional that will describe more chemistry types of chemistry. So, until now, you know, you can run expensive simulations, but then you can only simulate very small molecules, very simple molecules. We would like to simulate large materials. Um and so today there's no way of doing that. And we're building up towards building functional. Is that approximate schrodinger's equation. And then allow you to describe what the electrons are doing. Um And all materials sort of science and material properties are governed by the electrons and and how they interact.

Speaker 1  01:25:17
So, have a good summarization of the simulation through the functional um but one that is still close to what the actual simulation would come out with. So what mm, how difficult that task. What's involved in that task is running those, those complicated simulations and learning the task of mapping from the initial conditions and the parameters of the simulation, learning what the functional would

Speaker 2  01:25:43
be. So it's pretty tricky. And we've done it with you know the nice thing is we there are we can run a lot of the simulations. The molecular dynamics simulations on our compute clusters and so that generates a lot of data. So in this case the data is generated. So we like those sort of systems and that's why we use games Simulator generated data and we can kind of create as much of it as we want really. Um And just let's leave some you know if any computers are free in the cloud we just run we run some of these calculations right compute cluster calculations.

Speaker 1  01:26:15
The free computer time is used up on quantum mechanics.

Speaker 2  01:26:18
Quantum mechanics exactly simulations and protein simulations and other things. And so um and so you know when you're not searching on Youtube for video cat videos, we're using those computers usefully And Quantum chemistry the idea and putting them to good use and then Yeah. And then all of that computational data that's generated we can then try and learn the functional from that. Which of course are way more efficient. Once we learn the functional than running those simulations would be

Speaker 1  01:26:46
do you think one day aI may allow us to do something like basically crack open physics so do something like travel faster than the speed of light.

Speaker 2  01:26:55
My ultimate aim has always been with Ai is um the reason I am personally working on Ai for my whole life was to build a tool to help us understand stand the universe. So I wanted to and that means physics really and the nature of reality. So um I don't think we have systems that are capable of doing that yet, but when we get towards A G I I think that's one of the first things I think we should apply A G. I to. I would like to test the limits of physics and our knowledge of physics. There's so many things we don't know. There's one thing I find fascinating about science and you know, it's a huge proponent of the scientific method as being one of the greatest ideas humanity has ever had and allowed us to progress with our knowledge. I think as a true scientist, I think what you find is the more you find out the more you realize we don't know. And and I always think that it's surprising that more people don't aren't troubled, you know, every night. I think about all these things we interact with all the time that we have no idea how they work time, consciousness, gravity, life we can't I mean these are all the fundamental things of nature.

Speaker 1  01:27:59
I think the way we

Speaker 2  01:28:01
don't really know what they are

Speaker 1  01:28:03
to live life. We pin certain assumptions on them and kind of treat our assumptions as if they're a fact that allows us to sort of

Speaker 2  01:28:12
box them off somehow.

Speaker 1  01:28:13
Box them off. But the reality is when you think of time, you should remind yourself, you should put it off, take it off the shelf and realize like no, we have a bunch of assumptions. There's still a lot of there's even not a lot of debate. There's a lot of uncertainty about exactly what is time. Uh is there an era of time? You know, there's there's a lot of fun about the questions that you can't just make assumptions about and maybe ai allows you to um not put anything on the shelf. Yeah, not make any hard assumptions and really open it up and see what

Speaker 2  01:28:48
exactly. I think we should be truly open minded about that. And exactly that not be dogmatic to a particular theory. Um It'll also allow us to build better tools, experimental tools eventually, that can then test certain theories that may not be testable today about things about like what we spoke about the beginning about the computational nature of the universe. How one might if that was true. How one might go about testing that, right? And and how much, you know, there are people who have conjectured people like Scott Aaronson and others about, you know, how much information can a specific plank unit of space and time contain. Right? So one might be able to think about testing those ideas if you had um Ai helping you build some new, exquisite experimental tools. This is what I imagine that you know many decades from now we'll be able to do

Speaker 1  01:29:40
and what kind of questions can be answered to running a simulation of them. So there's a bunch of physics simulations you can imagine that could be run in a some kind of efficient way much like you're doing in the quantum simulation work and perhaps even the origin of life. So figuring out how going even back before the work of alpha fold begins of how this whole whole thing um emerges from Iraq from a static thing. What what do you do you think AI will allow us to, is that something you have your eye on is trying to understand the origin of life first of all yourself. What do you think? Um how the heck did life originate on earth?

Speaker 2  01:30:24
Yeah, well maybe we will come to that in a second but I think the ultimate use of AI is to kind of use it to accelerate science to the maximum. So I think of it a little bit like the tree of all knowledge. If you imagine that's all the knowledge there is in the universe to attain. And we sort of barely scratched the surface of that so far even though we've we've done pretty well since the enlightenment right as humanity and I think AI will turbocharge all of that like we've seen with alpha fold and I want to explore as much of that tree of knowledge as it's possible to do. And and I think that involves ai helping us with with with understanding or finding patterns, but also potentially designing and building new tools, experimental tools. So I think that's all uh and and also running simulations and learning simulations, all of that we're already we're sort of doing at a at a at a you know, baby steps level here. But I can imagine that in in in the decades to come as you know, what's the full flourishing of that line of thinking. It's going to be truly incredible. I would say

Speaker 1  01:31:31
I visualized this tree of knowledge, something tells me that that knowledge tree of knowledge for humans is much smaller in the set of all possible trees of knowledge, it's actually quite small given our cognitive limitations, um limited cognitive capabilities that even with the tools we build, we still won't be able to understand a lot of things. And that's perhaps what non human systems might be able to reach further, not just as tools, but in themselves, understanding something that they can bring back.

Speaker 2  01:32:04
Yeah, it could well be. So I mean there's so many things that the sort of encapsulated in what you just said there. I think first of all um there's there's two different things that's like, what do we understand today? What could the human mind understand and what is the totality of what is there to be understood. Right? And so there's three concentric, you know, you can think of them as three large and larger trees or exploring more branches of that tree. And I think with ai we're going to explore that whole lot now. The question is is, you know, if you think about what is the totality of what could be understood, um there may be some fundamental physics reasons why certain things can't be understood, like what's outside the simulation or outside the universe, maybe it's not understandable from within the universe. So that there may be some hard constraints like that, you know, it

Speaker 1  01:32:50
could be smaller constraints like we think of space time as fundamental to our human brains are really used to this idea of a three dimensional world with time maybe,

Speaker 2  01:33:02
But our tools could go beyond that, they wouldn't have that limitation necessarily. They could think in 11 dimensions, 12 dimensions, whatever is needed, but we could still maybe understand that in several different ways. The example I always give is um when I, you know, played Garry Kasparov for speed chess or we've talked about chess and these kind of things um you know, he if you if you if you're reasonably good at chess, you can you can't come up with the move. Gary comes up with in his move, but he can explain it to you

Speaker 1  01:33:29
and you can understand you

Speaker 2  01:33:30
can understand post hoc the reasoning. So, so I think there's a there's an even further level of like, well maybe you couldn't have invented that thing, but but using that, going back to using language again, perhaps you can understand and appreciate that same way that you can appreciate, you know, vivaldi or Mozart something without you can appreciate the beauty of that, without being able to construct it yourself, right? Invent the music yourself. So, I think we see this in all forms of life, so it'll be that times, you know, a million. But it would you can imagine also one sign of intelligence is the ability to explain things clearly and simply write, you know, people will find another. One of my all time heroes used to say that, right, if you can't, you know, if you can explain it something simply, then that's that's the best sign, a complex topic simply, then that's one of the best signs of understanding it. So I can

Speaker 1  01:34:17
see myself talking trash in the eye system in that way, it gets frustrated how dumb I am. And trying to explain something to me, it was like, well that means you're not intelligent because if you were intelligent, you'd be able to explain it simply.

Speaker 2  01:34:30
Yeah, of course, you know, there's there's also the other option, of course we could enhance ourselves and with our devices we we are already sort of symbiotic with our compute devices, right with our phones and other things and, you know, this stuff like neuralink and accept a, that could be, could could advance that further. Um, so I think there's lots of lots of really amazing possibilities that I could foresee from here.

Speaker 1  01:34:51
Well, let me ask you some wild questions. So out there looking for friends, do you think there's a lot of alien civilizations out there?

Speaker 2  01:34:59
So I guess this also goes back to your origin of life question too, because I think that that's key. Um, my personal opinion looking at all this and, and you know, it's one of my hobbies physics I guess. So, so I I, you know, it's it's something I think about a lot and talk to a lot of experts on and and and and read a lot of books on. And I think my feeling currently is that we are alone. I think that's the most likely scenario given what, what evidence we have. So, and the reasoning is, I think that, you know, we've tried since things like Seti program and I guess since the dawning of the space age, we've, you know, had telescopes, open radio telescopes and other things. And if you think about, um, and tried to detect signals now, if you think about the evolution of humans on earth, we could have easily been a million years ahead of our time now or million years behind right easily with just some slightly different quirk thing happening hundreds of thousands years ago. You know, things could have been slightly different if the Bt would hit the dinosaurs a million years earlier, maybe things would have evolved will be a million years ahead of where we are now. So what that means is if you imagine where humanity will be in a few 100 years, let alone a million years, especially if we hopefully um you know, solve things like climate change and other things and we continue to flourish um and we build things like ai and we do space traveling and all of the stuff that that that humans have dreamed of for forever, right? And sci fi has talked about forever. Um we will be spreading across the stars, right? And von neumann famously calculated, you know, it would only take about a million years if you send out von neumann probes to the nearest, you know, the nearest other solar systems and and then they built all they did was build two more versions themselves and sent those two out to the next nearest systems, you know, within a million years, I think you would have one of these probes in every system in the galaxy, so it's not actually in cosmological time, that's actually very short amount of time.

So, and and you know, people like Dyson have thought about constructing Dyson spheres around stars to collect all the energy coming out of the star, you know, that there would be constructions like that would be visible across space, um probably even across the galaxy. So, and then, you know, if you think about all of our radio television emissions have gone out since Since the 30s and 40s, um imagine a million years of that and now hundreds of civilizations doing that when we opened our years at that point we got technologically sophisticated enough in the space age, we should have heard a cacophony of voices, should have joined that cacophony of voices and what we did. We open our ears and we heard nothing. And many people who argue that there are aliens would say, well we haven't really done exhaustive search yet and maybe we're looking in the wrong bands and and we've got the wrong devices and we wouldn't notice what an alien form was likely to be so different to what we're used to. But you know, I'm not, I don't really buy that that it shouldn't be as difficult as that. Like I think we've searched enough

Speaker 1  01:38:01
everywhere.

Speaker 2  01:38:01
It was, it should be everywhere. We should see Dyson sphere's being put up, sons blinking in and out. You know, there should be a lot of evidence for those things. And then there are other people who argue, well the sort of Safari view of like, well we're a primitive species still were not spacefaring and and and and we're, you know, there's some kind of global like universal rule not to interfere your star trek rule, but like look, look, we can't even coordinate humans to deal with climate change and we're one species. What is the chance that of all of these different human civilization? You know, alien civilizations, they would have the same priorities and and and and agree across, you know, these kind of matters. And even if that was true and we were in some sort of safari for our own good. To me, that's not much different from the simulation hypothesis. Because what does it mean? The simulation hypothesis, I think in its most fundamental level it means what we're seeing is not quite reality, right? It's something there's something more deeper underlying it. Maybe computational now if we were in a if we were in a sort of safari park and everything we were seeing was a hologram and it was projected by the aliens or whatever.

That to me is not much different than thinking we're inside of another universe because we still can't see true reality.

Speaker 1  01:39:09
I mean, there's other explanations. It could be that the way they're communicating is just fundamentally different. That we're too dumb to understand. The much better methods of communication that have It could be I mean, I mean it's silly to say, but our own thoughts could be the methods by which they're communicating like the place from which our ideas, writers talk about this, like the muse the it sounds like very kind of uh wild, but it could be thoughts, it could be some interactions with our mind that we think are originating from us is actually something that is coming from other life forms elsewhere. Consciousness itself might be that

Speaker 2  01:39:50
it could be, but I don't see any sensible argument to that. Why why would all of the alien species? Some of them will be more primitive. They would be close to our level. You know, there there should be a whole sort of normal distribution of these

Speaker 1  01:40:04
things, right? Some would

Speaker 2  01:40:04
be aggressive, some would be, you know, curious others would be very stoical and philosophical because you know, maybe there are a million years older than us, but it's not. It shouldn't be like, I mean 11 alien civilization might be like that, communicating thoughts and others, but I don't see why, you know, potentially the hundreds there should be would be uniform in this way. It

Speaker 1  01:40:26
could be a violent dictatorship that the people, the alien civilizations that become successful become gain the ability to be destructive in order of magnitude more destructive. Um but of course the sad thought, wow, either humans are very special. We took a lot of leaps that arrived at what it means to be human. Um there's a question there which was the hardest, which was the most special. But also if others have reached this level and maybe many others have reached this level. The great filter that prevented them from going farther to becoming a multi planetary species are reaching out into the stars and those are really important questions for us whether um whether there's other alien civilizations that there are not, this is very useful for us to think about. If we destroy ourselves, how will we do it? And how easy is it to do?

Speaker 2  01:41:28
Yeah. Well, you know, these are big questions and I've thought about this a lot. But the interesting thing is that if we're if we're alone, that's somewhat comforting from the great filter perspective, because it probably means the great filters were passed us. I'm pretty sure they are. So that by going back to your origin of life question there are some incredible things that no one knows how happened. Like obviously the first life form from chemical soup. That seems pretty hard. But I would guess the multicellular, I wouldn't be that surprised if we saw single single cell sort of life forms elsewhere, bacteria type things. But multicellular life seems incredibly hard. That step of, you know, capturing mitochondria and then sort of using that as part of yourself, You know, when you've just eaten it,

Speaker 1  01:42:10
would you say that's the biggest, the most like if you had to choose one sort of hitchhiker's Guide to the galaxy one sentence summary of like, oh those clever creatures did this. That would be the multiple. I

Speaker 2  01:42:24
think that's probably the one that that's the biggest, I mean there's a great book called the 10 grand and great inventions of evolution by Nick Lane and he speculates on 10, 10 of these, you know, what could be great filters. Um, I think that's one, I think the the advent of of intelligence and and conscious intelligence and in order to, you know, to us to be able to do science and things like that is huge as well. I mean, there's only evolved once, as far as, you know, in in in earth history. So that would be a later candidate. But there's certainly for the early candidates. I think multicellular life forms is huge

Speaker 1  01:42:57
by the way. What it's interesting to ask you if you can hypothesize about what is the origin of intelligence? Is it that we started

Speaker 2  01:43:07
cooking

Speaker 1  01:43:07
meat over fire. Is it that we somehow figured out that we could be very powerful when we started collaborating. So cooperation between um our ancestors so that we can overthrow the alpha male. What is it? Richard, I talked to Richard Random who thinks we're all just beta males who figured out how to collaborate to defeat the one, the dictator, the authoritarian alpha male um, that control the tribe. Um, is there another explanation? Was there 2001 type of monolith that came down to earth?

Speaker 2  01:43:41
Well, I think, I think all of those things you suggested a good candidates fire and and and and cooking, Right? So that's clearly important for energy. You know, energy efficiency cooking our meat and then and then being able to to be more efficient about eating it and getting a consuming the energy. Um, I think that's huge and then utilizing fire and tools, I think you're right about the tribal cooperation aspects and probably language is part of that because probably that's what allowed us to out compete neanderthals and, and and perhaps less cooperative species. So, um, so that may be the case tool making spears axes. I think that let us, I mean, I think it's pretty clear now that humans were responsible for a lot of the extinctions of megafauna, especially in in in the Americas when humans arrived. So you can imagine once you discover tool usage, how powerful that would have been and how scary for animals. So I think all of those could have been explanations for it. You know, the interesting thing is that it's a bit like general intelligence too is it's very costly to begin with, to have a brain and especially a general purpose brain rather than a special purpose one because the amount of energy our brains use, I think it's like 20% of the body's energy and it's it's massive. And then you're thinking chest, One of the funny things that we used to say is it's as much as A racing driver uses for a whole Formula one race, just playing a game of, you know, serious, high level chess, which you know, you wouldn't think just sitting there because the brain is using so much energy. So in order for an animal, an organism to justify that there has to be a huge payoff? And the problem with with half a brain or half intelligence, satanic of you know of like a monkey brain.

It's it's not clear you can justify that evolutionary until you get to the human level brain. And so but how do you how do you do that jump? It's very difficult, which is why I think it's only been done once from the sort of specialized brains that you see in animals to this sort of general purpose chewing powerful brains that humans have. Um And which allows us to invent the modern modern world. Um And you know, it takes a lot to to cross that barrier. And I think we've seen the same with Ai systems, which is that maybe until very recently it's always been easier to craft a specific solution to a problem like chess than it has been to build a general learning system that can potentially do many things because initially that system will be way worse than less efficient than the specialist system.

Speaker 1  01:46:07
So one of the interesting corks of the human mind of this evolved system is that it appears to be conscious this thing that we don't quite understand, but it seems very um very special ability to have a subjective experience that it feels like something uh to eat a cookie the deliciousness of it or see a color and that kind of stuff. Do you think in order to solve intelligence? We also need to solve consciousness along the way. Do you think A. G. I. Systems need to have consciousness in order to b truly intelligent?

Speaker 2  01:46:43
Yeah we thought about this a lot actually and I think that my guess is that consciousness and intelligence are double dis sociable. So you can have one without the other both ways. And I think you can see that with consciousness in that I think some animals pets if you have a pet dog or something like that you can see some of the higher animals and dolphins. Things like that are have self awareness and a very sociable um seem to dream. Um You know those kinds of a lot of the trades one would regard as being kind of conscious and self aware. Um And but yet they're not that smart. Right? So they're not that intelligent. Bye bye. Say I. Q. Standards or something like

Speaker 1  01:47:24
That. It's also possible that our understanding of intelligence is flawed. Like putting an I. Q2. It may be the thing that a dog can do is actually gone very far along the path of intelligence and we humans are just able to play chess and maybe write poems

Speaker 2  01:47:40
right? But if we go back to the idea of A. G. I. And general intelligence, you know dogs are very specialist right? Most animals are pretty specialist. They can be amazing at what they do but they're like kind of elite sports sports people or something, right? So they extremely well because the entire brain is optimized.

Speaker 1  01:47:56
They have somehow convinced the entirety of the human population to feed them and service them. So in some way they're controlling. Yes,

Speaker 2  01:48:02
exactly. Where we co evolved to some crazy degree, right? Including the way the dogs, you know, even even wag their tails and twitch their noses, right? We find we find inexorably cute. Um but I think you can also see intelligence on the other side. So systems like artificial systems that are amazingly smart at certain things, like maybe playing go and chess and other things, but they don't feel at all in any shape or form conscious in the way that, you know, you do to me or I do to you. And and I think actually building Ai is these intelligent constructs is one of the best ways to explore the mystery of consciousness to break it down because we're going to have devices that are pretty smart at certain things or capable of certain things, but potentially won't have any semblance of self awareness or other things. And in fact I would advocate if there's a choice building systems in the first place, ai systems that are not conscious to begin with are just tools until we understand them better and the capabilities better.

Speaker 1  01:49:09
So on that topic just not as the ceo of deepmind. Um just as a human being, let me ask you about this one particular anecdotal evidence of the google engineer who made a comment or believed that there's some aspect of a language model, the lambda language model that exhibited sentience. So you said you believe there might be a responsibility to build systems that are not essential and this experience of a particular engineer, I think I'd love to get your general opinion on this kind of thing, but I think it will happen more and more and more, which not one engineers, but when when people out there that don't have an engineering background start interacting with increasingly intelligent systems, we anthropomorphize them, they start to have deep impactful um interactions with us in a way that we miss them when they're gone and we sure as heck feel like they're living entities, self aware entities and maybe even we project sentience onto them. So what's your thought about this particular system was have you ever met a language model that's sentient? No.

Speaker 2  01:50:21
What

Speaker 1  01:50:22
do you make of the case of when you kind of feel that there's some elements of sentience to this system?

Speaker 2  01:50:28
Yeah, so this is you know, an interesting question and obviously a very fundamental one. So the first thing to say is I think that none of the systems we have today, I would say even have one iota of semblance of consciousness or sentience, that's my personal feeling, interacting with them every day. So I think this way premature to be discussing what that engineer talked about. I preach I think at the moment it's more projection over the way our own minds work, which is to see uh sort of purpose and direction in almost anything that we, you know, our brains are trained to interpret uh agency basically and things even in inanimate things sometimes. And of course with a language system because language is so fundamental to intelligence, that's going to be easy for us to anthropomorphize that. Um I mean back in the day, even the first, you know, the dumbest sort of template chatbots ever Eliza. And and and and the yoke of the original chatbots back in the sixties fooled some people under certain circumstances, right, pretended to be a psychologist. So just basically rabbit back to you the same question you asked it back to you. Um and some people believe that. So I don't think we can, this is why I think the turing test is a little bit flawed as a formal test because it depends on the Sophistication of the of the judge whether or not they are qualified to make that distinction. So I think we should talk to, you know, the top philosophers about this. People like Daniel Dennett and David Chalmers and others who obviously thought deeply about consciousness.

Of course consciousness itself hasn't been. Well there's no agreed definition if I was to, you know, speculate about that, you know, I kind of the definite the working definition I like is it's the way information feels when you know it gets processed. I think maybe max tech Mark came up with that, I like that idea and if it helps us get towards any more operational thing but but it's it's it's I think it's a nice way of viewing it. Um I think we can obviously see from neuroscience certain prerequisites that required like self awareness I think is necessary but not sufficient component, this idea of a self and other and set of coherent preferences that the coherent over time. You know, these things are maybe memory. Um These things are probably needed for a sentient or conscious being. Um but but the reason that the difficult thing I think for us when we get and I think this is a really interesting philosophical debate is when we get closer to A G. I. And and you know, and and much more powerful systems than we have today. How are we going to make this judgment? And one way, which is the turing test is sort of a behavioral judgment. Is is the system exhibiting all the behaviors that human sentient or sentient being would would would exhibit is it answering the right questions?

Is it saying the right things? Is it indistinguishable from a human? Um and so on. But I think there's a second thing that makes us as humans regard each other as sentient, right? Why do we? Why do we think this? And I debated this with Daniel Dennett and I think there's a second reason that's often overlooked, which is that we're running on the same substrate, right? So if we're exhibiting the same behavior more or less as humans and we're running on the same, you know, carbon based biological substrate, the squishy, you know, a few pounds of flesh in our skulls, then the most parsimonious, I think explanation is that you're feeling the same thing as I'm feeling, right? But we will never have that second part, the substrate equivalence with the machine, Right? So we will have to only judge based on the behavior. And I think the substrate equivalence is a critical part of why we make assumptions that we're conscious and in fact, even with with animals, high level animals, why we think they might be because they're exhibiting some of the behaviors we would expect from a sentient animal. And we know they're made of the same things biological neurons.

Speaker 1  01:54:14
So we're going to have to come up with explanations or models of the gap between substrate differences between machines and humans Did to get anywhere beyond the behavioral. But to me, the practical question is very interesting and very important when you have millions, perhaps billions of people believing that you have a sentient ai believing what that google engineer believed, which I just see as an obvious, very near term future thing? Certainly on the path to A g I How does that change the world? What's the responsibility of the AI system to help those millions of people? Um and also what's the ethical thing? Because you can you can make a lot of people happy by creating a meaningful deep experience with the system that's faking it before it makes it. And I don't know are we the right who is to say what's the right thing to do? Should a I always be tools like shy, why are we constraining? I ask those bi tools as opposed to friends.

Speaker 2  01:55:23
Yeah, I think well, I mean, you know, you know, fantastic questions and and also critical ones. And we've been thinking about this since the start of deepmind and before that because we plan for success and you know how how you you know, however Remote that looked like back in 2010. And we've always had sort of these ethical considerations as fundamental at deepmind. Um And my current thinking on the language models is and and large models is they're not ready. We don't understand them well enough yet. Um and you know, in terms of analysis tools and and guardrails, what they can and can't do and so on to deploy them at scale because I think, you know, there are big still ethical questions like should an AI system always announce that it is an AI system to begin with? Probably yes. Um What what do you do about answering those philosophical questions about the feelings people may have about AI systems perhaps incorrectly attributed. So I think there's a whole bunch of research that needs to be done first um, to responsibly before, you know, you can responsibly deploy these systems at scale. That will be at least be my um current position over time. I'm very confident we'll have those tools like interpret ability questions, um, and analysis questions and then with the ethical quandary, you know, I think there it's important to look beyond just science. That's why I think philosophy, social sciences, even theology, other things like that come into it.

Where um what, you know, arts and humanities, what what does it mean to be human and the spirit of being human and to enhance that and and the human condition. Right? And allow us to experience things we could never experience before and improve the overall human condition and humanity overall, you know, get radical abundance, solve many scientific problems, solved disease. So this is the area I think this is the amazing area I think we're heading into if we do it right. Um, but we've got to be careful. We've already seen with things like social media, how dual use technologies can be misused by firstly by by by bad, you know bad actors or naive actors or crazy actors. Right? So there's that set of just the common or garden use misuse of existing dual use technology and then of course there's an additional thing that has to be overcome with a either eventually it may have its own agency. So it could be good or bad in and of itself. So I think these questions have to be approached very carefully. Um, using the scientific method I would say in terms of hypothesis generation and careful control testing, not live A B testing out in the world because with powerful technologies like ai if something goes wrong, it may cause you know, a lot of harm before you can fix it. It's not like a, you know, an imaging app or game where you know that if something goes wrong, it's relatively easy to fix and and the harm is relatively small.

So I think it comes with, you know, the the the usual cliche of like with a lot of power comes a lot of responsibility and I think that's the case here with things like ai given the enormous opportunity in front of us and I think we need a lot of voices uh, and as many inputs into things like the design of the systems and the values they should have and what goals should they be put to. Um, I think as wide a group of voices as possible beyond just the technologists is needed to input into that and to have a say in that, especially when it comes to deployment of these systems, which is when the rubber really hits the road, it really affects the general person in the street rather than fundamental research and that's why I say, I think as a first step it would be better if we have the choice to build these systems as tools to give. And I'm not saying that it should never, they should never go beyond tools because of course the potential is there um for it to go way beyond just tools. But I think that would be a good first step in order for us to you know, allow us to carefully experiment, understand what these things can do.

Speaker 1  01:59:16
So the leap between tool to sentient entity being as long as you take very carefully. Let me ask a dark personal question.

Speaker 2  01:59:26
So

Speaker 1  01:59:27
you're one of the most brilliant people in the community also one of the most kind and uh if I may say sort of loved people in the community that said, creation of a super intelligent Ai system would be one of the most powerful things in the world, tools or otherwise. And again as the old saying goes, power corrupts and absolute power corrupts. Absolutely. You are likely to be one of the people, I would say probably the most likely person to be in the control of such a system. Do you think about the corrupting nature of power when you talk about these kinds of systems that um as all dictators and people have caused atrocities in the past, always think they're doing good, but they don't do good because the power's polluted their mind about what is good and what is evil do you think about this stuff or we just focus on language model?

Speaker 2  02:00:32
No, I think about them all the time and you know, I think what are the defenses against that? I think one thing is to remain very grounded and sort of humble no matter what you do or achieve, and I try to do that, I might, you know, my best friends are still my set of friends from my undergraduate Cambridge days. My families, you know, and and and friends are very important. Um I've always, I think trying to be a multidisciplinary person, it helps to keep you humble because no matter how good you are at one topic, someone will be better than you at that. And and always re learning a new topic again from scratch is a new field is very humbling, right? So for me that's been Biology over the last five years, you know, huge area topic and and and it's been and I just love doing that, but it helps to keep you grounded. Like it keeps you open minded. Um and uh and then the other important thing is to have a really group, amazing set of people around you at your company or your organization who are also very ethical and grounded themselves and help to keep you that way. Uh and then ultimately, just to answer your question, I hope we're going to be a big part of of birthing Ai and that being the greatest benefit to humanity of any tool or technology ever. And and getting us into a world of radical abundance and curing diseases and and and and solving many of the big challenges we have in front of us and then ultimately help the ultimate flourishing of humanity to travel the stars and find those aliens if they are there, and if they're not there, find out why they're not there, what is going on here in the universe. Um this is all to come and and that's what I've always dreamed about. Um but I don't think, I think ai is too big an idea, it's not going to be uh there'll be a certain set of pioneers who get there first.

I hope we're in the vanguard so we can influence how that goes. And I think it matters who builds which which cultures they come from and what values they have. The builders of Ai systems, because I think even though the Ai system is going to learn for itself, most of its knowledge, there'll be a residue in the system of the culture and the values of the creators of the system. Um and there's interesting questions to to discuss about that geopolitically, you know, different cultures were in a more fragmented world than ever. Unfortunately, I think in terms of global cooperation, we see that in things like climate, where we can't seem to get our act together globally to cooperate on these pressing matters. I hope that will change over time. Perhaps, you know, if we get to an era of radical abundance, we don't have to be so competitive anymore. Maybe we can be more correct cooperative if resources aren't so scarce.

Speaker 1  02:03:00
It's true that in terms of power corrupting and leading to destructive things, it seems that some of the atrocities of the past happened when there's a significant constraint on resources.

Speaker 2  02:03:12
I think that's the first thing, I don't think that's enough. I think scarcity is one thing that's led to competition, you know, sort of zero sum game thinking I would like us to all be in a positive sum world. And I think for that you have to remove scarcity. I don't think that's enough, unfortunately to get well peace because there's also other corrupting things like wanting power over people and this kind of stuff, which is not necessarily satisfied by by just abundance, but I think it will help. Um and I think, but I think ultimately Ai is not going to be run by any one person or one organization. I think it should belong to the world, belong to humanity. Um and I think maybe many, there'll be many ways this will happen and ultimately um everybody should have a say in that.

Speaker 1  02:03:53
Do you have advice for young people in high school and college, maybe um if they're interested in ai or interested in having a a big impact in the world, what they should do to have a career, they can be proud of her to have a life that can be proud of.

Speaker 2  02:04:10
I love giving talks to the next generation. What I say to them is actually two things I think the most important things to learn about and to find out about when you're when you're young is what are your true passions is first of all as two things. One is find your true passions and I think you can do that by the way to do that is to explore as many things as possible when you're young and you have the time and you and you can take those risks. Um I would also encourage people to look at the, finding the connections between things in a unique way. I think that's a really great way to find a passion. Second thing I would say advises know yourself so spend a lot of time understanding how you work best, like what are the optimal times to work? What are the optimal ways that you study um what are your how do you deal with pressure? Um sort of test yourself in various scenarios and try and improve your weaknesses, but also find out what your unique skills and strengths are and then hone those. So then that's what will be your super value in the world later on and if you can then combine those two things and find passions that you're genuinely excited about the intersect with what your unique strong skills are, then you're you know, you're onto something incredible and and you know, I think you can make a huge difference in the world.

Speaker 1  02:05:26
So let me ask about knowing yourself. This is fun. This is fun, quick questions about day in the life, The perfect day, the perfect productive day in the life of Dennis's house. Maybe uh maybe these days your there's a lot involved. So maybe slightly younger nemesis when you could focus on a single project maybe. Um How early do you wake up? Are you night owl? Do you wake up early in the morning? What are some interesting habits, How many dozens of cups of coffee do you drink a day? What's the computer um that you use? What's the setup? How many screens, what kind of keyboard we're talking imax vim or we're talking something more modern?

A bunch of those questions. So maybe a day in the life, what what's the perfect day involved?

Speaker 2  02:06:14
Well, these days it's quite different from say 10, 20 years ago, back, 10, 20 years ago, it would have been, you know, a whole day of research, individual research or programming, doing some experiment, neuroscience, computer science experiment, reading lots of research papers. Uh and then perhaps at nighttime, you know um reading science fiction books or or playing some games,

Speaker 1  02:06:41
but lots of focus. So like deep focused work on whether it's uh programming or reading research papers. Yes,

Speaker 2  02:06:48
So that would be a lot of deep, you know, focus work these days for the last sort of I guess, you know, 5 to 10 years, I've actually got quite a structure that works very well for me now, which is that I'm a night complete night owl always have been. So I optimize for that. So, you know, I get, you know, I basically do a normal day's work, get into work about 11 o'clock and sort of do work to about seven in the office. Uh And I will arrange back to back meetings for the entire time of that and with as many meet as many people as possible. So that's my collaboration management part of the day. Then I go home spend time with the family and friends, have dinner, relax a little bit and then I start a second day of work. I call it my second day of work around 10 p.m. 11 P. M. And that's the time till about the small hours of the morning, 45 in the morning where I will do my thinking and reading a research, writing research papers. Um sadly I don't have time to code anymore, but it's it's not efficient to do that these days given the amount of time I have. Um But that's when I do, you know maybe do the long kind of stretches of of thinking and planning and then probably, you know, using using email, other things.

I would set, I would fire off a lot of things to my teams to to deal with the next morning for actually thinking about this overnight, we should go for this project or arrange this meeting the next day.

Speaker 1  02:08:10
When you think through a problem, you're talking about a sheet of paper or is there some structure?

Speaker 2  02:08:15
I still like pencil and paper best for working out things, but these days it's just so efficient to read research papers just on the screen. I still often print them out actually. I still prefer to mark out things and I find it goes into the brain quick better and sticks in the brain better when you're you're you're still using physical pen and pencil and paper.

Speaker 1  02:08:35
So you take notes. I

Speaker 2  02:08:36
have lots of notes, electronic ones and also whole stacks of notebooks that that that I use at home. Yeah.

Speaker 1  02:08:43
Some of these most challenging next steps, for example stuff. None of us know about that. You're working on your thinking there's some deep thinking required there, right? Like what what is the right problem? What is the right approach? Because there you're gonna have to invest a huge amount of time for the whole team. They're going to have to pursue this thing. What's the right way to do? It is RL gonna work here or not. Um What's the right thing to try, what's the right benchmark to you. We need to construct the benchmark from scratch all those kinds of things.

Speaker 2  02:09:14
So I think of all those kind of things in the night time phase but also much more. I find I've always found the quiet hours of the morning um when everyone's asleep it's super quiet outside. Um I love that time, the golden hours like between like one and three in the morning. Um Put some music on, some inspiring music on and then I think these deep thoughts. So that's when I would read you know my philosophy books and Spinoza, my you know recent favorite can all these things I read about a great a scientist of history, how they did things, how they thought things. So that's when you do all your create, that's when I do all my creative thinking and it's good I think I think people recommend, you know you do your your your sort of creative thinking in one block and the way I organize the day that way I don't get interrupted because obviously no one else is up at those times. So I can I can go you know as I can sort of get super deep and super into flow. The other nice thing about doing it night time wise is if I'm really onto something or I've got really deep into something I can choose to extend it and I'll go into six in the morning whatever and then I'll just pay for it the next day. I'll be a bit tired and I won't be my best, but that's fine. I can decide looking at my schedule the next day and given where I'm at with this particular thought or creative idea that I'm going to pay that cost the next day. So, so I think that's that's more flexible than morning. People who do that.

You know, they get up at four in the morning, they can also do those golden hours then, but then their start of their scheduled day starts at breakfast, you know, am whatever they have their first meeting. And then it's hard you have to reschedule a day if you're in flow. Yeah,

Speaker 1  02:10:55
that could be a special threat of thoughts that the you're too passionate about this is where some of the greatest ideas could potentially comments when you just lose yourself later and for the meetings. I mean, you're loading in really hard problems in a very short amount of time. So you have to do some kind of first principles thinking here. It's like, what's the problem? What's the state of things? What's the right next step?

Speaker 2  02:11:18
You have to get really good at context switching, which is one of the hardest things because especially as we do so many things, if you include all the scientific things, we do scientific fields were working in these are our entire field, you know, complex fields in themselves and you you you have to sort of keep up two abreast of that. But I enjoy it. I've always been a sort of generalist in a way and that's actually what happened with my games career after chess. I I one of the reasons I stopped playing chess because I got into computers, but also I started realizing there were many other great games out there to play too. So I've always been that way inclined, multidisciplinary and there's too many interesting things in the world to spend all your time just on one thing.

Speaker 1  02:11:57
So you mentioned Spinoza got asked the big, ridiculously big question about life, what do you think is the meaning of this whole thing? Why are we humans here? You've already mentioned that perhaps the universe created

Speaker 2  02:12:11
us, Is

Speaker 1  02:12:12
that why you think we're here to understand how the universe?

Speaker 2  02:12:16
Yeah, I think my answer to that would be, and at least the life I'm living is to gain and to gain and understand the knowledge, you know, to gain knowledge and understand the universe. That's what I think I can't see any higher purpose than that. If you think back to the classical Greeks, you know, the virtue of gaining knowledge, it's I think it's the it's one of the few true virtues is to understand um the world around us in the context and humanity better and and I think if you do that you become more compassionate and more understanding yourself and and more tolerant and all these. I think all these other things may flow from that and to me, you know, understanding the nature of reality that is the biggest question, what is going on here is sometimes the colloquial way I say, what is really going on here? It's so mysterious. I feel like we're in some huge puzzle and and it's but the world is also seems to be the universe seems to be structured in a way, you know, why is it structured in a way that science is even possible that you know, methods that the scientific method works. Things are repeatable. Um it feels like it's almost structured in a way to be conducive to gaining knowledge. So I feel like and you know, why should computers be even possible? Isn't that amazing that computational electronic devices can can can can be possible. And they're made of sand are most common element that we have, you know, silicon that on the on the earth's crust that could be made of diamond or something that we would have only had one computer. Right?

So it's a lot of things are kind of slightly suspicious to me.

Speaker 1  02:13:42
It sure as heck sounds this puzzle sure as heck. Sounds like something we talked about earlier, what it takes to to design a game that's really fun to play for prolonged periods of time. And it does seem like this puzzle like you mentioned, the more you learn about it, the more you realize how little you know. So it humbles you but excites you by the possibility of learning more one heck of a one heck of a puzzle we got going on here. Um So like I mentioned of all the people in the world, you're very likely to be the one who creates the A. G. I. System. Um that achieves human level intelligence that goes beyond it. So if you got a chance and very well you could be the person that goes into the room with the system and have a conversation. Maybe you only get to ask one question. If you do, what question would you ask her?

Speaker 2  02:14:35
I would probably ask um what is the true nature of reality? I think that's the question. I don't if I don't understand the answer because maybe it would be 42 or something like that. But that's the question I would ask.

Speaker 1  02:14:47
Yeah. And then there'll be a deep sigh from the systems like All right. How do I explain to this

Speaker 2  02:14:52
human? All

Speaker 1  02:14:53
right, let me I don't have time to explain. Maybe I'll draw you a picture that it is. I mean how do you even begin um to answer that question?

Speaker 2  02:15:07
Well I think it would um

Speaker 1  02:15:08
what would what would you think the answer could possibly look like?

Speaker 2  02:15:11
I think it could it could start looking like uh more fundamental explanations of physics would be the beginning. You know, more careful specification of that. Taking walking us through by the hand as to what one would do to maybe prove those things out.

Speaker 1  02:15:26
Maybe giving you glimpses of what things you totally missed in the physics of

Speaker 2  02:15:31
today.

Speaker 1  02:15:32
Just here here's glimpses of no like there's a much um a much more elaborate world or a much simpler world or something um a

Speaker 2  02:15:42
much deeper, maybe simpler explanation of things right than the standard model of physics which we know doesn't work but we still keep adding to so um and and that's how I think the beginning of an explanation would look and it would start encompassing many of the mysteries that we have wondered about for thousands of years. Like, you know, consciousness, dreaming, life and gravity, all of these things.

Speaker 1  02:16:04
Giving us glimpses of explanations for those things. Well um David, one of the special human beings in this giant puzzle of ours and it's a huge honor that you would take a pause from the bigger puzzle to solve this small puzzle of a conversation with me today. It's truly an honor and a pleasure. Thank you.

Speaker 2  02:16:22
I really enjoyed it. Thanks lex.

Speaker 1  02:16:25
     
Thanks for listening to this conversation with mrs Hobbs to support this podcast. Please check out our sponsors in the description and now let me leave you with some words from Oscar Dykstra. Computer science is no more about computers than astronomy is about telescopes. Thank you for listening and hope to see you next time