是的，我是克雷格-史密斯，这是我在人工智能[音乐]方面的报道。他是open Ai的共同创始人和首席科学家，也是大型语言模型gpt3及其公共后代chat GPT背后的主要推手之一，我认为说它正在改变世界并不夸张，这并不是Elia第一次改变世界，Jeff Hinton曾说他是Alex的主要推动者，而不是卷积神经网络，其戏剧性的表现在2012年震惊了科学界，掀起了深度学习革命。在这些对话中，他们假设听众有很多知识，主要是因为我不想浪费有限的时间，像伊利亚这样的人解释人或事件的概念，这些概念可以很容易地在谷歌上搜索到，或者我应该说，或者Chachi BT可以为你解释，与埃利奥的对话是在本集之前与Jan lacun的对话，所以如果你没有听过那一集，我鼓励你这样做，同时我希望你喜欢是的，很高兴见到你并与你交谈，我在网上看过你的许多演讲，也读过你的许多论文，你能不能先介绍一下你的背景，我知道你出生在俄罗斯，在那里接受教育，是什么让你对计算机科学感兴趣，如果那是最初的冲动或脑科学神经科学或任何东西，然后我会开始问问题，我可以谈一谈这个。是的，我出生在俄罗斯，在以色列长大，然后在十几岁的时候，我全家移民到了加拿大，我父母说我在很小的时候就对人工智能感兴趣，我也对意识非常感兴趣，我对它感到非常不安，我对能够帮助我更好地理解它的东西感到好奇，人工智能似乎是一个非常好的角度，所以我认为这些是让我开始的一些方法，实际上我很早就开始与杰夫-辛顿合作，那时我17岁。我们搬到了加拿大，我立即能够加入多伦多大学，我真的想做机器学习，因为这似乎是人工智能最重要的方面，在当时是完全不可触及的，但要给一些背景，那是2003年。今天，我们认为计算机可以学习是理所当然的，但在2003年，我们认为计算机不能学习是理所当然的，当时人工智能的最大成就是深蓝的胸部引擎，是的，但在那里，你有这个游戏，你有这个树状搜索，你有这个简单的方法来确定一个位置是否比另一个更好，它真的不觉得这可能适用于现实世界，因为没有学习所以我对学习非常感兴趣，非常幸运的是，杰夫-辛顿是我所在大学的教授，所以我能够找到他，我们几乎马上就开始一起工作。但是智能是如何工作的呢？现在我们有很多想法，它是一个大的神经网络，我们在某种程度上知道它是如何工作的，但是在当时，虽然神经网络已经出现了，但是没有人知道谷歌网络有什么用，所以智能是如何工作的？因为有很多对人工智能的贡献是不真实的，但由于各种原因，我可以知道它们不是真实的，不会有任何结果，我只是认为没有任何作用，人工智能是一个没有希望的领域，所以动机是我可以理解智能是如何工作的，也可以为它做出贡献，所以这是我最初的早期动机，所以这是2003年，几乎正好是20年前，然后亚历克斯说我已经和杰夫谈过，他说，这真的是你的兴奋他说是你对卷积神经网络的突破感到兴奋，导致你申请了imagenet竞赛，而且Alex有编码技能来训练网络，你能不能谈一谈这个问题，我不想在历史上陷入困境，但它很吸引人。如果你在一个足够大的数据集上训练一个大型的深度神经网络，该数据集规定了人们所做的一些复杂的任务，如视觉，但也包括其他任务，你只需训练该神经网络，那么你就一定会成功，其逻辑是非常不可还原的，我们知道人脑可以解决这些任务，并且可以快速解决它们，人脑只是一个具有缓慢神经元的神经网络，所以我们知道一些神经网络可以做得非常好，那么你只需要采取一个因此，你只需要采取一个较小但相关的神经网络，并在数据上对其进行应变，计算机内最好的神经网络将与我们所拥有的执行这一任务的神经网络相关，因此有一个论点，即神经网络、大型和深度神经网络取消了这一任务，此外，我们有工具来训练它，这是杰夫实验室的技术工作的结果，因此你将这两者结合起来，我们可以训练这些神经网络。你需要足够大的数据，如果你训练它，它就会工作得很好，你需要数据，它可以指定解决方案，而imagenet的所有成分都在那里，Alex有这些非常快的卷积内核，imagenet有足够大的数据，有一个真正的机会来做一些完全前所未有的事情，它完全成功了 是的，这就是监督学习和卷积神经坚果 2017年，注意力是你需要的论文出来了，介绍自我注意力和变形金刚，GPT项目是在什么时候开始的，是否有一些关于变形金刚和自我监督学习的直觉？监督下的学习，你能谈谈吗？所以在开放人工智能的背景下，从最早的时候，我们就在探索预测下一件事是你所需要的想法，我们是用当时更有限的神经网络来探索的，但希望是，如果你有一个神经网络，可以预测下一个字，下一个像素，这真的是关于压缩预测是压缩，而预测下一个词不是，让我想想用什么方式来解释，因为有很多事情要做，它们都是相关的，也许我会采取不同的方向，我们确实有兴趣尝试了解预测下一个词能走多远，以及它是否能解决无监督的问题。所以在gpts之前，无监督学习被认为是机器学习的圣杯，现在它刚刚被完全解决，甚至没有人谈论它，但它是一个圣杯，非常神秘，所以我们正在探索这个想法，我真的很兴奋，预测下一个词足够好，就可以让你进行无监督学习，如果但我们的神经网络不能胜任这个任务，我们使用的是循环神经网络，当Transformer出来的时候，简直就是论文出来的第二天，我就明白了，Transformer解决了循环神经网络在学习长期依赖方面的局限性。这是一个技术问题，但是如果我们马上转到变形器上，那么刚开始的GPT工作就会继续下去，然后就像变形器一样，它开始工作得更好，你把它变大，然后你就会意识到继续把它变大，我们就这样做了，这就是最终的GPT3。我只是想问，其实我已经被这段历史所吸引了，但我对它很感兴趣，我想了解大型语言模型或大型模型的问题或缺点，但Rich Sutton一直在写关于扩展和我想说的是，当他发表文章时，我们很高兴看到一些外部人士在思考类似的问题，我们认为这是很有说服力的。但实际上，我认为所阐述的痛苦的教训夸大了它的情况，或者至少我认为人们从它那里得到的启示夸大了它的情况，人们得到的启示是，你做什么来扩大规模并不重要，但这并不完全正确，你必须扩大一些具体的东西，你深度学习的一个伟大突破是，它为我们提供了有史以来第一个有效利用规模并从中获得回报的方法，比如在此之前，人们会把大型计算机集群用于什么呢？但也许有一天我们会发现，在我们扩展的事情上有一些小的转折，它将会更好地扩展，现在有多大的转折，然后当然有了高的好处，它会说它甚至计数，这是一个如此简单的变化，但我认为真正的说法是，你的规模很重要，现在我们只是找到了一个可以扩展的东西，给我们一些回报，大型语言模型的限制说存在的是他们的知识包含在他们训练的语言中，而大多数人类的知识我想每个人都同意是非我不确定诺姆-乔姆斯基是否同意，但在大型语言模型中存在一个问题，据我所知，他们的目标是满足统计学上的一致性提示，他们没有对语言所涉及的现实有一个基本的理解，我问过GBT关于我自己的情况，它承认我是一个记者，我曾在这些不同的报纸工作过，但它一直在谈论我从未获得过的奖项，把这些都读得很好，但没有一个与基本的现实相联系，有没有什么东西所以，在我评论你所问的直接表白之前，我想评论一下问题的前半部分，当然，我认为很难谈论甚至像语言模型的限制或局限性，因为两年前人们自信地谈论他们的局限性，他们是完全不同的。我没有那么大的信心。我还想就问题的一部分发表另一个评论，即这些模型只是学习了统计规律，因此它们并不真正知道世界的本质是什么。花了很多时间在神经网络上，而神经网络在某种程度上是统计学的，比如什么是统计学模型，你只是输入一些参数，比如真正发生了什么，但我认为有一个更好的解释，那就是预测的早期观点是压缩预测也是一种统计学现象，然而为了预测，你最终需要理解产生数据的真正底层过程，才能很好地预测数据，很好地压缩数据，你需要越来越多地了解产生数据的世界，因为我们的生成模型变得特别好，它们会有我所说的令人震惊的理解程度，对世界和它的许多微妙之处有令人震惊的理解，但它不仅仅是世界，它是通过文本的镜头看到的世界，它试图通过在互联网上人类所表达的文本空间上对世界的投影来了解越来越多的世界，但这些文本仍然已经表达了世界，我会给你一个例子，一个最近的例子，我认为这是真的意大利迷人的，所以我们都听说过悉尼生命的另一个自我，我已经看到这个非常有趣的与悉尼的互动，当用户告诉它，它认为谷歌是一个更好的搜索引擎时，悉尼变得好斗和咄咄逼人，现在我们怎么能像什么是一个好的方式来思考这个现象，什么是一个好的语言，什么是什么意思，你可以说，哇，就像它只是预测人们会做什么，人们会做这个，这是真的，但也许我们现在已经达到一个点，在那里，语言的现在让我们来谈谈局限性，的确，这些神经网络确实有产生幻觉的倾向，但这是因为语言模型对于学习世界来说是很好的，但对于产生良好的输出来说就有点不那么好了，这有各种技术原因，如果你认为有用的话，我可以详细说明，但现在来看，我将跳过这第二个技术原因语言模型在学习世界方面要好得多，它可以学习令人难以置信的对存在的思想、概念、人和过程的表述，但它的输出并不像人们所希望的那样好，或者说没有那么好，这就是为什么对于像聊天GPT这样的系统，这是一个语言模型，它有一个额外的强化学习训练过程，我们称之为从人类反馈中强化学习，但要理解这个过程，我们可以说，预训练的过程是训练过程，当你只是训练一个语言模型时，你想学习关于这个世界的一切，然后从人类反馈中强化学习，现在我们关心他们的输出，现在我们说任何时候输出是不适当的，不要再这样做，每次输出没有意义，不要再这样做，它快速运行以产生良好的输出，但现在是输出的水平，这不是在预训练期间的情况。在语言模型的训练过程中，现在是输出的水平，而在幻觉这一点上，它有编造东西的倾向，确实是这样，现在这些神经网络甚至是收费能力，不时地编造东西，这也大大限制了它们的作用，但我很希望，通过简单地改进这个后续的强化学习，从人类反馈的步骤，我们可以直接教它你可以说它真的会学习吗？我的答案是，让我们来看看，这个反馈回路来自公共聊天的GPT界面，如果它告诉我，我想要一个普利策奖，但不幸的是，我没有，我可以告诉它，它是错的，这将训练它或创造一些惩罚或奖励，这样，下次我问它，它会更准确，我们今天做事的方式是，如果我们雇人去教我们的神经网络的行为来教LGBT的行为，现在，他们指定所需行为的方式和精确的方式有点不同，但事实上，你所描述的是教学的方式，就像基本上是正确的教学方式，你只是与它互动，它从你的反应中看到，它推断出哦，这不是你想要的，你对它的输出不满意，所以输出我想和你谈谈Jana Kun在联合嵌入预测架构方面的工作，以及他的想法，即大型语言模型中所缺少的是这种非语言的底层世界模型。我想听听你对这个问题的看法，以及你是否探讨过这个问题，所以我回顾了癌症提案之外的一些想法，它们用不同的语言表达，与目前的Paradigm也许有一些小的差异，但在我看来，这些差异不是很重要，我想详细说明一下。第一个主张是，一个系统最好能有多模式的理解，即它不只是从文本中了解世界，我对此的评论是，多模式的理解确实是可取的，因为你可以从文本中了解世界。我的评论是，多模式理解确实是可取的，因为你对世界了解得更多，你对人们了解得更多，你对他们的状况了解得更多，所以系统将能够理解它应该解决的任务，以及人们和他们想要的东西，我们已经在这方面做了相当多的工作，最明显的是以我们在这方面做了很多工作，最明显的是我们做了两个主要的神经网络，一个叫剪辑，一个叫达利，它们都朝着这个多模态的方向发展，但我也想说，我也不认为情况是二元的，或者说如果你没有视觉，如果你不了解这个世界的视觉或视频，那么事情就不会成功。所以我认为有些东西更容易从图像和图表中学习，但我声称你仍然可以从文字中学习，只是速度更慢。然而，当你看到嵌入时，我需要绕一个小弯来解释嵌入的概念 是的，每个神经网络都通过表示嵌入的高维向量来表示单词句子概念，我们可以做的一件事是，我们可以看这些高维向量，我们可以我们可以看看什么与什么相似，网络是如何看待这个概念的，所以我们可以看看卡路里的嵌入，颜色的嵌入恰好是正确的，你知道，它知道紫色与蓝色比红色更相似，它知道紫色与红色的相似度比橘子低它知道所有这些事情，只是从文字上看，这怎么可能呢？如果你有视觉，颜色之间的区别就会跳到你身上，你会立即感知到它们，而这些文字却要花更长时间，也许你知道如何说话，你已经理解了句法、单词和语法，直到很久以后你才说，哦，这些颜色所以这将是我关于多模态的必要性的观点，我声称它不是必要的，但它绝对是有用的，我认为这是一个很好的方向，我只是没有看到它在这样的斯塔克或索赔中。是预测具有不确定性的高维向量，因此，例如预测图像，该论文提出了一个非常强烈的主张，即这是一个重大的挑战，我们需要使用一种特殊的方法来解决这个问题，但有一点我觉得很惊讶，或者至少是论文中没有承认的，那就是我给你举两个例子，一个是书中的一页，预测书中的下一页，后面可能有很多页，这是一个非常复杂的高维空间，而我们却能很好地处理它，这同样适用于图像。这些自动回归变形器在图像上的工作非常完美，比如说，我们在igpt上做了一些工作，我们只是把变形器应用到像素上，效果非常好，它可以以非常复杂和微妙的方式生成图像，它有非常漂亮和有监督的表征学习，与Dali相同。我相信谷歌今年早些时候在图像生成方面的工作叫 "派对"，我相信他们也采取了类似的方法，所以我认为这篇论文围绕着目前的方法不能处理预测高维分布的问题做出了强烈的评论，我认为他们绝对可以，所以也许这是另一个要告诉我的观点，然后你在谈论将像素转换成矢量，这基本上是将所有东西都变成了语言。矢量就像一串文字，是的，定义语言，但你把它变成了一个序列 是的，一个由什么组成的序列 你可以说，即使对一个人的生命来说，也是一个比特的序列 现在还有其他的东西，人们现在使用的是扩散模式，他们产生这些比特而不是但我认为在某种程度上，这种区别并不重要，我认为在某种程度上，这并不重要，重要的是你可以获得10倍的效率提升，这在实践中是巨大的，但在概念上我认为这并不重要。人类训练师与聊天gbt或大型语言模型一起工作，用强化学习来指导它，但凭直觉，这听起来不像是一个教模型了解其语言底层现实的有效方法，难道就没有一种方法可以将其自动化到yams credit中吗？他说的是用一种算法来教模型了解底层现实，而不需要人去干预。 所以我对这个问题有两个评论，我认为，首先，我对这个问题有不同的看法，所以我不同意这个问题的措辞。训练有素的模型已经知道他们需要知道的关于底层现实的一切，他们已经有了关于语言的知识，也有了关于世界上存在的产生这种语言的过程的大量知识，也许我应该重申这一点，这是一个小切口，但我认为它非常重要，大型生成模型从他们的数据中学习的东西，在这种情况下，大型语言模型关于文本数据的R和产生这些数据的现实世界过程的压缩表示，这意味着不仅是人和关于他们的想法的东西，关于他们的感觉的东西，而且还有关于人们所处的状况和他们之间的互动，一个人可能出现的不同情况，所有这些都是由神经网络表示的压缩过程的一部分，以产生文本，语言模型越好。生成模型越好，保真度越高，它就越能捕捉到这个过程，所以这是我们提出的第一个意见，所以特别是我要说的是，模型已经有了知识，现在是教师大军，正如你所说的那样，的确，当你想建立一个性能尽可能好的系统时，你只是说好吧，比如说如果这个东西有用，就多做一些，但当然，这些教师也在使用这些老师不是自己一个人，他们和我们的工具一起工作，他们非常高效，就像工具在做大部分的工作，但你确实需要有你需要有监督，你需要有人审查行为，因为你想让它最终达到一个非常高的可靠性，但总的来说，我会说我们同时是第二步，在我们把完成的预训练模型训练好的模型，然后我们在上面应用强化学习，确实有很多动力让它尽可能的高效和精确，这样得到的语言模型就会尽可能的表现良好，所以是的，有这些人类老师在教他们一个有理想行为的模型，他们也在使用人工智能辅助，而且他们使用人工智能辅助的方式在不断增加，所以他们自己的效率也在不断增加，也许这将是一个方法所以你的意思是，通过这个过程，模型最终会变得越来越有辨识度，输出越来越准确 是的，这是正确的，如果这里有一个比喻，就是它已经知道了各种事情，现在我们只想说，不，这不是我们想要的，不要这样做，你在这里的输出中犯了一个错误，当然，这正是你所说的，尽可能多的人工智能在循环中，使教师他们的工作被放大了，他们尽可能有效地工作，所以这和教育过程并不一样，如何在这个世界上表现良好，我们需要做额外的训练，以确保模型知道幻觉是不可能的，然后一旦它知道，现在你的业务，我明白了，这是强化学习人类教师循环，将教人类教师循环或一些其他的变体，但有一个论点，即我们很快就会发现，这是一个问题，这将会是一个什么样的问题，你现在专注于什么研究，我不能详细谈论我正在进行的具体研究，但我可以提到一点，我可以提到一些研究和广泛的笔触，这将是一些我非常感兴趣的东西，如让这些模型更可靠，更可控，让它们从更少的数据中更快地学习，更少的指示。我认为我提到的所有这组问题都是有联系的，还有一个问题是我们在这个问题上谈论的是多远的未来，我在这里评论的是也许更近的未来，你谈到了大脑和神经网络之间的相似性，这是Jeff Hinton对我提出的一个非常有趣的看法，我相信这对其他人来说并不陌生，但大型模型或大型语言模型特别是大型语言模型拥有大量的数据，但参数数量却不多，相比之下，人脑拥有数万亿和数万亿的参数，但数据量却相对较少，你是否从这些方面考虑过，你能否谈谈大型模型中缺少什么，以拥有更多的参数来处理数据，这是一个硬件问题还是一个训练问题。从这些数据中学习的问题 事实上，目前的技术结构确实喜欢大量的数据，特别是在训练的早期，现在在训练的后期，它变得有点不那么渴望数据，这就是为什么在最后它可以学习得非常快，但它可以学习得相当快，所以已经意味着在某种意义上，我们甚至关心我们需要所有这些数据来达到这个点，但事实上，更普遍的我认为将有可能从更少的数据中学习更多，我认为这是只是我认为这需要一些创造性的想法，但我认为这是可能的，我认为从更少的数据中学习更多的东西将释放出很多不同的可能性，它将使我们能够教给兔子所缺少的技能，并向它传达我们的愿望和偏好，使它更容易表现出来，所以我想说，更快的学习确实非常好，尽管在语言模型被训练后，它们可以很快地学习，我认为还有机会做得更多我听到你说我们需要更快的处理器来进一步扩展，似乎模型的扩展没有尽头，但训练这些模型所需的功率已经达到了极限，至少是社会公认的极限，所以我只想说一句话，我不记得我说过的你所指的确切评论，但你总是想要更快的处理器，当然你总是想要更多的处理器，当然功率不断增加我想问的问题不是成本是否很高，而是我们支付这个成本后得到的东西是否超过了成本，也许你支付了所有这些成本，但你什么也没得到，那么是的，这不值得，但如果你得到了非常有用的东西，非常有价值的东西，有时你可以解决很多问题，我们真的想卖掉，那么成本是合理的。是的，你是否参与了硬件问题，你与Cerebris合作，例如晶圆规模的芯片，现在我们所有的硬件都来自Azure和他们提供的GPU 是的，你有一次谈到了民主，谈到了人工智能对民主的影响 人们跟我说，如果你有足够的数据和足够大的模型，你可以在数据上训练模型，它可以提出一个最佳解决方案，让所有人满意你有什么愿望吗？或者你认为在帮助人类管理社会方面，这可能会导致什么结果？ 是的，让我们看看这是一个很大的问题，因为这是一个更有前瞻性的问题，我认为还有很多方法可以让我们的模型变得比现在更有能力，毫无疑问，特别是我们训练它们和使用它们的方法，等等，这里和那里会有一些变化，它们可能不是今天就能看到的。但我认为事后会非常明显 这将使它有能力提出解决这类问题的方案 无法预测政府将如何使用这项技术作为获得各种建议的来源 我认为对于民主问题，我认为未来可能发生的一件事是，因为你有这些神经网络，它们将如此普遍，它们将在社会中产生如此大的影响，我们我们会发现，最好能有某种民主进程，比如说，一个国家的公民向神经网络提供一些信息，说明他们希望事情如何发展，他们希望它的行为如何，或者类似这样的事情，我可以想象，这可能是一种非常像高带宽的民主形式，也许你从每个公民那里得到更多的信息，你汇总这些信息，明确我们希望这些系统如何行动。但这是未来可能发生的一件事 是的，我可以在你举的民主例子中看到，个人将有机会输入数据，但呃，这有点像世界模型的问题，你认为人工智能系统最终会足够大，它们可以理解一个情况并分析所有的变量，但你需要一个模型，不仅仅是吸收语言，我认为分析所有的意思是什么？最终，你需要做出一个选择，你说这些变量似乎真的很重要，我想深入了解，因为一个人可以读这本书，我可以读一百本书，或者我可以非常缓慢和仔细地阅读这本书，并从中获得更多的东西，所以会有一些这样的因素，我认为在某种意义上，可能从根本上不可能了解所有的事情，在社会上有任何种类的复杂情况，甚至在一个公司，甚至在一个中型公司我认为，如果我们以正确的方式建立我们的人工智能系统，我认为人工智能可以在几乎任何情况下提供令人难以置信的帮助，本期节目到此结束，我要感谢伊利亚的时间，还要感谢埃利-乔治帮助安排这次采访，如果你想阅读这次谈话的记录，你可以在我们的网站上找到一个ionai，这是E-ey-e hyphen o n dot a I 我们喜欢听到听众的意见，所以请随时给我发电子邮件：Craig c r a i g at e-y-e hyphen on dot a i 我收到很多邮件，所以在主题栏里写上听众，这样我就不会错过了 我们的听众遍布170个国家和地区 记住，奇点可能还没有到来，但人工智能正在改变你的世界，所以请注意