
Lex 00:00:00

以下是与Elliot discover的对话，他是open ai的联合创始人和首席科学家，是历史上被引用次数最多的计算机科学家之一，被引用次数超过165,000次，对我来说，他是深度学习领域最杰出和最有洞察力的人之一。在这个世界上，很少有人比伊利亚在麦克风上和麦克风下更愿意和我谈论深度学习智能和一般的生活，并进行头脑风暴。这是我的荣幸，也是我的快乐。这次谈话是在大流行病爆发前录制的，为的是让每一个感受到这场危机的医疗、心理和经济负担的人。我向你们传递爱，保持坚强，我们在一起。我们会战胜这一切的。这就是人工智能播客。如果你喜欢它。在youtube上订阅，在苹果播客上用五颗星评论，在Patreon上支持，或者直接在twitter上与我联系。Elex Friedman拼写为F R I D M A N。像往常一样，我现在会做几分钟的广告，中间绝不会有任何广告，以免破坏谈话的流程。我希望这对你有用，而且不会损害收听体验。

这个节目是由现金涨价提出的，当你得到它时，应用程序商店中的第一大金融应用程序。二手代码Lex播客。现金了，除非你给朋友送钱买比特币，用1美元就能投资股市，因为现金应用允许你购买比特币。让我提一下，在货币历史的背景下，加密货币是迷人的。我推荐《一分钱》是一本关于这段历史的好书。这本书和有声读物都认为，账本上的借记和贷记大约始于3万年前，美元创建于200多年前，比特币是10多年前发布的第一个分散的加密货币。因此，考虑到这段历史，加密货币在很大程度上仍处于发展的早期，但它的目标仍然是重新定义货币的性质。因此，同样，如果你从应用程序商店、谷歌游戏中获得现金，并使用代码lex播客，你将获得10美元，现金也将捐赠10美元给第一个组织，该组织正在帮助推进世界各地年轻人的机器人和干细胞教育。现在是我与埃利亚的对话，你是与亚历克斯-科索夫斯基（Alex Kosowski）杰夫-辛顿（Geoff Hinton）一起撰写的著名的亚历克斯网论文的三位作者之一，该论文可以说是呃标志着当时启动深度学习革命的大催化时刻？带我们回到那个时候。你对神经网络的直觉是什么，关于神经网络的力量表现，也许你可以提一下，在接下来的几年里，直到今天，在这10年里，你是如何演变的。

Ilya 00:03:10
是的，我可以回答这个问题 在大约2010年和2011年的某个时候，我连接到事实在我的脑海中基本上实现是这个在某些时候。我们意识到，我们可以训练非常大的不应该，你知道，他们是微小的今天的标准，但大型和深度的神经网络，并以反向传播结束在某些时候，不同的人获得这个结果。我获得了这个结果。第一个，我意识到深度神经网络强大的第一个时刻是当詹姆斯-马丁在2010年发明了无欺负的优化器，他训练了一个10层的神经网络，并在没有预训练的情况下从头开始结束。当这一切发生时，我想这就是它，因为如果你能训练一个大的神经网络，一个大的神经网络可以代表非常复杂的功能。因为如果你有一个有10层的神经网络，就好像你让人的大脑运行了若干毫秒，神经元的启动是缓慢的，所以在也许100毫秒内，你的神经元只启动了10次。所以它也有点像10层，在100毫秒内你可以完美地识别任何物体。所以我想，所以我当时已经有一个想法，我们需要在大量的监督数据上训练一个非常大的神经网络，然后它一定会成功，因为我们可以找到最好的神经网络。然后还有一个理论，如果你的数据比参数多，你就希望过度拟合，今天我们知道实际上这个理论是非常不完整的，当你的数据比参数少的时候，你希望过度拟合，但是绝对如果你的数据比参数多，你希望过度拟合。

Lex 00:04:50
所以事实上，你知道这对严重超过Perma trist的工作并没有让你气馁。所以你你在思考理论，参数的数量，事实上有一个巨大的参数数量是好的。这将是好的。I

Ilya 00:05:03
我的意思是，在这之前有一些证据，它是好的。但理论上说，如果你有一个大的数据集和一个大的壁画，那么，过度的私有化就不会有太大的问题。我想，好吧，我只是要添加一些数据增强。它将会是好的。

Lex 00:05:17
那么，任何疑问是从哪里来的呢？

Ilya 00:05:19
主要的疑问是，如果我们有足够的计算机训练足够大的神经网，用反向传播，反向传播，我们能不能训练出一个大的神经网？我想这是可以的。这个图像不清楚的是是否有足够的计算量来获得一个非常有说服力的结果。然后在某个时候，Alex kozinski写了这个速度惊人的cuda内核来训练卷积神经网络。那是bam，让我们做这个，让我们得到想象。而这将是最伟大的事情

Lex 00:05:40
你的直觉，你的直觉大部分来自于你和其他人的经验性结果。所以，就像刚刚实际证明一个程序可以训练一个10层的神经网络，还是有一些笔和纸或者马克笔和白板的思维直觉，因为你刚刚把一个10层的大型神经网络连接到大脑。所以你刚才提到了大脑。那么在你对神经网络的直觉中，人脑是否作为直觉的构建者而发挥作用？

Ilya 00:06:10
肯定的。我的意思是，你知道，你必须准确地将你的人工神经网络与大脑进行类比，但毫无疑问，大脑是深度学习研究人员的一个巨大的直觉和灵感来源，从60年代的Rosenblatt开始就一直如此。如果你看一下神经网络的整个想法是直接受到大脑的启发，你有像McCollum和Pitts这样的人，他们说，嘿，你在大脑中得到了这个新的神经元，嘿，我们最近了解了计算机和自动机，我们是否可以使用计算机和自动机的一些想法来设计某种计算对象，这将是简单的，计算的，有点像大脑。然后他们发明了神经元。所以他们当时受到了启发，然后你有来自福岛的卷积神经网络，后来年轻的拉汉说，嘿，如果你限制神经网络的接受领域，将特别适合于图像，因为它被证明是真的。因此，有一种非常小的例子，与大脑的类比是成功的，我想，好吧，可能一个人工神经元与大脑没有什么不同，如果你用力眯起眼睛。所以我们就假设它是，然后用它来招生。

Lex 00:07:17
所以我们现在处于一个深度学习非常成功的时代。因此，让我们少眯一会，说说，让我们睁开眼睛，说说对你来说，人脑之间有什么有趣的区别。现在，我知道你可能不是专家，呃，在你的科学家和你的生物学家都不是，但松散地说，人脑和人工神经网络之间有什么区别？这对你来说，在未来十年或二十年内是很有趣的？

Ilya 00:07:43
这是个好问题，可以问。大脑和我们的人工神经网络之间的神经元有什么有趣的区别。所以，我觉得今天的人工神经网络，所以我们都同意，在某些维度上，人脑的表现大大超过了我们的模型。我还认为的是，在某些方面，人工神经网络具有大脑的一些非常重要的优势。观察优势和劣势是一个很好的方法来弄清楚什么是重要的区别。因此，大脑使用尖峰，这可能很重要，也可能不重要。

Lex 00:08:17
是的，一个非常有趣的问题。你认为这是否重要？这就是人工神经网络和计算机网络之间的一个很大的架构区别。

Ilya 00:08:25
这很难讲。但我的先验不是很高。我可以说为什么，你知道，有一些人对尖峰神经网络感兴趣，基本上他们发现的是，他们需要在尖峰中模拟非尖峰神经网络，这就是他们要使经济网络工作。如果你不在尖峰中模拟非尖峰神经网络，它就不会工作。因为问题是，它为什么要工作？这连接了围绕反向传播的问题和围绕深度学习的问题。你有这个巨大的神经网络，为什么它应该工作？为什么这个学习规则应该工作？这不是一个不言自明的问题，特别是如果你说，如果你刚开始进入这个领域，你读了非常早期的论文，你可以说，嘿，人们正在说，让我们建立神经网络。这是一个伟大的想法，因为大脑就是神经网络。因此，建立神经网络将是有用的。现在让我们弄清楚如何训练它们。

应该有可能对他们进行培训。但如何做到这一点，所以大的想法是成本函数。这是个大主意。成本函数是一种根据某种措施来衡量系统性能的方法。通过

Lex 00:09:32
我想，这其实是一个很大的问题，让我想一想，这是不是一个很难达成的想法。还有，有多大的想法是有一个单一的成本函数。对不起，让我暂停一下，监督学习是一个很难达成的概念。

Ilya 00:09:50
我不知道所有的概念都很容易在

Lex 00:09:52
回头看。是的，这就是现在看来微不足道的东西。但是因为因为我问这个问题的原因，我们会讨论这个问题，因为是否有其他的东西，是否有不一定有成本函数的东西？也许有很多成本函数，也许有动态成本函数，也许有完全不同的架构？因为我们必须这样思考，才能得出新的东西。对吗？

Ilya 00:10:15
因此，唯一的那么好的例子，没有明确的成本函数的事情再次反对，你有一个游戏。因此，而不是思考一个你想优化的成本函数，但你知道你有一个算法梯度下降，这将优化成本函数。然后你就可以用它的优化方式来推理行为系统了。同样，你说我有一个游戏，并从游戏的均衡方面来推理系统的行为。但这都是关于提出这些数学对象，帮助我们推理行为系统。

Lex 00:10:47
对吗？这真的很有趣。是的。同样，这是唯一的方法，它是一种成本函数从比较中产生的。

Ilya 00:10:53
这是我不我不知道它是否有一个成本函数，我不知道谈论它的成本函数是否有意义。同样，它有点像生物进化的成本函数和经济的成本函数。你可以谈论它可以走向的区域，但我不认为，我不认为成本函数的比喻是最有用的。

Lex 00:11:14
因此，进化并没有这真的很有趣。所以，如果进化没有真正的成本函数，比如基于其类似于我们的数学概念的成本函数，那么你认为深度学习中的成本函数会阻碍我们吗？是的。所以你刚才提到成本函数是一个很好的第一个深刻的想法。你认为这是个好主意吗？你认为这是个会过去的想法吗？所以自我的地方开始触及强化学习系统中的一点。

Ilya 00:11:48
这就对了。自我发挥。还有围绕探索的想法，你试图采取的行动是存在惊喜的预测器。我是课程函数的一个大粉丝。我认为这些功能很好，它们的服务非常好。而且我认为，只要我们能做的事情，我们称之为成本函数，我们就应该，而且你知道，也许有机会我们会想出一些又一个深刻的看问题的方法，会以一种不那么核心的方式涉及成本函数。但我不知道，我认为成本函数是我的意思是我不会对这些函数打赌。

Lex 00:12:20
在设计人工神经网络时，有没有其他关于大脑的东西突然出现在你的脑海中，可能是不同的、有趣的，供我们考虑。因此，我们谈到了尖峰的问题。

Ilya 00:12:33
我的意思是，11件可能有潜在作用的事情。我认为人们的神经科学家想出了一些关于大脑的学习规则。或者我说的是尖峰时间依赖的可塑性。如果有人能在模拟中研究这个问题就好了。

Lex 00:12:45
对不起，尖峰时间依赖性可塑性。是的，这只是一个

Ilya 00:12:48
STD。这是一个特殊的学习规则，它使用尖峰时间来计算如何确定如何更新突触。所以它有点像如果突触在神经元开火之前就进入神经元，那么它就会加强突触。而如果突触在神经元发射后不久就发射到神经元中，那么它就成为突触。沿着这个思路的东西。我有90%的把握这是对的。所以如果我在这里说错了什么，不要不要太生气、

Lex 00:13:15
但你说的时候听起来很精彩。但是时间性，这是缺少的一件事。时间上的动态性没有被捕捉到。我认为这就像大脑的一个基本属性，就是信号的时间。

Ilya 00:13:30
被记录的神经网络。

Lex 00:13:32
但是，你认为，我的意思是，这是一个非常船员简化呃那叫什么？有一个时钟，我想是对呃递归神经网络。它这似乎是大脑是连续版本的一般。所有可能的定时都是可能的，然后在这些定时中包含了一些信息，你认为递归神经网络，在递归神经网络中有电流可以捕捉到与定时相同的现象，这似乎对大脑在大脑中的神经元的发射很重要。

Ilya 00:14:12
我的意思是，我认为我认为递归递归神经网络是惊人的，他们可以做我认为他们可以做任何事情。如果你想让一个系统现在就做，我们会希望他们这样做。递归神经网络已经被变压器取代了，但也许有一天它们会卷土重来。也许它会回来。我们将拭目以待。

Lex 00:14:32
让我呃一个小小的改变，说，你认为他们会回来吗？所以，最近我们要谈的自然语言处理和语言建模方面的许多突破都是用不强调递归的转化器。你认为递归会卷土重来吗？

Ilya 00:14:50
那么，某种递归我认为很可能是递归神经网络的过程，因为那里通常被认为是处理序列的？我认为这也是可能的。

Lex 00:15:01
对你来说是什么？递归神经网络 而一般来说，我想。什么是递归神经网络？

Ilya 00:15:07
你有一个神经网络，它保持着一个高维的隐藏状态。然后当一个观察结果到来时，它通过其连接以某种方式更新其高维的隐藏状态。

Lex 00:15:20
那么，你认为，你知道这就是像专家系统所做的吗？对，象征性的。基于知识的知识库的增长是保持一个隐藏的状态，这是它的知识库，它通过一些问题过程来增长它。你是否更普遍地以这种方式来考虑它？还是说，它仅仅是一个具有某种门控单元的隐藏状态的更有约束性的形式，我们今天认为是L S D M S之类的、

Ilya 00:15:51
我的意思是隐藏的状态在技术上是你在那里描述的。进入LSD em里面的隐藏状态，或者他们正在运行或者类似的东西。但是，那么应该包含什么呢？你知道，如果你想做专家系统的类比，我不是，你可以说知识故事在连接中，然后短期处理是在在隐藏状态中完成。

Lex 00:16:13
是的，你能这么说吗？那么，你认为在神经网络中建立大规模的知识库是否有前途？肯定是的。所以我们要在这种信心中暂停，因为我想探索一下。让我再放大问问，mm回到图像的历史。网络神经网络已经存在了几十年了。正如你所提到的，你认为导致他们成功的关键想法是什么，那个图像在那一刻及以后 在过去10年里的成功。

Ilya 00:16:49
好的，所以这个问题是为了确保我没有错过任何东西，在过去10年中导致深度学习成功的关键想法。

Lex 00:16:56
正是如此。尽管深度学习背后的基本东西已经存在了很久。

Ilya 00:17:02
所以，关于深度学习的关键想法，或者说，在深度学习开始成功之前，关于deplaning的关键事实是，它被低估了，从事机器学习的人根本不认为新的神经元能做什么。人们不相信大型神经网络可以被训练。人们认为，在机器学习中，有很多关于什么是正确的方法等的辩论，人们争论不休，因为没有，没有，没有办法得到硬的事实，我的意思是，没有真正困难的基准，如果你做得非常好，你可以说，看，这是我的系统，这时你从，这时这个领域变得有点像一个工程领域。所以，就深度学习直接回答问题而言，想法都在那里。缺少的是大量的监督数据和大量的计算，一旦你有大量的民权数据和大量的计算，那么还需要第三件事。这就是信念，相信如果你采取正确的东西，它已经存在，并应用和混合大量的数据和大量的计算，它实际上将工作。因此，这就是缺少的部分。你有你需要的数据，他需要计算，这表现在GPU方面，你需要有信念来认识到你需要将它们混合在一起。

Lex 00:18:35
所以这真的很有趣。所以我想，计算的存在和总统的监督数据使得经验证据能够对计算机科学界的大多数人做说服。所以我猜有一个关键时刻，有吉坦德拉-马利克和呃亚历克斯-阿廖沙-埃夫罗斯，他们都非常怀疑，对吗？然后有一个Geoffrey Hinton，他是怀疑论的反面，有一个令人信服的时刻，我认为排放是那个时刻，这代表了计算机视觉界的大支柱，有点像，巫师们聚在一起，然后突然有了一个转变，对于我将在那里和计算机在那里的想法是不够的。它是为了说服存在的愤世嫉俗，这很有趣，人们只是在几十年内不相信。

Ilya 00:19:32
是的，但它不仅仅是这样，它是一种当把这种方式，它听起来像，嗯，你知道，那些愚蠢的人谁不相信我们是什么，我们正在失去。但在现实中，事情是混乱的，因为神经元真的不工作的东西，他们不是最好的方法，在几乎所有的东西以及。而且很理性地说，是的，这个东西没有任何牵引力。这就是为什么你需要有这些非常艰难的任务，产生不可否认的证据，这就是我们取得进展的方式，这就是为什么该领域今天正在取得进展，因为我们有这些代表真正进展的硬性基准，因此，这就是为什么我们能够避免无休止的辩论。

Lex 00:20:15
那么，令人难以置信的是，你在计算机视觉语言、自然语言处理、强化学习这类介于两者之间的东西方面，贡献了一些最近在ai方面最大的想法？也许不是Ganz，是吗？可能没有一个主题是你没有接触过的。当然，还有深度学习的基础科学。对你来说，视觉语言和强化学习行动之间的区别是什么，作为学习问题。还有什么共同点，你认为它们都是相互关联的吗？它们是否从根本上是不同的领域，需要不同的

Ilya 00:20:52
办法？好的，这是个好问题。机器学习是一个有很多统一性的领域。大量的统一性。

Lex 00:21:01
你说的统一性是什么意思？比如思想的重合

Ilya 00:21:05
思想的重叠，原则的重叠。事实上，只有一个或两个或三个原则是非常非常简单的，然后它们以几乎相同的方式适用于不同的模式和不同的问题。这就是为什么今天有人写了一篇关于改进、优化深度学习设想的论文，它改进了不同的NLP应用，它改进了不同的强化学习应用，强化学习。所以我想说，计算机视觉和NLP在今天是非常相似的。它们的不同之处在于它们的架构略有不同，我们在NLP中使用变压器，并使用卷积神经网络设想，但也有可能有一天这将发生变化，一切都将统一为一个架构，因为如果你回到几年前的自然语言处理、如果你回到几年前的自然语言处理，有大量的架构，每一个不同的小问题都有自己的架构，今天只有一个转化器来处理所有这些不同的任务，如果你回到更久之前，你有更多和更多的碎片化，ai中的每一个小问题都有自己的小次专业和小技能集合，人们会知道如何设计这些功能。现在，所有这些都已经被归入了deplaning，我们有了这种统一，所以我希望视觉也能与自然语言统一起来，或者说我没有想到，我认为这是可能的。我不想太肯定，因为我认为在商业上，你知道那是非常竞争的。高效的一个轨道是不同的。一个真正不需要稍微不同的技术，因为你真的需要采取行动。你真的需要做一些探索，你的差异性要高得多。但是我认为即使在那里也有很多的统一性，我期望例如在某些时候，RL和监督学习之间会有一些更广泛的统一，在那里，以某种方式，他们是我将做出决定，使超级快，甚至不要去更好，它将是我想象的一个大黑盒子，你只是扔你知道，你铲铲东西到它，它只是想出做什么，无论你铲到它。

Lex 00:23:04
我的意思是强化学习有语言和视觉的一些方面，几乎有你应该利用的长期记忆的元素，也有真正丰富的感官空间的元素。所以它看起来就像这两者的结合体或类似的东西、

Ilya 00:23:25
我的说法略有不同。我想说，强化学习两者都不是，但它自然而然地与这两者对接和融合。

Lex 00:23:34
你认为行动是根本性的不同。所以，是的，关于学习行动的政策，什么是有趣的，什么是独特的？

Ilya 00:23:43
另外，有一个例子，比如说，当你学会行动的时候，你的根本是在一个非静止的世界里，因为随着你的行动的改变，你看到的东西，开始改变你，你以不同的方式体验世界，这不是更传统的静态问题的情况，你有一些分布，只是要对这个分布发挥一个模型。嗯。

Lex 00:24:06
你认为这是一个根本不同的问题，还是只是一个更困难的一般来说，它是理解问题的一个概括。

Ilya 00:24:13
我的意思是它是它是一个定义的问题，几乎有一个巨大的嗯，你知道，有一个巨大的共同点是肯定的。你采取梯度，你尝试，你采取梯度，我们在两种情况下都尝试近似梯度，在强化学习的情况下，你有一些工具来减少梯度的差异，你这样做，有很多共同点，在两种情况下，同样的神经网络，你计算梯度、所以我的意思是，肯定有很多共同点，但也有一些小的差异，这些差异并非完全不重要，这实际上只是你的观点的问题，什么参考框架，你想在看这些问题时放大或缩小多少、

Lex 00:24:54
你认为哪个问题更难？所以像诺姆-乔姆斯基这样的人认为，语言是一切的根本，所以它是一切的基础。你认为语言理解比视觉场景理解更难，还是相反？

Ilya 00:25:09
我认为问一个问题是否很难，是稍微有点错误的，我认为这个问题有点错误，我想解释一下原因，那么一个问题很难是什么意思？

Lex 00:25:21
好吧，这个无趣的愚蠢的答案是，有一个基准，有一个人类水平的性能在这个基准上，以及如何作为达到人类水平所需的努力。

Ilya 00:25:35
基准。因此，从多少的角度来看，直到我们达到人类的水平

Lex 00:25:40
在一个非常好的基准上

Ilya 00:25:43
是的，我明白，我明白你的意思。所以我想说的是，这在很大程度上取决于，你知道，一旦你解决了一个问题，它就不再是困难了，这是，这永远是真实的，所以，但一件事是否困难，取决于我们的工具今天能做什么，所以说今天，真正的人类水平的语言理解和视觉感知是困难的，在这个意义上，没有办法在未来三个月完全解决这个问题。所以我同意这个说法，除此之外，我只是，这将是我的猜测将和你一样好，我不

Lex 00:26:13
知道。好的，所以你对语言理解的难度没有一个基本的直觉

Ilya 00:26:19
是，我想我知道我改变了主意，那是一种语言可能会很难，我的意思是这取决于你如何定义它，我给你的意思是绝对一流的，100%的语言理解和去语言。

Lex 00:26:32
所以，但是

Ilya 00:26:33
那么如果我给你看一张写有字母的纸，如果你明白我的意思，那是不是？所以你有一个视觉系统，你说这是最好的人类水平的视觉系统，我给你看我打开一本书，我给你看字母我们需要理解这些字母如何形成单词和句子以及意义。这是不是视觉问题的一部分。视觉和语言从哪里开始？

Lex 00:26:53
是的，所以乔姆斯基会说它从语言开始。视觉只是一种结构的一个小例子，你知道，基本的思想层次已经在我们的大脑中以某种方式表现出来，通过语言来表现。但视觉在哪里停止，语言在哪里开始？这是一个非常有趣的问题。嗯。因此，一种可能性是，无论是图像还是语言，如果不基本上使用同一种系统，就不可能实现真正深刻的理解。所以你要免费得到另一个。

Ilya 00:27:38
我认为我认为这很有可能，是的，如果我们能用我们的机枪得到一个可能是那么好，我们可以得到另一个，但它不是100，我不是100％肯定。还有，我认为很多，很多确实取决于你的定义

Lex 00:27:53
的定义

Ilya 00:27:55
像完美的视觉，因为你知道，阅读他的视力，但它应该算吗？

Lex 00:28:01
是的。对我来说。所以我的定义是一个系统看了一张图片，然后一个系统看了一段文字，然后告诉我一些关于这个的事情，我真的印象深刻。

Ilya 00:28:15
那是相对的。你会被打动半小时，然后你会说，好吧，我的意思是所有的系统都会这样做。但有一点他们没有做到。

Lex 00:28:22
是的，但我对人类没有这种感觉。人类继续给人留下深刻印象

Ilya 00:28:25
我。那是真的吗？

Lex 00:28:27
好吧，我是一个一夫一妻制的粉丝。所以我喜欢和某人结婚，和他们在一起几十年的想法。所以我相信这样一个事实：是的，有一个人不断给你带来愉悦、有趣、诙谐的新想法是可能的。朋友们。是的，我想我是这么认为的。他们会继续给你带来惊喜。惊喜是......你知道，随机性的注入似乎是一个......似乎是一个很好的源泉，是的，继续是的。是的，灵感。就像幽默一样，我想是的，这将是一个非常主观的测试，但我认为如果你有足够的人类在他们自己的。

Ilya 00:29:15
是的，我明白你的意思。是的，我觉得我误解了你说的打动你的意思。我以为你的意思是用它的智慧来打动你，用它如何如何好的理解和一个图像来打动你。我以为你的意思是，我给你看一个非常复杂的图像，它将得到它的权利，你会说哇，这真的很酷。你知道2020年1月的系统并没有在做

Lex 00:29:36
那现在。我认为这一切都可以归结为人们在互联网上点击喜欢的东西的原因，这就像它让他们笑，所以它就像幽默或机智或洞察力。

Ilya 00:29:49
我相信我们也会得到的。

Lex 00:29:52
所以请原谅这个浪漫化的问题，但回过头来看你，你所遇到的最美丽或最令人惊讶的想法和深度学习或一般的ai。

Ilya 00:30:03
所以我认为深度学习最美妙的地方在于它确实有效。我的意思是，因为你有这些想法，你有一个小小的神经网络，你有反向传播算法，然后你有一些理论，你知道，这有点像大脑。因此，也许如果你让它变大，如果你让神经网络变大，并且你训练了大量的数据，那么它将做与大脑相同的功能。而事实证明，这是真的。这很疯狂。现在我们刚刚训练了这些神经网络，你让它们变得更大，它们就会不断变得更好。而我觉得这很不可思议。我觉得不可思议的是，我塞给神经网络的这个神圣的东西竟然起作用了。

Lex 00:30:39
你有没有建立起一种直觉，为什么会有一点一滴的直觉，为什么这整个事情会发生？

Ilya 00:30:48
我的意思是，有些肯定 嗯，我们知道，优化我们现在有很好的我们已经采取了我们已经有很多经验性的，大量的经验性的理由来相信，优化应该在所有我们关心的大多数问题上工作。

Lex 00:31:04
你有什么见解吗？所以你刚才说经验性的证据是你的大部分排序，经验性的证据有点让你信服。就像进化论是经验性的，它告诉你，看这个进化过程似乎是设计生物体在其环境中生存的好方法，但它并没有真正让你了解整个事情的内部情况。

Ilya 00:31:31
我想这是一个很好的比喻，就是物理学。你知道，你如何说，嘿，让我们做一些物理计算，提出一些新的物理理论，做一些预测。但是，你已经得到了周围的实验，你知道，你得运行的实验。这很重要。这里有点相同，只是也许有些时候，实验是在理论之前进行的，但仍然是这样的。你知道，你有一些数据，你想出了一些预测，你说，是的，让我们做一个大的神经网络，让我们训练它。它将会比之前的任何东西都要好得多。事实上，它将继续变得更好，因为你让它变得更大。而事实证明这是真的。当理论被这样评估时，那是令人惊讶的。你知道，这不是一个数学理论，它几乎更像是一个生物理论。所以我认为深度学习和生物学之间的类比并不可怕。

我想说这就像生物学和物理学的几何平均值。这就是深度学习的几何意义。

Lex 00:32:18
生物学和物理学的含义。我想我们需要几个小时的时间，因为要找到几何学，要找到生物学代表的集合。

Ilya 00:32:33
生物学中的事情真的很复杂，而且真的很难有好的预测理论，物理学中的理论太好，人们在物理学中提出了这种超级精确的理论，做出了这些惊人的预测，而在机器学习中，我们可以在这两者之间进行预测。

Lex 00:32:48
一种介于两者之间的东西。但如果机器学习能以某种方式帮助我们发现这两者的统一，而不是服务于两者之间，那就更好了。但你是对的，那是你在试图兼顾两者。那么，你认为它们仍然是神经网络的美丽和神秘的属性，尚未被发现？

伊利亚 00:33:07
肯定是这样。我认为，我们仍然严重低估了部署工作。

Lex 00:33:12
你觉得怎么样？它看起来像什么？像什么

Ilya 00:33:15
如果我知道，我就会这么做。

Lex 00:33:17
那么呃

Ilya 00:33:19
但是，如果你看看过去10年的所有进展，我会说大部分，我会说有一些情况，有些是感觉真正的新想法出现的东西，但总的来说，它是每年我们认为，好吧，部署到这一步。不，它实际上走得更远，然后第二年。好吧，现在这是个大的深度学习。真的完成了，不，更进一步了，只是每年都在进一步。因此，这意味着我们一直低估你一直不理解它，因为它一直是令人惊讶的属性。

Lex 00:33:48
你觉得现在越来越难了吗？

Ilya 00:33:50
来取得进展。你需要取得进展？这取决于你的意思。我认为该领域将在相当长的一段时间内继续取得非常有力的进展。我认为对于个别研究人员，特别是正在做研究的人来说，可能更难，因为现在有非常多的研究人员。我认为，如果你有大量的计算，那么你可以做出很多非常有趣的发现。但是，然后你必须处理管理巨大的计算机的挑战，巨大的、经典的、巨大的计算机集群来运行你的实验。这有点

Lex 00:34:19
更难。所以我问了所有这些没有人知道答案的问题，但你是我认识的最聪明的人之一，所以我们可以继续问 所以让我们想象一下所有的突破，那是，在未来30年发生的和深度学习。你认为这些突破中的大部分可以由一个人用一台计算机在突破的空间里完成，你认为计算将是呃计算和大的努力将是必要的。

Ilya 00:34:49
我的意思是，它不能确定当你说一台电脑时，你是指多大的电脑

Lex 00:34:55
呃你是你很聪明。我是说，1，1

Ilya 00:34:58
GPU我明白了，我认为这是很不可能的。我认为这是很不可能的。我认为有很多深度学习的堆栈开始变得相当深，如果你看看它，你已经得到了所有的想法，建立数据集的系统，分布式编程，建立实际的集群，Gpu编程，把它全部放在一起。因此，堆栈变得非常深，我认为，对于一个人来说，要在堆栈的每一层都成为世界级的人才是相当困难的。

Lex 00:35:34
像弗拉基米尔，瓦普-尼克真正坚持的是采取em nist并试图从很少的例子中学习。因此，能够更有效地学习，你认为在这个领域会有突破，可能不需要巨大的计算？

Ilya 00:35:51
我认为会有一个非常，我认为一般来说会有大量的面包师，如果你不是在一个巨大的计算量。所以也许我应该澄清一下。我认为一些突破将需要相当多的计算，我认为建立真正做事的系统将需要大量的计算，如果你想做X，而X需要一个巨大的壁画，你必须在这上面得到一个巨大的年份，这是非常明显的。但我认为会有很多，我认为会有很多空间让小团体和个人完成非常重要的工作。

Lex 00:36:22
你能不能就深度学习的科学主题，谈谈你最近发表的一篇论文，即深度双降是更大的模型和更多的数据伤害。我认为这是一篇非常有趣的论文，你能描述一下它的主要观点吗？

Ilya 00:36:39
是的，当然。因此，发生的事情是，一些，在过去的几年里，一些少数的研究人员注意到，这是一种奇怪的现象，当你使新的电大的时候，它工作得更好，它似乎与统计学思想相矛盾。然后有些人做了一个分析，显示实际上你得到了这个双倍的沙子碰撞，而我们所做的是显示双倍下降发生在几乎所有实用的深度学习系统中，并且它也会。所以

Lex 00:37:05
你能不能退一步说，嗯，双倍下降图的X轴和Y轴是什么？

Ilya 00:37:12
好的，很好。所以你可以你可以看，你可以做一些事情，比如你可以把你的神经网络，你可以开始慢慢增加它的大小，同时保持你的数据集固定。所以如果你增加神经元的大小工作缓慢，如果你不做早期停止，这是一个相当重要的细节。那么当最新的书真的很小的时候，你让它变大，你的性能就会得到非常快速的提高。然后你继续把它变大，在某个点上性能会变差 而它会变得和最差。确切地说，在它实现零训练的那一点上，零训练损失。然后，当你把它变大时，它很难再变好，这有点反直觉，因为你会期望离机现象是单调的。而且很难确定这意味着什么。但它也发生在线性分类器的情况下。而直觉基本上可以归结为当你当你有很多，当你有一个大的数据集和一个小的模型时，那么小的，微小的随机性的下降。所以基本上什么是过拟合？

过度拟合是指当你的模型在某种程度上对你的数据集中的小的随机的一个重要的东西非常敏感，在训练日，在训练数据集准确。所以，如果你有一个小的模型，你有一个大的数据集，可能有一些随机的东西，你知道，一些训练案例在数据集中是随机的，其他的可能不在那里，但是小的模型，但是小的模型对这种随机性有点不敏感，因为它是一样的。你有相当多的不确定性的模型，当一天是它的

Lex 00:38:54
大。所以，好吧，所以在最基本的层面上对我来说，这是最令人惊讶的事情，你会网络不超过适合每一次非常迅速，呃，在曾经能够学习任何东西，巨大的参数数量。

Ilya 00:39:13
所以这里是，所以有一个方法，好吧，所以也许让我试着给出解释，也许那会是那会工作。所以你有一个巨大的神经网络，我想你已经得到了他，你是，你有一个巨大的神经网络是一个巨大的参数数量。而现在让我们假装一切是线性的，这不是，让我们假装那么有这个大的子空间。把你的网络实现零面积。而作为职责是要找到近似的点无线电，这是正确的。大约是那个子空间中最小的规范的点。这也可以证明，当维度很高时，对数据中的小随机性不敏感，但当数据的维度与模型的维度相等时，那么所有的数据集和模型之间都有1-1的对应关系。所以，数据集的小变化实际上会导致模型的大变化，这就是为什么性能变差。所以这是最好的解释。或多或少。

Lex 00:40:09
所以，模型有更多的参数是好事。所以，呃，要比数据大。

Ilya 00:40:15
这就对了。但前提是你没有真正停止。如果你引入早期停止的正则化，你可以使双倍下降的颠簸几乎完全消失。什么是早期停止？早期停止是指当你训练你的模型，你监测你的只是验证性能。然后如果在某些时候验证性能开始变差。你说，好吧，让我们停止训练，你很好，你很好，你足够好。

Lex 00:40:36
所以神奇的事情发生在那一刻之后。所以，你不想做早期的停顿。

Ilya 00:40:41
好吧，如果你不做早期停止，你得到这个非常你得到一个非常明显的双重下降、

Lex 00:40:47
你有什么直觉，为什么会发生这种情况？

伊利亚 00:40:50
双降。也停了下来、

Lex 00:40:52
你知道的，双重下降。所以

Ilya 00:40:53
是的，所以我试试。让我们来看看，直觉基本上是这样的：当数据集有和模型一样多的自由度时，那么它们之间就有一个1-1的对应关系。因此，数据集的微小变化会导致模型的明显变化。所以你的模型对所有的随机性非常敏感，它无法摒弃随机性。而事实证明，当你有比参数多得多的数据或比数据多得多的参数时，产生的解决方案将对数据集的微小变化不敏感。

Lex 00:41:27
因此，它能够很好地解决这个问题，摒弃那些小的变化。

Ilya 00:41:32
参数。这正是假性相关的问题。如果你不希望

Lex 00:41:37
Geoff Hinton建议我们需要扔掉反向传播已经有点谈到这个问题了，但是他建议我们需要扔掉反向传播，重新开始。我的意思是，当然其中有些是有点机智和幽默的。但是你怎么想？什么可能是训练神经网络的替代方法？

Ilya 00:41:56
好吧，他所说的事情恰恰是，在你无法在大脑中找到反向传播的情况下。值得看看我们是否能从大脑的学习方式中学到一些东西。但是反向传播是非常有用的，我们应该继续使用它。

Lex 00:42:09
哦，你是说，一旦我们发现了大脑中的学习机制或该机制的任何方面，我们也应该尝试在你的网络中实现这一机制。

Ilya 00:42:17
如果事实证明，你在大脑中找不到反向传播的话

Lex 00:42:20
如果我们不能在大脑中找到反向传播。

Ilya 00:42:25
好吧、

Lex 00:42:26
所以我想你的答案是，反向传播是非常有用的。那么我们为什么要抱怨呢？

Ilya 00:42:33
我的意思是，我我个人是反向传播的大粉丝。我认为这是一个伟大的算法，因为它解决了一个极其基本的问题，即在某些约束条件下寻找一个神经回路。而且我不认为这个问题会消失。因此，这就是为什么我真的认为我们不太可能有什么东西会有很大的不同。它可能发生，但我现在不会赌它。

我想说的是
那么，让我问一个大的问题，你认为，你认为神经网络可以被用来推理吗？

Ilya 00:43:08
为什么不呢？好吧，如果你看看，例如，在阿尔法围棋或阿尔法零，阿尔法零的神经网络玩围棋。其中我们都同意这是一个需要推理的游戏 比99.9%的人类都要好，只是神经网络没有这个搜索，只是神经网络本身不就给了我们一个神经网络可以推理的存在证明吗？

我想说的是
来推倒重来，不同意一下？我们都同意围棋是有道理的？我想我我同意。我不认为这是一个微不足道的问题。所以很明显，像智力这样的推理是呃是一个松散的灰色地带的术语，有点也许你不同意这个说法。但是，是的，我认为它有一些与推理相同的元素，推理几乎是搜索的一个亲属。对吗？有一个循序渐进的元素，即逐步考虑各种可能性，并以循序渐进的方式建立在这些可能性之上，直到你得出一些洞察力。所以，是的，我想飞机有点像那样，当你有一个单神经元网络在做这个事情的时候，没有搜索，这有点像那样。因此，在一个特定的受限环境中，有一个存在的证明，类似于许多人所说的推理的过程存在，但更普遍的那种推理。因此，从

Ilya 00:44:35
板，还有一个存在的问题、

Lex 00:44:37
男孩。其中

Ilya 00:44:38
我们中的一员？人类？

Lex 00:44:39
是的。好的，好的。那么，你是否认为

Ilya 00:44:44
建筑

吕晓明 00:44:46
这将使神经网络?原因将与我们今天的神经网络架构相似？

Ilya 00:44:55
我认为会的，我认为嗯，我不想做太过明确的陈述。我认为绝对有可能，未来产生推理突破的神经网络将与今天存在的架构非常相似。也许是更多一点的电流，也许是更深一点的。但是，但这些这些新的是如此疯狂地强大。为什么它们不能学习推理呢？人类可以推理。那么，为什么神经网络不能

你认为我们所看到的神经网络所做的事情是一种软弱的推理吗？
你认为我们所看到的神经网络所做的事情是一种弱推理。所以这不是一个根本不同的过程。同样，这也是我们没有人知道答案的东西。

Ilya 00:45:36
因此，当涉及到我们的神经网络时，我会唱，我想说的是，神经网络是能够推理的。但如果你在一个不需要推理的任务上训练神经网络，它就不会推理。这是一个众所周知的效果，神经网络会以最简单的方式解决你在它面前提出的问题，这正是你要解决的。

Lex 00:46:01
对。这把我们带到了2.1。你描述神经网络的出色方式之一，就是你把神经网络称为寻找小电路，也许把通用智能称为寻找小程序，我发现这是一个比喻。非常有说服力。你能详细说明一下这种区别吗？

Ilya 00:46:26
是的。所以我说的是，如果你能找到最短的程序来输出你所掌握的数据，那么你就能用它来做出最好的预测。这是一个可以用数学方法证明的理论声明。现在你也可以从数学上证明，找到产生一些数据的最短程序并不是一个可计算的操作。不，有限数量的计算机可以做到这一点。因此，然后用神经网络，神经网络是下一个最好的污点，在实践中真正发挥作用。我们无法找到产生我们的数据的最短程序，但我们能够找到，你知道，一个小的，但现在这个声明应该被修正，甚至是一个大的电路，在某种程度上适合我们的数据。

Lex 00:47:22
嗯，我想你所说的小电路是指需要的最小的电路。好吧、

Ilya 00:47:27
的事情，也就是我现在要改变的事情，回到当时。我真的有我还没有完全内化过度参数。过度参数的结果是我们所知道的关于其他参数的事情，神经网络。现在，我会把它表述为一个大的电路，其权重包含少量的信息，我认为这就是发生的事情。如果你把神经网络的训练过程想象成你慢慢地将熵从数据集传输到参数，那么不知何故，权重中的信息量最终并不是很大。这就可以解释为什么一般的情况下会这么好、

Lex 00:48:02
所以，这是大的电路可能是一个有帮助的常规为一般化。

Ilya 00:48:08
是的，这个东西。嗯。

Lex 00:48:11
但你认为，能够尝试学习像程序这样的东西，是否很重要？

Ilya 00:48:19
我的意思是，如果我们能肯定我认为这是一种答案是肯定的，如果我们能做到这一点，我们应该做的事情，我们可以做到这一点。这也是我们推动深度学习的原因。那里的根本原因是，我们能够训练他们。因此，换句话说，训练是第一位的，你已经有了我们的支柱，这是训练的支柱，现在我们试图围绕训练的支柱来扭曲我们的神经网络，我们得保持可训练性，这是一个涉及，这是一个不变性，我们不能违反。所以

Lex 00:48:55
可培训意味着从一无所知开始。实际上，你可以很快地收敛起对很多东西的了解。

Ilya 00:49:01
甚至是缓慢的，但这意味着，鉴于你所掌握的资源，你可以训练神经网络并让它达到有用的性能。是的，这是一个我们不能远离的支柱。这是对的。因为如果你能各种，如果你说，嘿，让我们找到最短的程序，或者你不能这样做。所以这并不重要，这将是多么有用。我们可以做到这一点。所以你要、

Lex 00:49:25
所以你认为你有点提到神经网络擅长寻找小的电路或大的电路？你认为寻找小程序的问题只是数据问题吗？不，所以，对不起，不是，不是大小或捕捉质量，数据的类型排序问给它的程序

Ilya 00:49:45
好吧，我认为现在的问题是，没有好的总统的人成功找到程序真的很好。因此，你寻找程序的方法是你训练一个深度神经网络来做它基本上是正确的，这是这是正确的方法。

Lex 00:50:05
但没有好的呃插图

Ilya 00:50:07
这一点还没有做到。但原则上应该是可以的。

Lex 00:50:13
你能详细说明一下吗？你在原则上的见解是什么？而它换一种方式，你不明白为什么不可能？

Ilya 00:50:20
嗯，这有点像，这更像是一个声明，我认为我认为对深度学习下注是不明智的，如果这是一个如果这是一个人类似乎能够做到的认知功能，那么不需要太长时间，一些深度神经网络也会出现，可以做到这一点。

Lex 00:50:42
是的，我是我是和你一样。在这一点上，我可以我已经不再对神经网络下注了，因为它们不断给我们带来惊喜。那么长期记忆呢？你们都能知道，是有长期记忆是类似知识基础的东西。因此，能够在很长一段时间内汇总重要的信息，然后作为有用的ST的那种代表，你可以通过它来做决定，所以你有一个长期的接触，基于你做决定的东西。

Ilya 00:51:18
所以在某种意义上，参数已经做到了这一点。参数是对新奥尔良全部经验的神经元的一天的汇总。因此，他们算得上是长期以来形成的长期知识。而人们已经训练到各种神经网络作为知识基础，并与投资人们已经调查了语言模型知识基础。因此，有工作，有工作在那里。

Lex 00:51:44
是的。但在某种意义上，你认为在每一种意义上，你认为有一个它只是一个更好的机制来忘记无用的东西和记住有用的东西的问题，因为现在，我的意思是没有一个机制能够记住真正的长期信息。

Ilya 00:52:03
你的意思是什么呢？

Lex 00:52:05
确切地说？我喜欢我喜欢这个词。所以我在想，知识库所代表的那种信息的压缩，是在创造一种现在我为我对知识是什么的那种以人为中心的思考而道歉，因为神经网络并不是用它们所发现的那种知识来解释草本。但对我来说，一个好的例子是知识库能够随着时间的推移而建立起来。像维基百科所代表的知识。这是一个真正压缩的结构化呃知识库。显然，不是真正的维基百科或语言，而是像语义网，语义网所代表的梦想。因此，它是一个非常好的压缩知识库，或者在非解释能力意义上类似于神经网络的东西。

Ilya 00:53:03
好吧，神经网络将没有解释器，但如果你看一下率，但他们的输出应该是非常解释草本。

Lex 00:53:09
好的，那么你如何，如何让非常聪明的神经网络像语言模型一样解释草本？

Ilya 00:53:15
好吧，你让他们生成一些文字，而这些文字一般都会被解释。布莱

Lex 00:53:19
你觉得这就是翻译能力的缩影吗？你能做得更好吗？比如你能不能因为你不能，好吧，我想知道它知道什么，不知道什么。我希望神经网络能想出它完全愚蠢的例子和它完全聪明的例子，我现在知道的唯一方法是产生大量的例子并使用我的人类判断力，但如果你知道有一些关于自我意识的意识，那就更好了。

Ilya 00:53:48
100%.我是自我意识的忠实信徒，我认为我认为神经网络自我意识将允许像你描述的那些能力，比如让他们知道他们知道什么和他们不知道什么，让他们知道在哪里投资以最优化地增加他们的技能，并对一个问题的解释能力。这个问题实际上有两个答案。一个答案是，你知道，我们有神经网，所以我们可以分析神经元，我们可以尝试了解不同的神经元和不同的层意味着什么，你实际上可以做到这一点，开放已经在这方面做了一些工作，但有一个不同的答案，那就是我想说的以人为本的答案，你知道你看着一个人，你不能阅读，你怎么知道一个人的想法，你问他们，你说嘿，你对这个怎么看，你对那个怎么看，你得到一些答案。

Lex 00:54:40
你得到的答案是粘性的，在这个意义上，你已经有了一个心理模型，你已经没有了。是的，我的意思是人类的数量，你已经有了对人类的理解，就像一个大的概念，他们如何思考，他们知道什么，他们如何看待这个世界，然后你问的一切，你都是在这个基础上添加的，这种粘性似乎是。这就是人类真正有趣的品质之一。这种信息是有粘性的。你不，你似乎能很好地记住有用的东西，而忘记大部分没有用的信息，这个过程也很类似于神经网络的过程，只是神经网络在这个时候如此蹩脚。它似乎没有什么根本性的不同，但只是坚持推理的时间长一点。他说为什么不呢？为什么我不能推理，什么是好的令人印象深刻的壮举基准，对你的推理，你会对它的新主人能够做到的印象深刻。这是你已经想到的东西吗。

Ilya 00:55:49
好吧，我认为写出真正好的代码。我认为证明真正困难的定理，用开箱即用的方法解决开放性问题。

Lex 00:56:02
和呃排序的定理类型的数学问题。

Ilya 00:56:06
是的，我认为那些也是非常自然的例子。你知道，如果你能证明一个未经证实的理论，然后很难论证不要推理。所以顺便说一下，这又回到了关于硬性结果的问题上。你知道，如果你有心，如果你有机器学习深度学习作为领域是非常幸运的，因为我们有能力有时产生这些毫不含糊的结果，当它们发生时，辩论会改变，对话会改变。这是一个对话。我们有能力产生改变对话的结果

Lex 00:56:36
谈话。然后当然，就像你说的，人们有点认为这是理所当然的。说这其实不是一个难点。

Ilya 00:56:41
嗯，我的意思是，在某些时候，我们可能会用尽心脏问题。

Lex 00:56:46
是的。整个死亡率的问题是一个棘手的问题，我们还没有完全搞清楚。也许我们会解决这个问题。我认为在你的整个工作体系中，有一件令人着迷的事情，也是我最近开放的工作，其中一个对话变化是在语言模型的世界里。你能简要地尝试描述一下在语言和文本领域使用神经网络的近期历史吗？

Ilya 00:57:11
嗯，已经有很多历史了，我想，我想元素网络是一个小的，微小的递归网络，早在80年代就应用于语言。所以历史真的是，你知道，至少相当长。而开始改变神经网络和语言的轨迹的事情是改变了所有数据和计算的钋的轨迹的事情。因此，突然间，你从小的语言模型，它学习一点点，特别是语言模型，你可以，有一个非常清楚的解释，为什么他们需要大的才好，因为他们试图预测下一个词。所以我们不我们不知道什么。你会注意到非常非常宽泛的笔触，表面的模式，比如有时候有一些字符，这些字符之间有一个空间。你会注意到这种模式，你会注意到有时有一个昏迷，然后下一个字符是一个大写字母。你会注意到这种模式，最终你可能会开始注意到有某些词经常出现，你可能会注意到拼写是一件事，你可能会注意到句法，当你真正擅长所有这些，你开始注意到语义，你开始注意到事实，但为了实现这一点。语言模型需要更大。

莱克斯 00:58:28
让我们继续讨论这个问题，因为这是你和诺姆-乔姆斯基的分歧所在。所以你认为我们实际上是在采取渐进式的步骤，那种更大的网络更大的计算将能够得到语义学，从而能够理解语言，而不需要规范所喜欢的那种对语言结构的基本理解。就像呃把你的语言理论强加给学习机制。所以你是说，学习，你可以从原始数据中学习，语言的基础机制。

Ilya 00:59:10
嗯，我认为这很有可能。但我也想说，我并不真的我知道确切的是什么是乔姆斯基的意思。当他谈到他的时候，你说了一些关于强加你的结构语言的事情。我不是100%确定他的意思。但从经验上看，当你检查那些大型语言模型时，它们表现出理解语义的迹象，而小型语言模型则没有。我们已经看到，几年前，当我们做情感神经元的工作时，我们训练了一个小的，你知道，小壳STM来预测亚马逊评论中的下一个字符。我们注意到，当你把L.S.D.M.的规模从500个LSD自己增加到4000个sdm细胞时，那么其中一个神经元开始代表他们认为的故事的文章的情感，为什么呢，因为情感是一个相当的语义属性，而不是一个句法属性。

Lex 01:00:03
对于那些可能不知道的人来说，我不知道这是否是一个标准术语，但情绪是指无论它是积极的还是消极的。

伊利亚01:00:08
审查。这就对了。这是对某事感到高兴的人，是对某事感到不高兴的人。因此，在这里我们有一个非常明确的证据，即小的神经网络不能捕捉到情感，而大的神经网络可以。这又是为什么呢？嗯，我们的理论是，在某些时候，你用完了综合模型，你开始去关注其他东西

Lex 01:00:27
而随着规模的扩大，你很快就会耗尽模型的语法，然后你就会真正开始关注语义了。这将是一个想法。

Ilya 01:00:36
这就对了。因此，我不......我不想暗示我们的模型有完整的语义理解，因为那不是真的，但它们肯定显示了语义理解的迹象，部分语义理解。但是较小的模型并没有显示出那么低的迹象。

Lex 01:00:51
你能退一步说吗？什么是gpt 2？这是大的语言模型之一。那是在过去几年里对话的变化？

Ilya 01:01:00
是的，所以gpt two是一个有15亿个参数的转化器，它是在大约400亿个文本标记上训练出来的，这些文本是从reddit文章的链接中获得的，这些文章有三个以上的投票。

Lex 01:01:19
那变压器是什么？

Ilya 01:01:20
变压器是近代史上神经网络架构中最重要的进展。

Lex 01:01:26
什么是注意力？也许也是，因为我认为这是一个有趣的想法，不一定是技术上的，但注意力的想法与也许是什么复发的想法是不同的。

Ilya 01:01:37
神经网络代表。因此，现场是转化器是多种想法的同时组合，其中注意力是一个？你认为注意力是关键吗？不，它是一个关键，但它不是关键。转化器之所以成功，是因为它是多种想法的同时结合。而如果你去掉任何一个想法，它的成功率就会大打折扣。因此，变压器使用了大量的注意力，但注意力存在了几年，这可能是变压器的主要创新，它的设计方式是在Gpu上运行得非常快，这带来了巨大的差异。这是一件事，第二件事是变压器不是经常性的，这也是非常重要的，因为它是更浅的，因此更容易优化。因此，换句话说，要注意。它是，它真的很适合Gpu，而且它不是反复出现的，因此不那么深，更容易优化，这些因素的结合使它成功。所以现在它使它很好地利用了你的GPU，它允许你在相同的计算量下取得更好的结果，这就是它成功的原因。

Lex 01:02:48
你是否惊讶于变形金刚的工作效果和GTT两个工作。所以你在语言方面的工作，在转化器出现在语言方面之前，你已经有很多伟大的想法。所以你看到了前后的一整套革命。你感到惊讶吗？

Ilya 01:03:04
是的，有一点、

Lex 01:03:05
有一点。是的、

Ilya 01:03:07
我的意思是这很难它很难记住，因为你适应得非常快。但这绝对是令人惊讶的。这绝对是。事实上，你知道吗？我收回我的说法。这是......这是相当惊人的。看到产生这样的文字，真是令人惊讶。而且你知道，你得记住，我们在那个时候已经看到，你已经看到甘孜州在改进方面的所有这些进展。你知道，甘孜州产生的样本实在是令人惊讶。你有这些逼真的面孔，但文字并没有真正的进展。突然间，我们从你知道的，不管黑帮在2015年是什么，到最好的，最惊人的Ganz，一步到位，我真的很惊讶，即使理论预测。是的，你训练一个大的语言模型。当然你应该得到这个。

但是当你亲眼看到它时，那就是另一回事了。

Lex 01:03:51
而我们却能很快适应。而现在有呃种一些认知科学家写文章说，GTT两个模型并不能真正理解语言。我们很快就适应了，他们能把语言模型做得这么好是多么了不起。那么，你认为标准是什么？对于打动我们的是什么，它

Ilya 01:04:19
我不知道

Lex 01:04:20
你认为那个酒吧会不断被移动吗、

Ilya 01:04:23
当然。我认为当你开始看到真正戏剧性的经济影响时，那就是我认为在某种意义上，下一个障碍，因为现在如果你考虑到ai的工作，那真的很混乱。真的很难知道该如何看待所有这些进展。这有点像，好吧，你提前得到了，现在你可以做更多的事情，你已经有了另一个改进，你在某个时候有另一个很酷的演示。我认为在Ai之外的人，他们已经无法区分这种进步了。所以

Lex 01:04:55
我们正在讨论将俄语翻译成英语的问题，以及在俄语中如何有许多世界上其他国家不知道的杰出工作。这对中国人来说是真的，对很多科学家和一般的艺术作品来说也是真的。你认为翻译是我们将看到经济大影响的地方吗？

Ilya 01:05:14
我不知道，我认为，我认为有大量的公众，我的意思是首先，我想我想指出今天的翻译已经是巨大的。我认为数十亿人主要通过翻译与互联网的大块内容互动。因此，翻译已经是巨大的，它也是巨大的积极的。我认为自动驾驶将产生巨大的影响，你知道的，具体何时发生还不知道。但同样，我不会打赌，深度学习。所以我

Lex 01:05:44
所以这就是一般的深度学习，但你

Ilya 01:05:47
继续学习自我驾驶。

Lex 01:05:48
是的。用于自动驾驶的深度学习，但我说的是语言的种类。

Ilya 01:05:51
模型，只是你的胡须掉了一点儿

Lex 01:05:54
我只是想确认一下，你是不是看到了驾驶和其他方面之间的联系。

伊利亚 01:05:57
语言。不，不。好吧，好吧。都是使用神经网络、

Lex 01:06:00
会有一种诗意的联系。我想可能会有一些，就像你说的，可能会有某种统一，走向呃我那种多任务的转化器，可以同时承担语言和视觉的任务，是一种有趣的统一。现在，让我们看看，我还能问什么关于GPT两个。嗯、

Ilya 01:06:21
它很简单，所以没有太多的要求，把它，把它拿去改造，你让它给它更多的数据，突然间它就做了所有这些惊人的事情。

Lex 01:06:29
美丽的事情之一是，GPT的变压器从根本上说是简单的，可以解释为训练。是的。你认为更大的会在语言方面继续显示出更好的结果吗？

Ilya 01:06:44
可能是

Lex 01:06:45
有点像GTT两人的下一步是什么，你觉得呢？

Ilya 01:06:48
我的意思是，我想肯定的是，看看更大的版本能做什么也是一个方向。我的意思是有有很多问题，有一个问题，我很好奇接下来的问题。所以现在GPT二。所以我们从互联网上拟合了所有这些数据，这意味着它需要记住所有那些关于互联网上所有东西的随机事实，如果这个模型能够以某种方式使用自己的智慧来决定它要接受哪些数据，大卫要拒绝哪些数据，那就更好了。就像人一样，人们不会不分青红皂白地学习所有数据。我们对我们所学的东西是有超级选择性的。我认为这种主动学习我认为是非常好的，可以有

Lex 01:07:31
是的。听着，我喜欢主动学习。那么，让我问一下，数据的选择，你能再详细说明一下吗？你认为数据的选择就像，我有这种感觉，你如何选择数据的优化。所以主动学习过程将是一个有很多突破的地方，甚至在你的未来，因为那里还没有很多突破是公开的。我觉得可能会有公司自己保留的私人突破，因为如果你想解决自动驾驶，如果你想解决一个特定的任务，就必须解决根本问题，你对这个空间总体上怎么看？

Ilya 01:08:14
是的。所以我认为，对于像主动学习这样的东西，或者事实上对于任何一种能力，比如主动学习，它真正需要的是一个问题。它需要一个需要它的问题，如果你没有一个任务，就很难做关于能力的研究，因为接下来会发生的是，你会想出一个人工任务，得到好的结果，但并没有真正说服任何人？

Lex 01:08:37
对吗？就像我们现在已经过了得到呃结果的阶段，而不是一些聪明的制定残余的人将说服人们？

Ilya 01:08:47
这就对了。事实上，你可以很容易地想出一个简单的关于赦免的主动线方案，并获得10倍的速度。但那又怎么样呢？我认为，有了主动学习，他们的需求，他们需要主动学习会自然产生，因为有需要主动学习的问题冒出来了。这就是我的看法，这是我的，我对它的看法。

Lex 01:09:09
还有另一个有趣的事情，作为GTT二号带来的开放，那就是当你创造了一个强大的人工智能系统，不清楚一旦你发布GPT二号，会有什么样的不利影响，因为如果你有一个模型，可以生成一个相当现实的文本，你可以开始想象，你知道，在它会被机器人和一些我们甚至无法想象的一些方式使用。因此，就像有这种紧张的感觉，什么是可能做的？因此，你做了一件非常勇敢的事情，我认为是深刻的事情，这刚刚开始了关于这个的对话。就像我们如何发布强大的人工智能模型，公众如果做这一切，我们如何私下与其他，甚至竞争对手讨论我们如何管理系统的使用等等。因此，从这一点来看，这整个经验，你已经发布了一份报告。但总的来说，你有没有从思考这个问题中收集到一些见解，关于你如何发布这样的模型？

Ilya 01:10:14
我的意思是，我认为我对这个问题的看法是，人工智能领域一直处于童年状态，现在它正在退出这种状态，进入成熟状态。这意味着这个想法是非常成功的，也是非常有影响力的，它的影响不仅大，而且还在增长。因此，出于这个原因，在我们听取我们的系统之前开始考虑其影响似乎是明智的，也许有点太早，而不是有点太晚。就像我前面提到的GPT 2的情况，结果真的很惊人，而且似乎很有道理。它似乎并不确定，像GTT二号这样的东西可以很容易地用来减少这种信息的成本，这是不可能的。因此，有一个问题是什么是最好的方式来发布它，分阶段发布似乎是合理的。一个小模型被发布了，有时间看到许多人以许多很酷的方式使用这些模型。已经有很多非常酷的应用。据我们所知，还没有任何负面的应用，所以最终它被发布了，但也有其他人复制了类似的模型。

Lex 01:11:27
这是一个有趣的问题，虽然我们知道。所以在你看来，阶段性释放作为呃，至少是对我们如何如何的问题的部分答案，一旦我们创建了这样一个系统，我们该怎么做？

Ilya 01:11:42
这是答案的一部分，是的。

Lex 01:11:44
有没有其他的见解，比如说，你根本就不想发布这个模型，因为它对你有什么业务上的帮助、

Ilya 01:11:52
虽然有很多人已经不发布模型了。

Lex 01:11:55
对，当然了。但是，当你有一个非常强大的模型来进行沟通时，是否有一些道德伦理上的责任，就像你说的，当你有GPT 2时，不清楚你能在多大程度上被用于误导。这是一个开放的问题，要得到答案可能需要你与其他真正聪明的人交谈，这些人在你的特定小组之外。请你告诉我，是否有一些乐观的途径，让世界各地的人在这些案件上进行合作，或者说，从一家公司到另一家公司谈话仍然非常困难？

Ilya 01:12:36
所以，这绝对是可能的。绝对有可能与其他地方的同事讨论这类模型，并得到他们对如何做的看法？

Lex 01:12:49
不过这有多难呢？

Ilya 01:12:50
我是说

Lex 01:12:53
你认为会发生这种情况吗？

Ilya 01:12:54
我认为这是一个在公司之间逐步建立信任的重要地方，因为最终所有的ai开发者都在建造技术，而这些技术将越来越强大。因此，这是思考问题的方式。是，最终只有在一起。

Lex 01:13:15
是的，我倾向于相信我们本性中更好的天使，但我确实希望，当你在某个特定领域建立一个真正强大的Ai系统时，你也会考虑到潜在的负面后果。是的。是的，这是一种有趣而可怕的可能性。将会有一场ai ai开发的竞赛，会推动人们关闭该开发，不与他人分享想法。

Ilya 01:13:50
我不爱这个。我在纯学术界呆了10年，我真的很喜欢分享想法，这很有趣，很刺激。嗯。

Lex 01:13:58
你认为需要什么，让我们来谈谈G.I，你认为需要什么来建立一个人类水平的智能系统？我们谈到了推理，我们谈到了长期记忆，但总的来说，它需要什么呢？你认为呢？

Ilya 01:14:10
嗯，我不能确定，但我认为深度学习加上也许是另一个小想法、

你认为自我游戏会不会参与其中？
你认为自我游戏会参与其中吗？就像你所说的强大的自我游戏机制一样，系统通过在竞争环境中探索世界，与其他与他们有类似技能的实体进行竞争，因此以这种方式逐步提高？你认为自我游戏将是建立A G. I.系统的一个组成部分。

Ilya 01:14:44
是的。所以我想说的是，要建立一个G，我认为这将是深度学习加上一些想法，我认为自我发挥将是这些想法之一。我认为，这是一个非常自我的游戏，有这个惊人的属性，它可以以真正新颖的方式给我们带来惊喜。例如，像我们我的意思是几乎每一个自我放置系统都是我们的女儿买的。我不知道是否开放，我有一个关于多代理的发布，你有两个小代理在玩捉迷藏，当然还有阿尔法零，他们都产生了令人惊讶的行为。他们都产生了我们没有想到的行为，他们对问题的创造性解决方案，这似乎是一个G的重要组成部分，我们的系统现在没有表现出常规。因此，这就是为什么我喜欢这个领域，比如这个方向，因为它有能力让我们吃惊

Lex 01:15:44
来给我们带来惊喜。而这个系统会让人惊讶

Ilya 01:15:47
根本。是的。但是，而且准确地说，不只是不只是一个随机的惊喜，而是要找到一个令人惊讶的解决问题的方法。这也是有用的吧

Lex 01:15:56
现在很多自我发挥的机制已经在游戏背景下或至少在模拟背景下被使用了？Mm hmm.你认为有多少，有多少，在通往e G的道路上有多远会在模拟中完成？你对模拟有多少信心，而不是必须有一个在现实世界中运作的系统，无论是现实世界的数字、现实世界的数据，还是现实世界的机器人技术，比如实际的物理世界。

Ilya 01:16:30
我不认为这是一场简单的战争。我认为模拟是一种工具，它有助于它有某些优势和某些弱点，我们应该使用它。

Lex 01:16:38
是的。不过还好。我明白，那是嗯，那是真的。但自我发挥的批评之一，批评之一和强化学习是它目前的力量之一。它目前的结果虽然令人惊讶，但已经在模拟环境或非常有限的物理环境中得到了证明。你认为有可能让他们逃离模拟环境，并能够在非模拟环境中学习吗？或者你认为有可能也只是以照片逼真和物理逼真的方式模拟现实世界，使我们能够在模拟中通过自我发挥来解决实际问题。

Ilya 01:17:23
所以我认为，从模拟到现实世界的转移是绝对可能的，而且已经被许多不同的团体展示过很多次。它已经特别成功了。Envision也在夏天展示了一个机器人手，它完全是在模拟中以某种方式训练的，允许似乎是真实的转移发生。

Lex 01:17:46
这是给魔方的吗？

Ilya 01:17:48
cube.这就对了

Lex 01:17:49
我不知道这是在训练中。

Ilya 01:17:51
模拟是完全在模拟中训练的。

Lex 01:17:54
真的。所以不是在物理学上，手没有被训练。

Ilya 01:17:57
没有100%的训练是在模拟中完成的，在模拟中学习的政策被训练得非常有适应性，适应性非常强，当你转移它时，它可以非常迅速地适应物理的物理。

Lex 01:18:10
世界。因此，长颈鹿的那种扰动或不管它是什么。这些都是模拟的一部分。

Ilya 01:18:18
好吧，一般来说，模拟是这样的，所以模拟被训练成对许多不同的事情具有鲁棒性，但不是我们在视频中的那种扰动。因此，它从来没有接受过手套的训练。它从来没有接受过长颈鹿毛绒玩具的训练。

Lex 01:18:34
所以从理论上讲，这些都是新颖的

Ilya 01:18:35
缓刑，对吗？在实践中，理论上是没有的。

Lex 01:18:37
还有，那些是小说的感化。嗯，没关系，那是一个干净的小规模但干净的从模拟世界转移到物理世界的例子

Ilya 01:18:48
世界。而且我还要说，我期望深度学习的转移能力普遍提高，转移能力越好，模拟就越有用。因为这样你就可以在模拟中经历一些事情，然后学到故事的寓意，然后你就可以带着这些寓意进入现实世界，就像人类在玩电脑游戏时经常做的那样。所以

Lex 01:19:15
让我问一个体现性的问题，在一个G上停留一下。你认为A. Js仍然是我们需要有一个身体，我们需要有一些自我意识的人类元素？意识是对死亡的恐惧，是在物理空间中的自我保护，这与拥有一个身体有关？

Ilya 01:19:37
我认为有一个身体会很有用。我不认为这是必要的，但我认为有一个身体肯定是非常有用的。因为你可以学到全新的东西，你可以学到没有身体就学不到的东西。但与此同时，我认为你可以，如果你没有身体，你可以弥补它，仍然可以成功。我想是的。是的。嗯，有证据表明，例如，有许多人天生就是聋子和瞎子，他们能够弥补模式的不足。我特别想到了海伦-凯勒。

我的意思是，我实际上是在问，也许让我问一下更特别的问题，我不知道这是否和你有关。
所以，即使你不能与世界进行物理上的互动，如果你不能......我的意思是，我实际上是在得到也许让我问在更特别的，我不确定它是否与拥有一个身体有关，但意识的想法和一个更受约束的版本是自我意识。你认为我需要一个系统应该有意识吗？这是我们无法定义的上帝，不管你认为意识是什么。

Ilya 01:20:36
是的，这个问题很难回答。鉴于它的定义有多难、

Lex 01:20:41
你认为思考是否有用

Ilya 01:20:42
关于什么？我的意思是，它是它是绝对有趣的。这很吸引人。我认为，我们的援助绝对有可能是有意识的。

Lex 01:20:50
做为一种新兴的东西，只是来自于。你认为意识会从储存在你的网络中的表征中出现吗？所以，当你变得越来越多，你能够代表越来越多的世界时，它自然就会出现。

Ilya 01:21:04
好吧，是我提出以下论点，即人类是有意识的，如果你相信人工神经网络与大脑足够相似，那么至少应该存在人工神经元，我们应该有意识到。

Lex 01:21:20
你对那个存在性证明的倚重程度很高。好吧。

Ilya 01:21:25
但这是我能做的最好的回答了

Lex 01:21:28
给。不，我我知道我知道，我知道。嗯，仍然有一个开放的问题，如果大脑中没有一些我们不知道的魔法？我的意思是，我不是指非物质主义的魔力，而是指大脑可能比我们给它的信用要复杂和有趣得多。

Ilya 01:21:46
如果是这样的话，那么它应该显示出来，在某些时候我们会发现我们可以继续取得进展。但我认为我认为这不太可能。

Lex 01:21:55
所以我们谈论意识，但让我谈谈另一个定义不明确的概念--智力。同样，我们已经谈论过推理，我们已经谈论过记忆。你认为这对你来说是一个很好的智力测试吗？你是否对阿兰-图灵用自然语言的模仿游戏制定的测试印象深刻。在你的脑海中是否有这样的东西，如果一个系统能够做到，你会被深深地打动、

Ilya 01:22:23
我的意思是很多事情。有某些......有某些前沿，今天有某些前沿的能力。是的，还有一些在前沿之外的东西，我会被任何这样的东西所打动，例如，我会被一个深度学习系统所打动，该系统可以解决一个非常普通的行人任务，如机器翻译或计算机视觉任务，或一些在任何情况下都不会犯人类不会犯的错误。我认为这是还没有被证明的东西，我会觉得它非常令人印象深刻。

Lex 01:22:59
是的，所以现在他们在不同的地方犯错，他们可能在人类身上更准确，但他们仍然会犯一系列不同的错误。

Ilya 01:23:06
所以我的我的我猜想，一些人对深度学习的很多怀疑是当他们看着自己的错误，他们说好吧那些错误他们没有意义。就像如果你理解了这个概念，你就不会犯这样的错误，我认为改变这一点会是会启发我，是的，这就是这就是这就是进步。

Lex 01:23:29
是的，那是那是一个非常好的说法。但我也只是不喜欢人类本能地批评模型不聪明，这和我们批评任何一群生物时的本能是一样的，因为是的，Gpt 2很有可能比人类和很多东西都要聪明的多。

Ilya 01:23:53
这绝对是真的。它的知识广度要大得多。

Lex 01:23:56
是的知识的广度，甚至甚至可能是某些主题的深度。

Ilya 01:24:02
要判断深度是什么意思有点难。但肯定有一种意义，那就是人类不会犯错，而这些模型会犯错。

Lex 01:24:11
同样的情况也适用于自动驾驶车辆。同样的情况可能会继续被应用于很多人工智能系统。我们发现这是恼人的。这是在21世纪的过程。分析人工智能进展的过程就是寻找一个系统失败的案例。你知道大的方式，人类不会。然后许多人写关于它的文章，然后广泛地作为公众普遍被说服，该系统是不智能的，我们喜欢安抚自己，但我认为它不智能，因为这一个轶事案例，这似乎继续发生。

Ilya 01:24:51
是的，我的意思是有真相，有的人虽然我相信很多人也对今天的制度印象极深。但我认为这与我们之前讨论的观点相联系，即判断Ai的进展只是混乱的。是的，你知道你有一个新的机器人展示了一些东西，你应该有多大的印象。我认为，一旦我开始在G.D.P.上真正有所进展，人们就会开始留下深刻印象。

Lex 01:25:17
所以，你是可能在这里创建媒体系统的人之一 不是你，而是你和开艾如果你真的创建了一个系统，你就可以和它一起度过那种夜晚。他她。你会谈论什么 你认为

Ilya 01:25:34
第一次的时候是什么时候？好吧，第一次我只是会问各种各样的问题，并试图让它犯错，那会很惊讶，它不犯错，只是一直不停地问宽。好吧，什么类型的

你认为有哪些问题？
你认为是什么问题？它们是事实性的还是个人情感性的、心理性的。你是怎么想的？

Ilya 01:25:59
以上都是你肯定会问的建议。我的意思是为什么我为什么要限制自己与这样的系统交谈？

Lex 01:26:09
现在让我再次强调一个事实，你真的是可能在这个房间里发生的人之一。所以让我问一个有点深刻的问题，我刚刚和斯大林谈过他的故事。我一直在和很多研究权力的人交谈。亚伯拉罕-林肯说，几乎所有的人都能忍受逆境。但如果你想测试一个人的性格，给他权力，我会说21世纪的权力，也许是22世纪，但希望21世纪是建立一个A.G.I.系统，以及拥有控制权的人直接拥有和控制这个系统。那么，在花了那个晚上与A.G.I.系统进行讨论之后，你认为你会怎么做呢？

Ilya 01:27:03
好吧，我想想象的理想世界是这样的：人类。我喜欢一个公司的董事会成员，他们是首席执行官。因此，我喜欢这样的画面：你有一些不同的实体，不同的国家和城市，人们投票选择代表他们的A.G.应该做什么，一个代表他们的机构去做什么？我认为这样的画面我觉得非常吸引人。你可以有八个人，你会有一个城市或国家的代理人，这将是试图在实际上把民主进程带到下一个阶段。

Lex 01:27:52
级别和董事会可以随时解雇首席执行官

Ilya 01:27:55
基本上按重置按钮说重新随机化参数。

Lex 01:27:59
但是，让我排序，这实际上是好的，这是一个美丽的愿景。我认为只要有可能按下重启按钮。你认为永远有可能按下重启键吗？

Ilya 01:28:12
但是，所以我认为，这绝对是它绝对是真的可以建立。所以你在说。所以，我从你那里真正理解的问题是，人类或人类的人是否会对建造的ai系统进行控制。是的。我的回答是，绝对有可能建立希望由人类控制的人工智能系统。

Lex 01:28:38
哇，那是他们的一部分。所以并不是说他们不能不被控制，而是说他们存在的原因。他们存在的目的之一就是要被控制在

Ilya 01:28:51
就像人类父母一般想帮助他们的孩子一样。他们希望他们的孩子能够成功。这对他们来说不是一种负担。他们兴奋地帮助孩子们，给他们提供食物，解决他们的问题，照顾他们。我坚信，同样的情况也可能发生在A. G.身上。将有可能对A. G.进行编程，以这样的方式设计它，它将有类似的深层驱动力，它将乐于实现这一驱动力，帮助人类繁荣。

Lex 01:29:28
但让我退一步说，当你创建A.G.I.系统的那一刻。我认为这是一个非常关键的时刻。而在那个时刻和民主董事会成员与G.在头之间，必须有一个放弃权力的过程。乔治-华盛顿也是如此，尽管他做了很多坏事。他做的一件大事是你放弃这里的权力，首先，不想当总统，甚至当他成为总统时，他给他没有像大多数独裁者那样一直只是无限期地任职。你认为自己能够放弃对任何G.I.系统的控制，鉴于你可以对世界拥有多大的权力？

起初金融只是赚大钱的权利，然后通过拥有GI系统来控制。

Ilya 01:30:24
我会发现这样做是微不足道的。我发现裁决这种部分是微不足道的。我的意思是，你知道，你所描述的那种情况对我来说听起来很可怕。这都是我绝对不希望处于那个位置。

Lex 01:30:38
你认为你代表眼科界的大多数人还是少数人？

Ilya 01:30:46
虽然，我的意思是、

Lex 01:30:47
这是一个开放的问题，一个重要的问题。大多数人是好的吗是另一种问法

Ilya 01:30:52
它。因此，我不知道大多数人是否是好的，但我认为，在真正关键的时候，人们可以比我们想象的更好。

Lex 01:31:04
这句话说得很好。是的。在使爱因斯坦的价值观与人类价值观相一致方面，你能想到的具体机制吗？在我们发展空气系统的过程中，你是否考虑过这些持续调整的问题？

Ilya 01:31:17
是的，当然。在某种意义上，你所问的那种问题是，如果你能够把这个问题翻译成今天的术语，这将是一个关于如何获得一个优化价值函数的RL代理的问题，而这个价值函数本身是学习的，如果你看一下人类，人类就是这样，因为奖励函数，人类的价值函数不是外部的。它是内部的。而且有明确的想法，即如何训练一个价值函数，基本上是一个客观的，尽可能客观的感知系统，它将被单独训练，以识别，内化人类对不同情况的判断，然后该部分不会被整合为价值，作为一些更有能力的空中系统的基础价值函数。你可以想象这样的一个过程。我并不是说这就是这个过程。我是说这是一个你可以做的事情的例子

Lex 01:32:24
所以在人类生存的客观功能这个话题上。你认为什么是客观功能？人类存在中的那个简单性？的意义是什么？

Ilya 01:32:35
生活？哦，mm hmm。我认为这个问题在某些方面是错误的。我认为这个问题暗示着，之所以有一个客观的答案，这是一个外部的答案。你的生命的意义是X。我认为现在的情况是，我们存在。而这是惊人的。而我们应该尝试充分利用它，并尝试在我们存在的这段非常短暂的时间里最大限度地发挥我们自己的价值和享受。

Lex 01:33:10
这很有趣，因为行动确实需要一个目标函数肯定是以某种形式存在的，但很难把它明确化，可能不可能明确化，我想是你的意思，这也是RL环境中一个有趣的事实？

Ilya 01:33:25
好吧，我所提出的稍微不同的观点是，人类想要的东西和他们的愿望创造了导致他们对我们的愿望的驱动。我们的我们的目标函数是个人目标函数。我们后来可以决定我们要改变这一点。我们之前想要的东西不再好了，你想要别的东西。

Lex 01:33:44
但他们是如此的有活力，一定有一些潜在的弗洛伊德的东西。有一些东西，比如性的东西，还有人们认为是对死亡的恐惧，还有对知识的渴望，你知道，所有这些种类的东西都被占用。他们是所有进化论的论据，似乎可能有某种基本的客观功能，从那里其他的东西嗯出现。但似乎因为

Ilya 01:34:12
这是非常我的意思是，我认为我认为这可能是一个进化的目标功能，就是生存和繁殖，使你使你的学生成功。这将是我的猜测，但它并没有给出问题的答案，生命的意义是什么？我想你可以看到人类是这个大过程的一部分，这个古老的过程。我们是我们是他们存在于一个小星球上，仅此而已。所以鉴于我们的存在，要尽量利用它，尽量多享受，少受罪。

Lex 01:34:46
让我问一些关于生活的愚蠢问题。一是你是否有遗憾的时刻，如果你回到过去，你会以不同的方式去做；二是是否有让你特别自豪的时刻，让你真正感到幸福。

Ilya 01:35:01
所以我可以回答这个问题。我可以回答这两个问题。当然，有，有大量的选择和决定，事后看来，我不会做出这些选择和决定，我确实经历了一些遗憾，但你知道，我试着安慰自己，知道当时我做了他们能做的最好的事情，就我为之骄傲的事情而言，我非常幸运，有我为之骄傲的事情，它们使我在一段时间内感到幸福，但我不认为那是幸福的来源。

Lex 01:35:31
所以你的学术成就，所有的论文，你是世界上被引用最多的人之一。我提到的在计算机视觉和语言等方面的所有突破是幸福和的来源。

Ilya 01:35:45
为你感到骄傲。我的意思是，所有这些事情都是骄傲的来源，这是肯定的。我非常感谢做了所有这些事情，做这些事情非常有趣。但是幸福来自于，但是你知道你可以幸福，我现在的观点是，幸福来自于我们在很大程度上看待事物的方式，你可以吃一顿简单的饭，结果是相当幸福。或者你可以和别人聊天，结果也很开心。或者相反，你可以吃一顿饭，但对这顿饭不是更好的饭感到失望。所以我认为很多幸福来自于此，但我不确定我不想太自信。I

Lex 01:36:22
在不确定的情况下保持谦逊，这似乎也是幸福这件事的一部分。好吧，我认为没有比呃生命的意义和对幸福的讨论更好的方式来结束它。所以，阿列克谢，非常感谢你。你给了我一些不可思议的想法，你给了世界许多不可思议的想法。我真的很感激。也感谢你的谈话

Ilya 01:36:43
今天，你知道的，谢谢你停下来，真的很喜欢。

Lex 01:36:47
     
感谢收听这次与外星人的对话发现，感谢我们的介绍赞助商Cash up。请考虑通过下载cash up和使用Code Lex podcast来支持这个播客。如果你喜欢这个播客，请在Youtube上订阅，在苹果播客上评论五颗星，在Patreon上支持，或者干脆在twitter上与我联系：lex Friedman，现在让我用阿兰-图灵关于机器学习的一些话离开你，而不是试图制作一个程序来模拟成年人的思维。为什么不尝试制作一个模拟儿童的程序，如果这个程序再经过适当的教育课程，就会得到成人的大脑。谢谢您的聆听，希望下次再见。
