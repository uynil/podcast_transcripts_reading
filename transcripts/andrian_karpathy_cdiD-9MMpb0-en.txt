Andrej  00:28:07
Yeah, I don't know what the terminating conditions are, but definitely there's a trend line of something and we're part of that story and like where does that, where does it go? So, you know, we're famously described often as a biological boot loader for ai and that's because humans, I mean, you know, we're an incredible biological system and we're capable of computation and uh you know, and love and so on. Um but we're extremely inefficient as well. Like we're talking to each other through audio. It's just kind of embarrassing honestly that we're manipulating like seven symbols serially. We're using vocal cords. It's all happening over like multiple seconds. It's just like kind of embarrassing when you step down to the frequencies at which computers operate or are able to cooperate on. And so basically it does seem like um synthetic intelligences are kind of like the next stage of development and um I don't know where it leads to like at some point I suspect the universe is some kind of a puzzle. And these synthetic a eyes will uncover that puzzle and solve it. And

Lex  00:29:10
then what happens after right? Like what? Because if you just like fast forward earth many billions of years it's like it's quiet and then it's like normal you see like city lights and stuff like that. And then what happens at like at the end like is it like a pro is it or is it like a calming is it explosion? Is it like

Andrej  00:29:29
Earth? Like open like

Lex  00:29:30
a giant because you said emit roasters will start admitting like like a giant number of like satellites?

Andrej  00:29:40
Yes. It's some kind of a crazy explosion and we're living we're like we're stepping through a explosion and we're like living day to day and it doesn't look like it but it's actually if you I saw a very cool animation of Earth and life on Earth and basically nothing happens for a long time. And then the last like two seconds like basically cities and everything and in the lower orbit just gets cluttered and just the whole thing happened in the last two seconds and you're like this is exploding statement explosion.

Lex  00:30:05
Yeah if you play it at normal speed is it'll just look like an explosion.

Andrej  00:30:11
It's a firecracker. We're living in a firecracker

Lex  00:30:13
where it's going to start emitting all kinds of interesting things and then the explosion doesn't, it might actually look like a little explosion with with lights and fire and energy emitted all that kind of stuff. But when you look inside the details of the explosion there's actual complexity happening where there's like yeah human life or some kind of life

Andrej  00:30:35
we hope it's another destructive firecracker. It's kind of like a constructive firecracker. Alright

Lex  00:30:41
so given that

Andrej  00:30:43
I think is

Lex  00:30:43
hilarious, it

Andrej  00:30:44
is a really interesting to think about like what the puzzle of the universe is that the creator of the universe. Give us a message. Like for example in the book contact um Carl Sagan, there's a message for humanity for any civilization in the digits In the expansion of Pi in base 11 eventually which is kind of interesting thought maybe maybe we're supposed to be giving a message to our creator, maybe we're supposed to somehow create some kind of a quantum mechanical system that alerts them to our intelligent presence here because if you think about it from their perspective, it's just say like quantum field theory massive like cellular automaton like thing. And like how do you even notice that we exist? You might not even be able to pick us up in that simulation. And so how do you how do you prove that you exist, that you're intelligent and that you're part of the universe? So

Lex  00:31:31
this is like a touring test for intelligence from earth.

Andrej  00:31:33
Like the

Lex  00:31:34
creator is uh I mean maybe this is like trying to complete the next word in the sentence. This is a complicated way of that. Like Earth is just is basically sending a message back.

Andrej  00:31:44
Yeah, the puzzle is basically like alerting the creator that we exist or maybe the puzzle is just to just break out of the system and just you know, stick it to the creator in some way basically like if you're playing a video game, you can um you can somehow find an exploit and find a way to execute on the host machine any arbitrary code. There's some uh for example, I believe someone got Mario game of Mario to play pong just by uh exploiting it and then um creating uh basically writing writing code and being able to execute arbitrary code in the game. And so maybe we should be, maybe that's the puzzle is that we should be um find a way to exploit it. So so I think like some of these synthetic ads will eventually find the universe to be some kind of a puzzle and then solve it in some way. And that's kind of like the endgame somehow.

Lex  00:32:30
Do you often think about it as um as a simulation? So as the universe being kind of computation that has might have bugs and exploits?

Andrej  00:32:41
Yes. Yeah, I think so. Physics

Lex  00:32:43
is essentially,

Andrej  00:32:44
I think it's possible that physics has exploits and we should be trying to find them arranging some kind of a crazy quantum mechanical system that somehow gives you buffer overflow somehow gives you a rounding error in the floating point. Uh

Lex  00:32:57
Yeah, that's right. And like more and more sophisticated exploits. Those are jokes, but that could be actually

Andrej  00:33:04
very close. We'll find some way to extract infinite energy. For example, when you train reinforcement learning agents um in physical simulations and you ask them to say run quickly on the flat ground, they'll end up doing all kinds of weird things. Um in part of that optimization, right? They'll get on their back legs and they will slide across the floor and it's because the optimization, um the enforcement learning optimization on that agent has figured out a way to extract infinite energy from the friction forces and um basically they're poor implementation and they found a way to generate infinite energy and just slide across the surface and it's not what you expected. It's just a it's sort of like a perverse solution. And so maybe we can find something like that. Maybe we can be that little dog in this physical simulation,

Lex  00:33:45
the cracks or escapes the intended consequences of the physics that the universe came up with. We'll figure out some kind of shortcut to some weirdness and then but see the problem with that weirdness is the first person to discover the weirdness, like sliding in the back legs, that's all we're gonna do.

Andrej  00:34:05
Yeah,

Lex  00:34:06
it's very quickly because everybody does that thing. So like the paperclip maximize er is a ridiculous idea, but that very well could be what then we'll just we'll just all switch that because it's so fun.

Andrej  00:34:21
Well no person will discover it. I think by the way I think it's going to have to be uh some kind of a super intelligent A. G. I. Of a third generation, like we're building the first generation A. G. I. You know,

Lex  00:34:33
third generation. Yeah, so the bootloader for an ai that ai will be a bootloader for another

Andrej  00:34:42
guy

Lex  00:34:43
and then there's no way for us to introspect. Like what might even, I

Andrej  00:34:47
think it's very likely that these things for example, like so you have these G. I. S. It's very likely, for example, they will be completely inert. I like these kinds of sci fi books sometimes where these things are just completely inert. They don't interact with anything and I find that kind of beautiful because they probably they probably figured out the meta meta game of the universe in some way, potentially they're they're doing something completely beyond our imagination. Um and they don't interact with simple chemical life forms, like why would you do that? So I find those kinds of ideas compelling.

Lex  00:35:17
What's their source of fun? What are they, what are they doing

Andrej  00:35:20
solving in the universe?

Lex  00:35:22
But inert. So can you define what it means inert? So they escape the interaction,

Andrej  00:35:28
physical realities as in um uh They will behave in some very like strange way to us because they're they're beyond their playing the meta game. And the meta game is probably say like arranging quantum mechanical systems in some very weird ways to extract infinite energy uh solve the digital expansion of pi to whatever amount they will build their own like little fusion reactors or something crazy. Like they're doing something beyond comprehension and not understandable to us and actually brilliant under the hood.

Lex  00:36:00
What if quantum mechanics itself is the system? And we're just thinking it's physics but we're really parasites on not parasite. We're not really hurting physics. We're just living on this organism and this organism and we're like trying to understand it. But really it is an organism. And with a deep deep intelligence maybe physics itself is uh the the organism that's doing the super interesting thing and we're just like one little thing.

Andrej  00:36:32
Yeah

Lex  00:36:33
and sitting on top of it trying to get energy from it.

Andrej  00:36:36
We're just kind of like these particles in the wave that I feel like it's mostly deterministic and takes universe from some kind of a big bang to some kind of a super intelligent replicator, some kind of a stable point in the universe given these laws of physics, you

Lex  00:36:50
don't think uh as Einstein said, God doesn't play dice, so you think it's mostly deterministic, there's no randomness and the thing

Andrej  00:36:57
I think is deterministic, there's tons of, well, I want to be careful with randomness,

Lex  00:37:01
pseudo random.

Andrej  00:37:02
Yeah, I don't like random. I think maybe the laws of physics are deterministic. Um Yeah, I think they're determined

Lex  00:37:09
just got really uncomfortable with this question. I do you have anxiety about whether the universe is random or not? What's there's

Andrej  00:37:18
no randomness

Lex  00:37:19
you like? Good will hunting, It's not your fault andrei

Andrej  00:37:23
it's

Lex  00:37:23
your fault, man. Um So you you don't like randomness uh

Andrej  00:37:28
yeah, I think it's unsettling, I think it's a deterministic system. I think that things that look random, like say the collapse of the wave function, et cetera. I think they're actually deterministic, just entanglement and so on and some kind of a multiverse theory something something.

Lex  00:37:43
Okay, so why does it feel like we have a free will, like if if I raised his hand, I chose to do this now. Um what that doesn't feel like a deterministic thing, it feels like I'm making a choice,

Andrej  00:37:58
it feels like it

Lex  00:37:59
okay, so it's all feelings, it's just feelings. So when RL agent is making a choice is that um it's not really making a choice, the choice is already there.

Andrej  00:38:11
Yeah. You're interpreting the choice and you're creating a narrative for for having made it.

Lex  00:38:15
Yeah. And now we're talking about the narrative, it's very matter. Looking back what is the most beautiful or surprising idea in deep learning or ai in general that you've come across, you've seen this field explode uh and grow in interesting ways. Just what what cool ideas like, like we made you sit back and go small, big or small.

Andrej  00:38:39
Well, the one that I've been thinking about recently the most probably is the

Lex  00:38:44
the

Andrej  00:38:44
transformer architecture. Um so basically uh neural networks have a lot of architectures that were trendy have come and gone for different sensory modalities, like for vision, audio, text, you would process them with different looking neural nuts. And recently we've seen these this convergence towards one architecture, the transformer and you can feed it video or you can feed it, you know, images or speech or text and it just gobbles it up and it's kind of like a Bit of a general purpose computer that is also trainable and very efficient to run in our hardware. And so this paper came out in 20

Lex  00:39:18
16, I

Andrej  00:39:19
want to say

Lex  00:39:20
attention is all you need

Andrej  00:39:21
attention is all you need, You

Lex  00:39:23
criticized the paper title in retrospect that it wasn't um it didn't foresee the bigness of the impact that it was going to

Andrej  00:39:32
have. I'm not sure if the authors were aware of the impact that that paper would go on to have probably weren't, but I think they were aware of some of the motivations and design decisions behind the transformer and they chose not to, I think expand on it in that way in the paper. And so I think they had an idea that there was more um, than just the surface of just like, oh we're just doing translation and here's a better architecture. You're not just doing translation. This is like a really cool differentiable optimism, efficient computer that you've proposed and maybe they didn't have all of that foresight. But I think it's really interesting,

Lex  00:40:01
isn't it funny, Sorry to interrupt that that title is memorable that they went for such a profound idea. They went with the I don't think anyone used that kind of title before. Right,

Andrej  00:40:12
attention is all you need. It's like a meme or something.

Lex  00:40:15
It's not funny that one. Like maybe

Andrej  00:40:19
if

Lex  00:40:20
it was a more serious title didn't have the impact.

Andrej  00:40:22
Honestly, I yeah, there is an element of me that honestly agrees with you and prefers it this way.

Lex  00:40:28
If

Andrej  00:40:29
it was two grand it would over promise and under deliver potentially. So you want to just mean your way to greatness

Lex  00:40:36
that should be a t shirt. So you, you tweeted the transformers, a magnificent neural network architecture because it is a general purpose differential computer. It is simultaneously expressive in the forward pass optimize Herbal via back propagation and gradient descent and efficient. High parallelism compute graph. Can you discuss some of those details, expressive. Optimize herbal, efficient, yeah. From memory or or in general whatever comes to your

Andrej  00:41:03
heart. You want to have a general purpose computer that you can train on arbitrary problems like say the task of next word prediction or detecting if there's a cat in the image or something like that and you want to train this computer so you want to set its its weight. And I think there's a number of design criteria that sort of overlap in the transformer simultaneously. That made it very successful. And I think the authors were kind of deliberately trying to make this really powerful architecture and so basically it's very powerful in the forward past because it's able to express um very general computation as sort of something that looks like message passing, You have notes and they all store vectors and these nodes get to basically look at each other and it's each other's vectors and they get to communicate and basically notes, get to broadcast. Hey, I'm looking for sir, certain things and then other nodes get to broadcast. Hey, these are the things I have those are the keys in the values.

Lex  00:41:57
So it's not just attention.

Andrej  00:41:58
Exactly, transformer is much more than just the attention component that's got many pieces architectural that went into it. The residual connection of the way it's arranged, there's a multi layer perceptron and there the way it's stacked and so on. Um but basically there's a message passing scheme where nodes get to look at each other, decide what's interesting and then update each other. And so I think the, when you get to the details of it, I think it's a very expressive function so it can express lots of different types of algorithms and forward pass. Not only that, but the way it's designed with the residual connections. Later normalization is the softmax attention and everything. It's also optimize double this is a really big deal because there's lots of computers that are powerful that you can't optimize or they are not easy to optimize using the techniques that we have, which is back propagation ingredients sent. These are first order methods, very simple optimizers really. And so um you also needed to be optimized. Herbal. Um and then lastly, you wanted to run efficiently in our hardware. Our hardware is a massive throughput machine, like gps, they prefer lots of parallelism.

So you don't want to do lots of sequential operations. You want to do a lot of operations serially. And the transformer is designed with that in mind as well. And so it's designed for our hardware and is designed to both be very expressive in the forward pass but also very optimized able in the backward pass.

Lex  00:43:09
And you said that uh the residual connections support a kind of ability to learn short algorithms fast and first and then gradually extend uh longer during training. Yeah. What's what's the idea of learning short algorithms?

Andrej  00:43:23
Right. Think of it as So basically a transformer is a series of blocks, right? And these blocks have attention and a little multi layer perception. And so you you go off into a block and you come back to this residual pathway and then you go off and you come back and then you have a number of layers arranged sequentially. And so the way to look at it I think is because of the residual pathway in the backward pass, the gradients sort of flow along it uninterrupted because addition distributes the gradient equally to all of its branches. So the gradient from the supervision at the top just floats directly to the first layer and the all the residual connections are arranged so that in the beginning of during initialization they contribute nothing to the residual pathway. Um so what it kind of looks like is imagine the transformer is kind of like a python function like a death. And um you get to do various kinds of like lines of code. Um so you have 100 layers deep transformer, typically they would be much shorter, say 20 so 20 lines of code and you can do something in them. And so think of during the optimization, basically what it looks like is first you optimize the first line of code and then the second line of code can kick in and the third line of code can kick in and I kind of feel like because of the residual pathway and the dynamics of the optimization, You can sort of learn a very short algorithm that gets the approximate answer, but then the other layers can sort of kick in and start to create a contribution and at the end of it you're you're optimizing over an algorithm that is 20 lines of code Except these lines of code are very complex because it's an entire block of a transformer. You can do a lot in there. What's really interesting is that this transformer architecture actually has been remarkably resilient, basically a transformer that came out in 2016 as the transformer you would use today except you reshuffle from the layer norms, the normalization have been reshuffled to a pre norm um formulation and so it's been remarkably stable, but there's a lot of bells and whistles that people have attached on it and try to improve it.

I do think that basically it's a, it's a big step in simultaneously optimizing for lots of properties of a desirable neural network architecture and I think people have been trying to change it, but it's proven remarkably resilient. Um but I do think that there should be even better architecture is potentially,

Lex  00:45:25
but it's your, you admire the resilience here, there's something profound about this architecture that at least maybe we can everything can be turned into a uh into a problem that transformers can solve

Andrej  00:45:38
currently definitely looks like the transformers taking over AI and you can feed basically arbitrary problems into it and it's a general differentiable computer and it's extremely powerful and uh this convergence in AI has been really interesting to watch uh for me personally

Lex  00:45:53
what else do you think could be discovered here about transformers? Like what surprising thing or is it a stable I was in a stable place, is there something interesting we might discover about transformers like aha moments maybe has to do with memory, maybe knowledge representation, that kind of stuff

Andrej  00:46:11
definitely The zeitgeist today is just pushing like basically right now the guys is do not touch the transformer, touch everything else. So people are scaling up the data sets making them much much bigger, they're working on the evaluation, making the evaluation much much bigger and uh um they're basically keeping the architecture unchanged and that's how we've that's the last five years of progress in ai kind of

Lex  00:46:33
what do you think about one flavor of it? Which is language models? Have you been surprised uh has your sort of imagination been captivated by, you mentioned D. P. T. And all the bigger and bigger and bigger language models and uh what are the limits of those models do you think? So just for the task of natural language,

Andrej  00:46:59
basically the way GPT is trained, right, is you just down a massive amount of text data from the internet and you try to predict the next word in the sequence, roughly speaking, you're predicting a little word chunks but roughly speaking, that's it. Um and what's been really interesting to watch is Basically it's a language model. Language models have actually existed for a very long time. Um there's papers on language modeling from 2003 even earlier. Can

Lex  00:47:23
you explain that case what language model is?

Andrej  00:47:26
Yeah, so language model, just basically the rough idea is um just predicting the next word in a sequence, roughly speaking. Uh so there's a paper from for example, Benji Oh and the team from 2003 where for the first time they were using a neural network to take say like three or five words and predict the next word. And they're doing this on much smaller data sets. And the neural net is not a transformer, it's a multi layer perceptron but it's the first time that a neural network has been applied in that setting. But even before neural networks that were um, language models except they were using um N gram models. So N gram models are just count based models. So um if you try if you try to take two words and predict the third one, you just count up how many times you've seen any two word combinations and what came next and what you predict is coming next is just what you've seen the most of in the training set. And so language modeling has been around for a long time, neural networks have done language modeling for a long time. So really what's new or interesting or exciting is just realizing that when you scale it up with powerful enough neural net transformer, you have all these emergent properties. Where basically what happens is if you have a large enough dataset of text, you are in the task of predicting the next word, you are multitasking a huge amount of different kinds of problems you are multitasking understanding of, you know, chemistry physics, human nature, lots of things are sort of clustered in that objective. It's a very simple objective, but actually you have to understand a lot about the world to make that prediction.

Lex  00:48:59
You just said the u word understanding. Are you in terms of chemistry and physics and so on. What do you feel like it's doing is it's searching for the right context uh in in what, what is it, what is the actual process happening here? Yes.

Andrej  00:49:16
So basically it gets 1000 words and trying to predict 1001st and in order to do that very, very well over the entire dataset available on the internet, you actually have to basically kind of understand the context of what's going on in there. Um and uh it's a sufficiently hard problem that you uh if you have a powerful enough computer, like a transformer, you end up with interesting solutions and uh you can ask it to do all kinds of things and it shows a lot of emergent properties like in context learning. That was the big deal with GPT and the original paper when they published it is that you can just sort of uh prompt it in various ways and ask it to do various things and it will just kind of complete the sentence. But in the process of just completing the sentence it's actually solving all kinds of really interesting problems that we care about. Do

Lex  00:50:05
you think it's doing something like understanding like when we use the word understanding for us humans?

Andrej  00:50:13
I think it's doing some understanding it in its weights, it understands I think a lot about the world and it has to in order to predict the next word in a sequence.

Lex  00:50:22
So it's trained on the data from the internet. What do you think about this this approach in terms of data sets of using data from the internet. Do you think the internet has enough structured data to teach ai about human civilization?

Andrej  00:50:37
Yes, I think the internet is a huge amount of data. I'm not sure if it's a complete enough set. I don't know that text is enough for having a sufficiently powerful A. G I has an outcome. Um

Lex  00:50:48
Of course there is audio and video and images and all that kind of stuff.

Andrej  00:50:51
Yeah. So, text by itself. I'm a little bit suspicious about. There's a ton of things we don't put in text in writing just because they're obvious to us about how the world works in the physics of it and that things fall, we don't put that stuff in text because why would you we share that understanding? And so taxes communication medium between humans and it's not a all encompassing medium of knowledge about the world. But as you pointed out, we do have video and we have images and we have audio. And so I think that that definitely helps a lot, but we haven't trained models sufficiently across both across all these modalities yet. So I think that's what a lot of people are interested in,

Lex  00:51:24
but I wonder what that shared understanding of, like, what we might call common sense has to be learned inferred in order to complete the sentence correctly. So maybe the fact that it's implied on the internet, the model's gonna have to learn that not by reading about it by inferring in the representation. So like, common sense, just like we I don't think we learned common sense, like nobody says tells us explicitly, we just figure it all out by interacting with the

Andrej  00:51:56
world.

Lex  00:51:57
And so here's a model of reading about the way people interact with the world and might have to infer that I wonder

Andrej  00:52:03
Yeah,

Lex  00:52:04
you you briefly worked on a project called the world of bits, training in RL system to take actions on the internet um versus just consuming the internet, like we talked about, do you think there's a future for that kind of system interacting with the internet to help the learning?

Andrej  00:52:20
Yes, I think that's probably the final frontier for a lot of these models because um so as you mentioned, there was an opening, I was working on this project world of bits and basically it was the idea of giving neural networks access to a keyboard and a mouse and the idea

Lex  00:52:34
possibly go wrong.

Andrej  00:52:37
So basically you you perceive the input of the uh screen pixels and basically the state of the computer is sort of visualized for human consumption in images of the web browser and stuff like that. And then you give them the ability to press keyboards and use the mouse and we're trying to get it to for example, complete bookings and you know, interact with the user interfaces and what

Lex  00:52:59
did you learn from that experience? Like what was some fun stuff? There's a super cool idea. I mean, it's like yeah, I mean the step between observer to actor is a super fascinating

Andrej  00:53:12
step. Well, the universal interface in the digital realm, I would say. And there's a universal interface in like the physical realm which in my mind is a humanoid form factor kind of thing. We can later talk about optimus and so on, but I feel like there's a they're kind of like a similar philosophy in some way where the human the world, the physical world is designed for the human form and the digital world is designed for the human form of seeing the screen and using keyword, keyboard and mouse. And so is the universal interface that can basically command the digital infrastructure we've built up for ourselves. And so it feels like a very powerful interface to command and to build on top of now to your question as to like what I learned from that. It's interesting because the world of bits was basically too early I think at open ai at the time um this is around 2015 or so, and the zeitgeist at that time was very different in ai from the zeitgeist today at the time everyone was super excited about reinforcement learning from scratch. This is the time of the Atari paper where neural networks were playing Atari games um and beating humans in some cases uh Alphago and so on. So everyone is very excited about training neural networks from scratch using reinforcement learning. Um directly it turns out that reinforcement learning is extremely inefficient way of training neural networks because you're taking all these actions and all these observations and you get some sparse rewards once in a while. So you do all this stuff based on all these inputs and once in a while you're like told you did a good thing, you did a bad thing. It's just an extremely hard problem.

You can't learn from that, You can burn the forest and you can sort of brute force through it. And we saw that I think with, you know, with Go and Dota and so on and does work, but it's extremely inefficient uh and not how you want to approach problems, practically speaking. And so that's the approach that at the time we also took the world of bits, we would have an agent initialized randomly. So with keyboard mash and mouse mash and try to make a booking. And it's just like revealed the insanity of that approach very quickly where you have to stumble by the correct booking in order to get a reward of you did it correctly and you're never gonna stumble by it by chance at random. So

Lex  00:55:19
even with a simple web interface, there's too many options,

Andrej  00:55:21
there's just too many options, uh and uh it's too sparse of reward signal and you're starting from scratch at the time. And so you don't know how to read, you don't understand pictures, images, buttons, you don't understand what it means to like make a booking, but now what's happened is uh it is time to revisit that and opening, I was interested in this. Uh, Companies like Adept are interested in this and so on and uh the idea is coming back because the interface is very powerful, but now you're not training an agent from scratch, you are taking the GPT as initialization. So GPT is pre trained on all of text and it understands what's a booking, it understands what to submit, it understands um quite a bit more and so it already has those representations, they are very powerful and that makes all the training significantly more efficient um and makes the problem tractable.

Lex  00:56:06
Should the interaction be with like the way humans see it with the buttons and the language or should be with the html javascript and CSS what's what do you think is the better? So

Andrej  00:56:17
today, all of this interaction is mostly on the level of html CSS and so on. That's done because of computational constraints. Uh but I think ultimately, um everything is designed for human visual consumption and so at the end of the day there's all the additional information is in the layout of the web page and what's next to you and what's a red background and all this kind of stuff and what it looks like visually. So I think that's the final frontier is we're taking in pixels and we're giving out keyboard mouse commands, but I think it's impractical Still today,

Lex  00:56:45
do you worry about bots on the internet, Given, given these ideas, given how exciting they are. Do you worry about bots on twitter being not the stupid bots that we see now with the crypto bots, but the bots that might be out there actually that we don't see that they're interacting in interesting ways. So this kind of system feels like it should be able to pass the I'm not a robot click button whatever um which you actually understand how the test works. I don't quite like there's there's a there's a check box or whatever that you click, it's presumably tracking like mouse movement and the timing and so on. So exactly this kind of system we're talking about should be able to pass that. So yeah, what do you feel about? Um bots that are language models plus have some interact ability and are able to tweet and reply and so on. Do you worry about that world?

Andrej  00:57:40
Yeah, I think it's always been a bit of an arms race between sort of the attack and the defense. So the attack will get stronger but the defense will get stronger as well, our ability to detect that. How

Lex  00:57:50
do you defend? How do you detect? How do you know that your account on twitter is is human?

Andrej  00:57:58
How

Lex  00:57:58
did you approach that? Like if people will claim you know uh how would you defend yourself in the court of law that I am a human?

Andrej  00:58:07
Um

Lex  00:58:08
this account at some

Andrej  00:58:09
point I think uh it might be I think the society society will evolve a little bit like we might start signing digitally signing some of our correspondence or you know things that we create right now. It's not necessary but maybe in the future it might be I do think that we are going towards the world where we share we share the digital space with a eyes,

Lex  00:58:29
synthetic beings.

Andrej  00:58:30
Yeah. And they will get much better and they will share our digital realm and they'll eventually share our physical realm as well. It's much harder. But that's kind of like the world we're going towards and most of them will be benign and hopeful and some of them will be malicious and it's going to be an arms race trying to detect them.

Lex  00:58:45
So I mean the worst isn't the ai is the worst is the Ai is pretending to be human. So I don't know if it's always malicious. There's obviously a lot of malicious applications but it could also be, you know, if I was an ai I would try very hard to pretend to be human because we're in a human world. I wouldn't get any respect as an A I want to get some love and respect.

Andrej  00:59:10
I don't think the problem is intractable. People are people are thinking about the proof of personhood and uh we might start digitally signing our stuff and we might all end up having like uh yeah, basically some some solution for proof of personhood. It doesn't seem to be intractable. It's just something that we haven't had to do until now. But I think once the need like really starts to emerge which is soon. I think people think about it much more

Lex  00:59:32
so, but that too will be a race because obviously you can probably uh spoof or fake the proof of personhood. So you have to try to figure out how to

Andrej  00:59:45
probably. I

Lex  00:59:47
mean it's weird that we have like social security numbers and like passports and stuff. It seems like it's harder to fake stuff in the physical space, in the visual space. It just feels like it's gonna be very

Andrej  01:00:00
tricky, very

Lex  01:00:01
tricky to out because it seems to be pretty low cost fake stuff. What are you gonna put an ai in jail for like trying to use a fake fake personhood proof? I mean, okay fine, you put a lot of guys in jail, but there will be more as our like exponentially more, the cost of creating bot is very low. Unless there's some kind of way to track accurately. Like you're not allowed to create any program without showing uh tying yourself to that program. Like any program that runs on the internet, you'll be able to uh trace every single human program that was involved with that

Andrej  01:00:44
program. Yeah. Maybe you have to start declaring when uh you know, we have to start drawing those boundaries and keeping track of okay, what are digital entities versus human entities and uh what is the ownership of human entities and digital entities and uh something like that. Um I don't know, but I'm I think I'm optimistic that this is uh this is uh possible and in some, in some sense, we're currently in like the worst time of it because um all these bots suddenly have become very capable, but we don't have defenses yet built up as a society and but I think that doesn't seem to be intractable. It's just something that we have to deal with.

Lex  01:01:21
It seems weird that the twitter, but like really crappy twitter bots are so numerous. Is it? So I presume that the engineers of twitter are very good. So it seems like what I would infer from that uh is it seems like a hard problem if they're probably catching all right. If I were to sort of steel man the case. It's a hard problem and there's a huge cost to uh false positive to removing a post by somebody that's not about, that creates a very bad user experience. So they're very cautious about removing. So maybe it's um, and maybe the boss are really good at learning what gets removed and not such that they can stay ahead of the removal process very quickly. My

Andrej  01:02:10
impression of it honestly is there's a lot of longing for. I mean,

Lex  01:02:14
yeah, just that's what I

Andrej  01:02:15
it's not subtle my impression of it. It's not so, but

Lex  01:02:19
you have, yeah, that's my impression as well, but it feels like maybe you're seeing the tip of the iceberg, maybe the number of boxes and like the trillions and you have to like just, it's a constant assault of bots and yeah I don't know um you have to steal in the case because the bots, I'm seeing a pretty like obvious I could write a few lines of code to catch these bots.

Andrej  01:02:44
I mean definitely there's a lot of low hanging fruit but I will say I agree that if you are a sophisticated actor you could probably create a pretty good but right now um you know using tools like G. P. T. S because it's a language model, you can generate faces that look quite good now uh and you can do this at scale and so I think um it's quite possible it's going to be hard to defend.

Lex  01:03:05
There was a google engineer that claim that the lambda was essentially, do you think there's any inkling of truth to what he felt? And more importantly to me at least, do you think language models will achieve sentience or the illusion of sentience soon? Ish. Yeah.

Andrej  01:03:25
To me it's a little bit of a canary in a coal mine kind of moment. Honestly a little bit because uh so this engineer spoke to like a chatbot at google and uh became convinced that

Lex  01:03:38
asked some existential philosophical question

Andrej  01:03:41
and it gave like reasonable answers and looked real and uh and so on so to me it's a he was he was he wasn't sufficiently trying to stress the system I think and exposing the truth of it as it is today. Um But I think this will be increasingly harder over time. So uh yeah, I think more and more people will basically become um yeah, I think more and more there will be more people like that over time as as this gets better, like

Lex  01:04:13
form an emotional connection to an ai perfectly

Andrej  01:04:16
plausible in my mind. I think these guys are actually quite good at human human connection. Human emotion. A ton of text on the internet is about humans and connection and love and so on. So I think they have a very good understanding in some in some sense of how people speak to each other about this and they're very capable of creating a lot of that kind of text. The there's a lot of like sci fi from fifties and sixties that imagined Ai is in a very different way. They are calculating cold Vulcan like machines, that's not what we're getting today. We're getting pretty emotional ai that actually are very competent and capable of generating, you know, possible sounding text with respect to all of these topics.

Lex  01:04:57
See I'm really hopeful about ai systems that are like companions that help you grow, develop as a human being, help you maximize long term happiness. But I'm also very worried about ai systems that figure out from the internet, the humans get attracted to drama and so this would just be like shit talking eyes, they just constantly did you hear, like they'll do gossip, they'll do they'll try to plant seeds of suspicion to other humans that you love and trust and just kind of mess with people. Uh you know, because because that's going to get a lot of attention to drama maximize drama on the path to maximizing engagement. And us humans will feed into that machine and get it will be a giant drama shit storm. Uh so I'm worried about that. So it's the objective function really defines the way that human civilization progresses with the eyes in

Andrej  01:05:52
it. I think right now at least today they're not sort of it's not correct to really think of them as goal seeking agents that want to do something. They have no long term memory or anything. They it's literally a good approximation of it is you get 1000 words and you're trying to predict 1000 and first and then you continue feeding it in and you are free to prompt it in whatever way you want. So in text, so you say, okay you are a psychologist and you are very good and you love humans and here's a conversation between you and another human human column something, you something and then it just continues the pattern and suddenly you're having a conversation with the fake psychologist who's trying to help you. And so it's still kind of like an aroma of a tool is a people can prompt in arbitrary ways and it can create really incredible text but it doesn't have long term goals over a long period of time, it doesn't try to uh so it doesn't look that way right now

Lex  01:06:44
but you can do short term goals that have long term effects. So if my prompting, short term goal is to get Andrew capacity to respond to me on twitter when I like I think a I might that's the goal but it might figure out that talking shipped to you. It would be the best in a highly sophisticated interesting way and then you build up a relationship when you were responding once and then it like over time it gets to not be sophisticated and just like just talk shit and

Andrej  01:07:20
okay

Lex  01:07:21
maybe you won't get to andre but it might get to another celebrity and might get into other big accounts and then it'll just so with just that simple goal get them to respond to maximize the probability of actual response.

Andrej  01:07:34
Yeah, I mean you could prompt a powerful model like this with their its opinion about how to do any possible thing you interested. So they will just, they're kind of on track to become these oracles, I could sort of think of it that way they are. Oracles currently it's just text but they will have calculators, they will have access to google search, they will have all kinds of gadgets and gizmos, they will be able to operate the internet and find different information and yeah, in some sense, that's kinda like currently what it looks like in terms of the development,

Lex  01:08:04
do you think it will be an improvement eventually over what google is for access to human knowledge, Like it'll be a more effective search engine to access human knowledge.

Andrej  01:08:14
I think there's definite scope in building a better search engine today and I think google, they have all the tools, all the people, they have, everything they need, all the puzzle pieces, they have people training transformers at scale, they have all the data. Uh it's just not obvious if they are capable as an organization to innovate on their search engine right now and if they don't someone else will, there's absolute scope for building a significantly better search engine built on these tools.

Lex  01:08:37
It's so interesting. A large company where the search, there's already an infrastructure, it works as brings out a lot of money, so where structurally inside the company is their motivation to pivot to say we're going to build a new search engine.

Andrej  01:08:51
Yeah, that's hard.

Lex  01:08:53
So it's usually going to come from a startup,

Andrej  01:08:55
right? That's um, that would be yeah, or some other more competent organization. Um so, uh, I don't know, so currently, for example, maybe being has another shot at it, you know,

Lex  01:09:07
Go Microsoft,

Andrej  01:09:09
we're talking

Lex  01:09:10
offline um I

Andrej  01:09:12
mean, I definitely it's really interesting because search engines used to be about, okay, here's some query, here's, here's here's web pages that look like the stuff that you have but you could just directly go to answer and then have supporting evidence. Um and these uh these models basically they've read all the text and they read all the web pages and so sometimes when you see yourself going over to search results and sort of getting like a sense of like the average answer to whatever you're interested in like that just directly comes out, you don't have to do that work. Um So they're kind of like uh yeah, I think they have a way to this of distilling all that knowledge

Lex  01:09:47
into like

Andrej  01:09:49
some level of insight basically.

Lex  01:09:50
Do you think of prompting as a kind of teaching and learning like this whole process like another layer, you know, because maybe that's what humans are already have that background model and you're the world is prompting you?

Andrej  01:10:06
Yeah, exactly. I think the way we are programming these computers now, like GPS is converging to how you program humans. I mean how do I program humans via prompt? I go to people and I prompt them to do things. I prompt them from information. And so natural language prompt is how we program humans and we're starting to program computers directly in that interface, it's like pretty remarkable honestly.

Lex  01:10:27
So you've spoken a lot about the idea of software 2.0 um all good ideas become like cliches so quickly, like the terms it's kind of hilarious um it's like I think Eminem once said that like if he gets annoyed by song, he's written very quickly, that means it's gonna be a big hit because it's too catchy. But can you describe this idea and how you're thinking about it has evolved over the months and years since, since you coined it?

Andrej  01:10:59
Yeah. Yes. I had a block post on software 2.0, I think several years ago now. Um and the reason I wrote that post is because I kept, I kind of saw something remarkable happening in like software development and how a lot of code was being transitioned to be written, not in sort of like C plus plus and so on, but it's written in the weights of the neural net. Basically just saying that neural nets are taking over software, the realm of software and um taking more more more tasks. And at the time I think not many people understood this deeply enough that this is a big deal. It's a big transition uh neural networks were seen as one of multiple classification algorithms you might use for your dataset problem on cattle. Like this is not that this is a change in how we program computers and I saw neural nuts as uh this is going to take over the way we program computers is going to change is not going to be people writing software in C plus plus or something like that and directly programming the software, it's going to be accumulating training sets and datasets and crafting these objectives by which we train these neural nets and at some point there's going to be a compilation process from the data sets and the objective and the architecture specification into the binary, which is really just uh the neural nut, you know, weights and the forward path of the neural nut. And then you can deploy that binary. And so I was talking about that sort of transition and uh that's what the post is about. And I saw this sort of play out in a lot of fields, uh you know, being one of them, but also just a simple image classification. People thought originally, you know, in the 80s and so on that they would write the algorithm for detecting a dog in an image.

And they had all these ideas about how the brain does it. And first we detect corners and then we detect lines and then we stitch them up and they were like really going at it. They were like thinking about how they're gonna write the algorithm and this is not the way you build it. Um there was a smooth transition where okay first we thought we were gonna build everything. Then we were building the features. So like hog features and things like that that detect these little statistical patterns from image patches and then there was a little bit of learning on top of it like support vector machine or binary classifier for cat versus dog and images on top of the features. So we wrote the features but we trained the last layer sort of the classifier. And then people are like actually let's not even design the features because we can't honestly we're not very good at it. So let's also learn the features. And then you end up with basically a convolutional neural net where you're learning most of it, you're just specifying the architecture and the architecture has tons of fill in the blanks which is all the knobs and you let the optimization right? Most of it. And so this transition is happening across the industry everywhere.

And uh suddenly we end up with a ton of code that is written in neural net weights. And I was just pointing out that the analogy is actually pretty strong. And we have a lot of developer environments for software like we have I. D. S. Um how you work with code? How you debug code. How do you how do you run code? How do you maintain code? We have Git hub. So I was trying to make those analogies in the new realm like what is the Git hub? Software 2.0, turns out it's something that looks like hugging face right now.

Lex  01:14:05
Uh,

Andrej  01:14:06
you know, And so I think some people took it seriously and build cool companies and uh many people originally attacked the post. It actually was not well received when I wrote it and I think maybe it has something to do with the title but the post was not well received and I think more people sort of have been coming around to it over time.

Lex  01:14:22
Yeah so you were the director of Ai at Tesla where I think this idea was really implemented a scale which is how you have engineering teams doing software two point Oh so can you sort of linger on that idea of I think we're in the really early stages of everything you just said which is like get hub I. D. S. Like how how do we build engineering teams that that work in software 2.0. System and and the the data collection and the data annotation which is All part of that software 2.0. Like what do you think is the task of programming software? 2.0 is it debugging in the space of hyper parameters or is it also debugging the space of data?

Andrej  01:15:09
Yeah. The way by which you program the computer and influence its algorithm is not by writing the commands yourself. You're changing mostly the dataset. You're changing the loss functions of like what the neural net is trying to do, how it's trying to predict things but they're basically the data sets and the architecture of the neural net and um so in the case of the autopilot, a lot of the data sets had to do with for example detection of objects and lane lane markings and traffic lights and so on. So accumulate massive data sets of, here's an example, here's the desired label and then uh, here's roughly how the architect, here's roughly what the algorithm should look like. And that's a convolutional neural net. So the specification of the architecture is like a hint as to what the algorithm should roughly look like. And then the fill in the blanks process of optimization is the training process and then you take your neural net that was trained. It gives all the right answers on your dataset and you deploy it.

Lex  01:16:04
So there's in that case perhaps at all machine learning cases, there's a lot of tasks. So is coming up formulating a task like uh, for a multi headed neural network, is formulating a task part of the programming,

Andrej  01:16:21
how

Lex  01:16:22
you break down a problem into a set of tasks.

Andrej  01:16:27
I'm on the high level, I would say if you look at the software running in in the autopilot, I gave a number of talks on this topic, I would say originally a lot of it was written in software one point No, there's imagine lots of c plus plus, right. And then gradually there was a tiny neural net that was for example, predicting given a single image. Is there like a traffic light or not? Or is there a landline marking or not. And this neural net didn't have too much to do in the in the scope of the software was making tiny predictions on individual little image and then the rest of the system stitched it up. So okay, we're actually we don't have just a single camera with eight cameras. We actually have eight cameras over time. And so what do you do with these predictions? How do you put them together? How do you do the fusion of all that information and how do you act on it? All of that was written by humans um in C plus plus. And then we decided, okay, we don't actually want uh to do all of that fusion in C.

Plus plus code because we're actually not good enough to write that algorithm. We want the neural nets to write the algorithm and we want to support all of that software into the stack. And so then we actually have neural nets that now take all the eight camera images simultaneously and make predictions for all of that. So um and actually they don't make predictions in the in the space of images. They now make predictions directly in three D. And actually they don't in three dimensions around the car. And now actually we don't um manually fuse the predictions over in three D. Over time. We don't trust ourselves to write that tracker. So actually we give the neural net uh the information over time. So it takes these videos now and makes these predictions. And so you're sort of just like putting more and more power into the neural net neural processing and at the end of it, the eventual sort of goal is to have most of the software potentially be in the and um because it works significantly better, humans are just not very good at writing software basically.

So

Lex  01:18:16
The prediction is happening in this like 4D land with three dimensional world over time. How do you do annotation in that world? What what what have you as the data annotation whether it's self supervised or manual by humans is um is a big part of the world,

Andrej  01:18:37
right? I would say by far in the industry if you're like talking about the industry and how what is the technology of what we have available, Everything is supervised learning. So you need a data set of input, desired output and you need lots of it. And um there are three properties of it that you need, you need to be very large, you needed to be accurate, no mistakes and you needed to be diverse. You don't want to uh just have a lot of correct examples of. One thing you need to really cover the space of possibility as much as you can and the more you can cover the space of possible inputs, the better the algorithm will work at the end. Now, once you have really good data sets that you're collecting curating, um and cleaning you can train your neural net um on top of that. So a lot of the work goes into cleaning those datasets now as you pointed out it's probably it could be. The question is how do you achieve a ton of uh if you want to basically predict in three D. You need data and three D. To back that up. So in this video we have eight videos coming from all the cameras of the system and this is what they saw.

And this is the truth of what actually was around there was this car, there was this car this car, these are the main line markings, this is the geometry of the road, there's traffic light in this three dimensional position. You need the ground truth. Um And so the big question that team was solving of course is how do you how do you arrive at that ground truth? Because once you have a million of it and it's large, clean and diverse. Then training neural net on it works extremely well and you can ship that into the car. And uh so there's many mechanisms by which we collected that training data. You can always go for human annotation. You can go for a simulation as a source of ground truth. You can also go for what we call the offline tracker um

Lex  01:20:12
that

Andrej  01:20:13
we've spoken about at the A. I. D. And so on. Which is basically an automatic reconstruction process for taking those videos and recovering the three dimensional sort of reality of what was around that car. So basically think of doing like a three dimensional reconstruction as an offline thing and then understanding that okay there's 10 seconds of video. This is what we saw and therefore here's all the landlines cars and so on. And then once you have that annotation you can train a neural net to imitate it.

Lex  01:20:39
And how difficult is the reconstruct the three reconstruction? It's

Andrej  01:20:43
difficult but it can be done.

Lex  01:20:44
So there's so there's overlap between the cameras and you do the reconstruction and there's uh perhaps if there's any inaccuracy. So that's caught in the annotation step.

Andrej  01:20:55
Yes. The nice thing about the annotation is that it is fully offline. You have infinite time, you have a chunk of one minute and you're trying to just offline in a supercomputer somewhere figure out where were the positions of all the cars, all the people and you have your full one minute video from all the angles and you can run all the neural nets you want. And they can be very efficient massive neural nuts. There can be neural nets that can't even run in the car later at test time. So they can be even more powerful neural nets than what you can eventually deploy. So you can do anything you want three dimensional reconstruction neural nets anything you want just to recover that truth and then you supervise that truth.

Lex  01:21:28
What have you learned, You said no mistakes about humans doing annotation because I assume humans are uh there's like a range of things that are good at in terms of clicking stuff on screen. Is that how interesting is that you have a problem with designing an annotator where humans are accurate, enjoy it, like what are they, even the metrics are efficient or productive? All that kind of stuff.

Andrej  01:21:53
Yeah. So I grew the annotation team at Tesla from basically 0 2000 uh while I was there, that was really interesting. You know, my background as a PhD student researcher. So growing that kind of organization was pretty crazy. Uh but uh yeah I think it's extremely interesting and part of the design process very much behind the autopilot as to where you use humans. Humans are very good at certain kinds of annotations. They're very good for example, at two dimensional annotations of images. They're not good at annotating uh cars over time in three dimensional space. Very, very hard. And so that's why we were very careful to design the tasks that are easy to do for humans versus things that should be left to the offline tracker. Like maybe the maybe the computer will do all the triangulation and three D reconstruction, but the human will say exactly these pixels of the image, our car, exactly these pixels are human. And so co designing the data annotation pipeline was very much bread and butter was what I was doing daily,

Lex  01:22:48
Do you think there's still a lot of open problems in that space?

Andrej  01:22:52
Um

Lex  01:22:52
just in general annotation where the stuff the machines are good at machines do and the humans do what they're good at and there's maybe some iterative process, right?

Andrej  01:23:03
I think to a very large extent we went through a number of iterations and we learned a ton about how to create these datasets. Um I'm not seeing big open problems like originally when I joined, I was like, I was really not sure how this will turn out, but by the time I left I was much more secure in actually we sort of understand the philosophy of how to create these data sets and I was pretty comfortable with where that was at the time.

Lex  01:23:24
So what our strengths and limitations of cameras for the driving task and your understanding when you formulate the driving task as a vision task with eight cameras. you've seen the entire, you know, most of the history of the computer vision field when it has to do with neural networks. What just if you step back, what are the strengths and limitations of pixels of using pixels to drive?

Andrej  01:23:49
Yeah, pixels I think are a beautiful sensory, beautiful sensor. I would say the things like cameras are very, very cheap and they provide a ton of information, ton of bits. Also it's uh extremely cheap sensor for a ton of bits and each one of these bits as a constraint on the state of the world. And so you get lots of megapixel images, very cheap and it just gives you all these constraints for understanding what's actually out there in the world. So vision is probably the highest bandwidth sensor. It's very high bandwidth sensor. And um

Lex  01:24:21
I love that pixels is uh, is a constraint in the world, is highly complex, high bandwidth constraint in the world, on the state of the world. It's

Andrej  01:24:34
not just that, but again, this real real importance of it's the sensor that humans use. Therefore everything is designed for that sensor

Lex  01:24:42
text,

Andrej  01:24:44
the writing, the flashing signs, everything is designed for vision. And so you just find it everywhere. And so that's why that is the interface you want to be in. Um talking again about these universal interfaces and that's where we actually want to measure the world as well. And then develop software for that sensor.

Lex  01:25:01
But there's other constraints on the state of the world that humans use to understand the world. I mean, vision ultimately is the main one, but we were like, we're like referencing our understanding of human behavior and some common sense and physics that could be inferred from vision from, from a perception perspective, but it feels like we're using some kind of reasoning to predict the world, not just the pixels,

Andrej  01:25:30
you have a powerful prior for how the world evolves over time, etcetera. So it's not just about the likelihood term coming up from the data itself, telling you about what you are observing but also the prior term of like where, where are the likely things to see and how do they likely move and so on? And

Lex  01:25:47
the question is how complex is the the the range of possibilities that might happen in the driving task? That still is that you still an open problem of how difficult is driving? Like philosophically speaking, do all

Andrej  01:26:05
the time you worked on

Lex  01:26:06
driving. Do you understand how hard driving is

Andrej  01:26:10
driving is really hard because it has to do with the predictions of all these other agents and the theory of mind and you know what they're gonna do and are they looking at you, are they, where are they looking, what are they thinking? Yeah, there's a lot that goes there at the, at the full tale of you know the expansion of the nine that we have to be comfortable with it. Eventually the final problems are of that form, I don't think those are the problems that are very common I think eventually they're important but it's like really in the tail end

Lex  01:26:35
in the tail end the rare edge cases from the vision perspective, what are the toughest parts of the vision problem of driving?

Andrej  01:26:45
Um well basically the sensor is extremely powerful but you still need to process that information. Um, and so going from brightness is of the special values to hey, here's the three dimensional world is extremely hard and that's what the neural networks are fundamentally doing. And so, um, the difficulty really is in just doing an extremely good job of engineering the entire pipeline, the entire data engine, having the capacity to train these neural nuts, having the ability to evaluate the system and iterate on it. So I would say just doing this in production at scale is like the hard part, it's an execution problem.

Lex  01:27:22
So the data engine, but also the, um, the sort of deployment of the system such that has low latency performance. So it has to do all these steps

Andrej  01:27:32
for general, not specifically just making sure everything fits into the chip on the car and you have a finite budget of flops that you can perform and uh, and memory bandwidth and other constraints. And you have to make sure it flies and you can squeeze in as much computer as you can into the tiny,

Lex  01:27:47
what have you learned from that process because maybe that's one of the bigger, like new things coming from a research background where there's, there's a system that has to run under heavily constrained resources has to run really fast. What, what kind of insights have you learned from that?

Andrej  01:28:04
Yeah, I'm not sure if it's, if there's too many insights, you're trying to create a neural nets that will fit in what you have available and you're always trying to optimize it and we talked a lot about it on the ai day and uh basically the triple back flips that the team is doing to make sure it all fits and utilizes the engine. Uh, so I think it's extremely good engineering. Um, and then there's all kinds of little insights peppered in on how to do it properly.

Lex  01:28:30
Let's actually zoom out because I don't think we talked about the data engine, the entirety of the layout of this idea that I think is just beautiful with humans in the loop. Can you describe the data engine?

Andrej  01:28:42
Yeah, the data engine is what I call the almost biological feeling like process by which you perfect the training sets for these neural networks. Um, so because most of the programming now is on the level of these data sets and make sure they're large, diverse and clean basically you have a data set that you think is good. You train your neural net, you deploy it and then you observe how well it's performing and you're trying to always increase the quality of your data set. You're trying to catch scenarios basically there are basically rare and it is in these scenarios that will typically struggling because they weren't told what to do in those rare cases in the dataset. But now you can close the loop because if you can now collect all those at scale, you can then feed them back into the reconstruction process I described and reconstruct the truth in those cases and added to the dataset. And so the whole thing ends up being like a staircase of improvement of perfecting your training set and you have to go through deployments so that you can mine uh the parts that are not yet represented well in the data set. So your data says basically in perfect, it needs to be diverse, it has pockets, there are missing and you need to pad out the pockets, you can sort of think of it that way in the data.

Lex  01:29:54
What role do humans play in this? So what's the this biological system like a human body is made up of cells? What what role like how do you optimize the human system, the multiple engineers collaborating, figuring out what to focus on what to contribute, which which task to optimize in this neural network, who is in charge of figuring out which task needs more data. What can you can you speak to the hyper parameters the human uh system,

Andrej  01:30:28
it really just comes down to extremely good execution from an engineering team, who knows what they're doing, they understand intuitively the philosophical insights underlying the data engine and the process by which the system improves and uh how to again like delegate the strategy of the data collection and how that works and then just making sure it's all extremely well executed and that's where most of the work is, is not even the philosophizing or the research or the ideas of it is just extremely good execution is so hard when you're dealing with data at that

Lex  01:30:53
scale. So your role in the data engine, executing well on it. It is difficult and extremely important. Is there a priority of like uh like a vision board of saying like we really need to get better at stoplights. Like the prioritization of tasks is that essentially, and that comes from the data

Andrej  01:31:14
that comes to um a very large extent to what we are trying to achieve in the product for a map where we're trying to the release, we're trying to get out um in the feedback from the QA team where the system is struggling or not, the things we're trying to improve and

Lex  01:31:26
the QA team gives some signal some information in aggregate about the performance of the system in various conditions

Andrej  01:31:34
and then of course all of us drive it and we can also see it, it's really nice to work with the system that you can also experience yourself and you know, it drives you home. It's

Lex  01:31:41
is there some insight you can draw from your individual experience that you just can't quite get from an aggregate statistical Yeah, it's so weird. Right? Yes. It's not scientific in a sense because you're just one anecdotal sample.

Andrej  01:31:57
Yeah, I think there's a ton of uh it's a source of truth is your interaction with the system and you can see it, you can play with it, you can perturb it, you can get a sense of it, you have an intuition for it. I think numbers just like have a way of numbers and plots and graphs are much harder. Uh, it hides a lot of

Lex  01:32:15
it's like if you train a language model, what it's a really powerful way is, is by you interacting with

Andrej  01:32:22
it and try

Lex  01:32:23
to build up an intuition.

Andrej  01:32:24
Yeah, I think like Ellen also like he always wanted to drive the system himself. He drives a lot and uh, I want to say almost daily. So, uh, he also sees this as a source of truth. You driving the system um, and performing and

Lex  01:32:38
yeah, so what do you think? Tough questions here? Uh, so Tesla last year removed radar from, from the sensor suite and now just announced there's going to remove ultrasonic sensors relying solely on vision. So camera only does that make the perception problem harder or easier? I

Andrej  01:33:01
would almost reframe the question in some way. So the thing is basically you would think that additional sensors

Lex  01:33:07
by the way, can I just interrupt. I wonder if a language model will ever do that If you prompted? Let me reframe your question. That would be epic.

Andrej  01:33:16
That's the wrong

Lex  01:33:16
problem. Sorry.

Andrej  01:33:17
It's like a little bit of a wrong question because basically you would think that these sensors are an asset to you. But if you fully consider the entire product in its entirety. These sensors are actually potentially liability because the sensors aren't free. They don't just appear on your car. You need suddenly you need to have an entire supply chain. You have people procuring it. There can be problems with them. They may need replacement. They are part of the manufacturing process. They can hold back the line in the production, you need to source them to maintain them. You have to have teams that write the firmware, all of the, all of it. And then you also have to incorporate and fuse them into the system in some way.

And so it actually like bloats the a lot of it. And I think Ellen is really good at simplify, simplify best part is no part. And he always tries to throw away things that are not essential because he understands the entropy in organizations and an approach And I think in this case the cost is high and you're not potentially seeing it if you're just a computer vision engineer and I'm just trying to improve my network and you know, is it more useful or less useful? How how useful is it? And the thing is once you consider the full cost of a sensor, it actually is potentially a liability and you need to be really sure that it's giving you extremely useful information in this case. We looked at using it or not using it and the delta was not massive. And so it's not useful

Lex  01:34:33
is it also blow in the data engine like having more sense

Andrej  01:34:37
percent

Lex  01:34:39
and

Andrej  01:34:39
these sensors, you know, they can change over time. For example, you can have one type of say radar, you can have other type of radar. They change over time now you suddenly need to worry about it. Now suddenly you have a column in your sequel light telling you, oh, what sensor type was it? And they all have different distributions and then uh, they can, they just, they contribute noise and entropy into everything and they bloat stuff And also organizationally has been really fascinating to me that it can be very distracting. Um, if you, if you, if you only want to get to work is vision, all the resources are on it and you're building out a data engine and you're actually making forward progress because that is the, the sensor with the most bandwidth, the most constraints in the world and you're investing fully into that and you can make that extremely good if you're, you're only a finite amount of sort of spend of focus across different facets of the system.

Lex  01:35:26
And uh, this kind of reminds me of which Sutton's a bitter lesson. It just seems like simplifying the system in the long run. Of course you don't know what the long run and it seems to be always the right solution

Andrej  01:35:40
in

Lex  01:35:40
that case it was for RL but it seems to apply generally across all systems that do computation. So where what do you think about the lidar as a crutch debate. The battle between point clouds and pixels.

Andrej  01:35:54
Yeah, I think this debate is always like slightly confusing to me because it seems like the actual debate should be about like do you have the fleet or not? That's like the really important thing about whether you can achieve really good functioning of an Ai system at the scale. So

Lex  01:36:07
data collection systems.

Andrej  01:36:09
Yeah. Do you have a fleet or not? Is significantly more important whether you have lighter or not? It's just another sensor. Um and uh yeah, I think similar to the radar discussion basically. I um yeah I don't think it it basically doesn't offer extra, extra information is extremely costly. It has all kinds of problems you have to worry about it, you have to calibrate it etcetera. It creates bloat and entropy. You have to be really sure that you need this uh this um sensor in this case. I basically don't think you need it and I think honestly I will make a stronger statement. I think the others, some of the other companies who are using it are probably going to drop it. Yeah.

Lex  01:36:46
So you have to consider the sensor in the full in considering can you build a big fleet that collects a lot of data and can you integrate that sensor with that? That data and that sensor into a data engine that's able to quickly find different parts of the data that then continuously improves whatever the model that you're using

Andrej  01:37:07
another way to look at it is like vision is necessary in the sense that uh dr uh the world is designed for human visual consumption so you need vision it's necessary and then also it is sufficient because it has all the information that you that you need for driving and humans obviously has a vision to drive. So it's both necessary and sufficient. So you want to focus resources and you have to be really sure if you're going to bring in other sensors, you could you could you could add sensors to infinity at some point you need to draw the line and I think in this case you have to really consider the full cost of any one sensor that you're adopting and do you really need it? And I think the answer in this case, you know,

Lex  01:37:44
so what do you think about the idea that that the other companies are forming high resolution maps and constraining heavily the geographic regions in which they operate? Is that approach not in your in your view um not going to scale over time to the entirety of the United States.

Andrej  01:38:04
I think you mentioned like they pre map all the environments and they need to refresh the map and they have a perfect centimeter level accuracy map of everywhere they're gonna drive. It's crazy how are you going to, We've been talking about autonomy actually changing the world. We're talking about the deployment on the on the global scale autonomous systems for transportation and if you need to maintain sending your accurate map for earth or like many cities and keep them updated. It's a huge dependency that you're taking on huge dependency. It's it's a massive massive dependency and now you need to ask yourself do you really need it and humans don't need it? Um Right so it's it's very useful to have a low level map of like okay the connectivity of your road. You know that there's a four coming up when you drive an environment, you sort of have that high level understanding. It's like a small google map and Tesla uses google map like similar kind of resolution information in the system but it will not pre map environments centimeter level accuracy. It's a crutch. It's a distraction, it costs entropy and it diffuses the team. It dilutes the team and you're not focusing on what's actually necessary which is computer vision problem.

Lex  01:39:09
What did you learn about machine learning about engineering about life? About yourself? As one human being from working with Elon musk.

Andrej  01:39:20
I think the most I've learned is about how to sort of run organizations efficiently and how to create efficient organizations and how to fight entropy in an organization.

Lex  01:39:29
So human engineering in the fight against

Andrej  01:39:32
entropy. There's a there's a, I think Ellen is a very efficient warrior in the fight against entropy in organizations.

Lex  01:39:40
The organization look like exactly

Andrej  01:39:42
it's process, it's it's process and

Lex  01:39:46
inefficiencies and and that kind of stuff.

Andrej  01:39:49
Yeah meetings, he hates meetings, he keeps telling people to skip meetings if they're not useful. Um He basically runs the world's biggest startups I would say uh Tesla SpaceX are the world's biggest startups. Tesla actually multiple startups. I think it's better to look at it that way. And so I think he's he's extremely good at at that. And uh yeah he's a very good intuition for streamline processes, making everything efficient. Best part is no part simplifying focusing um and just kind of removing barriers moving very quickly, making big moves all this is very startup, p sort of seeming things but at scale

Lex  01:40:24
so strong drive to simplify from from your perspective. I mean that um that also probably applies to just designing systems and machine learning and otherwise like simplify simplify. What do you think is the secret to maintaining the startup culture in a company that grows. Is there, can you introspect that?

Andrej  01:40:47
I do think he needs someone in a powerful position with a big hammer. Like Ellen who's like the cheerleader for that idea and ruthlessly ruthlessly pursues it. If no one has a big enough hammer, everything turns into committees, Democracy within the company process, talking to stakeholders decision making. Just everything just crumbles. If you have a big person who is also really smart and has a big hammer. Things move quickly.

Lex  01:41:12
So you said your favorite scene in Interstellar is the intense stocking scene with the ai and cooper talking saying cooper, what are you doing docking? It's not possible, No, it's necessary such a good line by the way. Just so many questions there, why an Ai in that scene presumably is supposed to be able to compute a lot more than the human is saying it's not optimal. Why the human, I mean that's a movie but shouldn't they? I know much better than the human anyway. What do you think is the value of setting seemingly impossible goals? So like uh our initial intuition which seems like something that you have taken on that Ellen espouses that where the initial intuition of the community might say this is very difficult and then you take it on anyway with a crazy deadline. You just from a human engineering perspective, uh have you seen the value of that?

Andrej  01:42:15
I wouldn't say that setting impossible goals. Exactly is is a good idea, but I think setting very ambitious goals is a good idea. I think there's a, what I call sub linear scaling of difficulty, which means that 10 X problems are not 10 X hard, usually 10 X 10 X harder problem is like two or three X harder to execute on because if you want to actually like if you want to improve the system by 10% it costs some amount of work and if you want to improve the system it doesn't cost You know 100 x. Amount of work and because you fundamentally change the approach and if you start with that constraint then some approaches are obviously dumb and not going to work and it it forces you to reevaluate. Um and I think it's a very interesting way of approaching problem solving

Lex  01:42:57
but it requires a weird kind of thinking it's just going back to your like PhD days, it's like how do you think which ideas in the machine learning community are solvable?

Andrej  01:43:10
Yes it's

Lex  01:43:11
uh it requires what is that? I mean there's the cliche first principles thinking but like it requires to basically ignore what the community is saying because it doesn't the community doesn't. A community in science usually draw lines of what is and isn't possible and like it's very hard to break out of that without going crazy.

Andrej  01:43:32
Yeah I mean I think a good example here is you know the deep learning revolution in some sense because you could be in computer vision at that time when during the deep learning sort of revolution of 2012 and so on. Uh you could be improving a computer vision stack by 10% or we can just be saying actually all this is useless and how do I do 10 X. Better computer vision? Well it's not probably by tuning Hog feature detector I need a different approach um I need something that is scalable. Going back to uh Richard Sutton's um and understanding sort of like the philosophy of the bitter lesson and then being like actually I need much more scalable system. Like a neural network that in principle works and then having some deep believers that can actually execute on that mission and make it work. So that's the solution.

Lex  01:44:16
What do you think is the timeline to solve the problem of autonomous driving? That's still in part open question.

Andrej  01:44:26
Yeah. I think the tough thing with timelines of self driving obviously is that no one has created self driving.

Lex  01:44:31
Yeah.

Andrej  01:44:32
So it's not like what do you think is the timeline to build this bridge? Well we've built million bridges before. Here's how long that takes its. You know it's uh no one has built autonomy. It's not obvious. Uh some parts turned out to be much easier than others so it's really hard to forecast you do your best based on trend lines and so on and based on intuition but That's why fundamentally it's just really hard to forecast this. No one is

Lex  01:44:54
even still like being inside of it is hard to to do

Andrej  01:44:58
some things turn out to be much harder and some things turn out to be much easier.

Lex  01:45:02
Do you try to avoid making forecasts? Because like Ellen doesn't avoid them right? And heads of car companies in the past have not avoided it either forward in other places have made predictions that we're going to solve level four. Driving by 2020 2021 whatever. And they all kind of backtracking that prediction. Are you as a as an ai person, do you for yourself privately make predictions or do they get in the way of like your actual ability to think about a thing?

Andrej  01:45:37
Yeah, I would say like what's easy to say is that this problem is tractable and that's an easy prediction to make. It's tractable. It's going to work. Yes, it's just really hard. Something turned out to be harder than something turned out to be easier. So but it's it definitely feels tractable and it feels like at least the team at Tesla which is what I saw internally is definitely on track to that. How

Lex  01:45:57
do you form a strong representation that allows you to make a prediction about attract ability? So like you're the leader of a lot, a lot of humans, you have to kind of say this is actually possible. Like how do you build up that intuition? It doesn't have to be even driving, it could be other tasks. It could be. Um and I want to, what difficult task did you work on your life? I mean classification, achieving certain just an image in that certain level of super human level performance. Yeah,

Andrej  01:46:29
expert intuition just intuition, it's belief.

Lex  01:46:34
So just like thinking about it long enough. Like studying looking at sample data, like you said driving my intuition is really flawed on this. Like I don't have a good intuition about tracked ability. It could be either, it could be anything, it could be solvable. Like uh, you know, the driving task could be simplified into something quite trivial. Like uh, the solution to the problem would be quite trivial and at scale more and more cars driving perfectly might make the problem much easier. The more cars you have drive, like people learn how to drive correctly, not correctly, but in a way that's more optimal for heterogeneous system of autonomous and semi autonomous and manually driven cars that could change stuff. Then again also have spent a ridiculous number of hours just staring at pedestrians crossing streets, thinking about humans and it feels like the way we use our eye contact, it sends really strong signals and there's certain quirks and edge cases of behavior and of course a lot of the fatalities that happen have to do with drunk driving and um, both on the pedestrian side and the driver's side. So there's that problem of driving at night and all that kind of so I wonder, you know, it's like the space of possible solution to autonomous driving includes so many human factor issues that it's almost impossible to predict. There could be super clean, nice solutions.

Andrej  01:48:04
Yeah, I would say definitely like to use a game analogy, there's some fog of war, but you definitely also see the frontier of improvement and you can measure historically how much you've made progress. And I think for example, at least what I've seen and roughly five years of Tesla when I joined, it barely kept laying on the highway. I think going up from Palo Alto to SF was like three or four interventions anytime the road would do anything geometrically or turn too much, it would just like not work. And so going from that to like a pretty competent system in five years and seeing what happens also under the hood and what the scale of what the team is operating now with respect to data and computer and everything else, uh, is just a massive progress. So

Lex  01:48:43
just you're climbing a mountain and fog, but you're making a lot of progress,

Andrej  01:48:49
You're making progress and you see what the next directions are and you're looking at some of the remaining challenges and they're not like, uh, they're not perturbing you and they're not changing your philosophy and you're not control contorting yourself. You're like actually these are the things that we still need to do.

Lex  01:49:01
The fundamental components of solving the problems seem to be there for the data engine, to the computer, the computer on the card, to the computer, the training, all that kind of stuff. So you've done over the years, you've been a test, you've done a lot of amazing breakthrough ideas and engineering, all of it. Um, from the data engine to the human side, all of it can you speak to why you chose to leave Tesla,

Andrej  01:49:27
basically, as I described, that ran? I think over time, during those five years I've kind of gotten myself into a little bit of managerial position, most of my days where you know, meetings and growing the organization and making decisions about sort of high level strategic decisions about the team and what it should be working on and so on and uh it's kind of like a corporate executive role and I can do it, I think I'm okay at it, but it's not like fundamentally what I what I enjoy. And so I think when I joined um there was no computer vision team because Tesla was just going from the transition of using mobile, I a third party vendor for all of its computer vision to having to build this computer vision system. So when I showed up there were two people training deep neural networks and they were training them at a computer at their at their legs. Like down there was a

Lex  01:50:14
basic classification task

Andrej  01:50:16
and so I kind of like grew that into what I think is a fairly respectable deep learning team, massive computer cluster, very good data annotation organization. And uh I was very happy with where that was, it became quite autonomous. And so I kind of stepped away and I, you know, I'm very excited to do much more technical things again. Yeah, and kind of like we focused on a G I

Lex  01:50:38
what was this soul searching like you took a little time off and think like what how many mushrooms did you take? I mean what what was going through your mind, the human lifetime is finite?

Andrej  01:50:49
You

Lex  01:50:50
did a few incredible things, You're you're one of the best teachers of ai in the world, You're one of the best and I don't mean that, I mean that in the best possible way you're one of the best tinkerers in the Ai world, meaning like understanding the fundamental fundamentals of how something works by building it from scratch and playing with the basic intuitions, it's like Einstein Feinman, we're all really good at this kind of stuff, like a small example of a thing to to play with it, to try to understand it. So that and obviously now will you help build a team of machine learning um uh like engineers and a system that actually accomplished something in the real world, given all that, like what what was the soul

Andrej  01:51:33
searching? Like? It was hard because obviously I love the company a lot and I love I love Ellen, I love Tesla, I want um it was hard to leave, I love the team basically. Um but yeah, I think actually I would potentially like interested in revisiting it when you're coming back at some point, are working optimist, working on a gi at Tesla, I think Tesla is going to do incredible things. It's basically like uh it's a massive large scale robotics kind of company with a ton of in house talent for doing really incredible things and I think uh human robots are going to be amazing. I think autonomous transportation is going to be amazing. All this is happening at Tesla. So I think it's just a really amazing organization. So being part of it and helping it along I think was very, basically enjoyed that a lot. Yeah, it was basically difficult for those reasons because I love the company but you know, I'm happy to potentially at some point come back for Act two. But I felt like at this stage I built the team, it felt autonomous and I became a manager and I wanted to do a lot more technical stuff, I wanted to learn stuff, I want to teach stuff. Uh and uh I just kind of felt like it was a good time for for a change of pace a little bit.

Lex  01:52:45
What do you think is the best movie sequel of all time? Speaking of Part 2? Because like because most of them suck

Andrej  01:52:52
movie

Lex  01:52:53
Sequels and you tweet about movies. So just a tiny tangent is there? What's your, what's like a favorite movie sequel? Godfather? Part two. Um Are you a fan of Godfather cause you didn't even tweet or mention the Godfather.

Andrej  01:53:07
Yeah, I don't love that movie. I know it hasn't

Lex  01:53:08
edit that out. We're going to edit out the hate towards The Godfather? How dare you

Andrej  01:53:13
Think will make a strong statement? I don't know why. I don't know why, but I basically don't like any movie before 1995. Something like that.

Lex  01:53:21
Didn't you mention Terminator

Andrej  01:53:23
2? Okay, Okay. That's like a terminator two was a little bit later, 1990.

Lex  01:53:29
No, I think terminator two was in there

Andrej  01:53:31
And I like terminator one as well. So okay, so like a few exceptions, but by and large, for some reason I don't like movies before 1995 or something, they feel very slow. The camera is like zoomed out, it's boring, it's kind of naive. It's kind of weird.

Lex  01:53:44
And also Terminator was very much ahead of its time.

Andrej  01:53:47
Yes. And The Godfather, there's like no, A G. I joe

Lex  01:53:52
I mean, but you have Good Will Hunting was one of the movies you mentioned and that doesn't have any A G. I either. I guess that's mathematics. I

Andrej  01:54:01
guess occasionally I do in the movies that don't feature or

Lex  01:54:04
like anchorman that has no, that's that

Andrej  01:54:07
is so good.

Lex  01:54:08
I don't understand. Um Speaking of A G. I because I don't understand why Will Ferrell is so funny. It doesn't make sense. It doesn't compute there's just something about him and he's a singular human because you don't get that many comedies these days and I wonder if it has to do about the culture or the like The Machine of Hollywood or does it have to do it just we got lucky with certain people in comedy came together because he is a singular human. That was a ridiculous tangent, I apologize, but you mentioned humanoid robots. So what do you think about optimus? About Tesla body? Do you think we'll have robots in the factory in in in the home in 10 2030, 40, 50 years?

Andrej  01:54:49
Yeah, I think it's very hard project, I think it's going to take awhile but who else is going to build human robots at scale? And I think it is a very good form factor to go after because like I mentioned that the world is designed for human in form factor. These things will be able to operate our machines, they will be able to sit down in chairs, potentially even drive cars. Uh basically the world is designed for humans, that's the form factor you want to invest into and make work over time. Uh I think you know, there's another school of thought which is okay, take a problem and design a robot to it. But actually designing a robot and getting a whole data engine and everything behind it to work is actually incredibly hard problem. So it makes sense to go after general interfaces that okay, they are not perfect for any one given task but they actually have the generality of just with a prompt with english able to do something across and so I think it makes a lot of sense to go after a general uh interface um, in the physical world. And I think it's a very difficult project. It's going to take time. Um, but I see no other, no other company that can execute on that vision. I think it's going to be amazing. Like uh basically physical labor, like if you think transportation is a large market, try physical labor insane,

Lex  01:55:57
but it's not just physical labor. To me, the thing that's also exciting is the social robotics. So the relationship will have on different levels with those robots. That's why I was really excited to see optimists like um people have criticized me for the excitement, but I've I've worked with uh a lot of research labs that do humanoid legged robots, boston dynamics, unitary. A lot there's a lot of companies that do legged robots, but that's the the elegance of the movement is a tiny tiny part of the big picture. So integrating the two big exciting things to me about Tesla doing humanoid or any legged robots is clearly integrating into the data engine. So the data engine aspect, so the actual intelligence for the perception and the and the control and the planning and all that kind of stuff integrating into this huge the fleet that you mentioned, right. Um and then speaking of fleet, the second thing is the mass manufacturers just knowing uh culturally uh driving towards a simple robot that's cheap to produce at scale and doing that well, having experience to do that. Well, that changes everything. That's why that's a very different culture and style than boston dynamics who by the way, those those robots are just the way they move. It's like, it'll be a very long time before Tessa can achieve the smoothness of movement. But that's not what it's about.

It's, it's about, it's about the entirety of the system. Like we talked about the data engine and the fleet. That's super exciting. Even the initial sort of models but that too was really surprising that in a few months you can get a prototype

Andrej  01:57:47
and the reason that happened very quickly is as you alluded to, there's a ton of copy paste from what's happening in the autopilot a lot. The amount of expertise that like came out of the woodworks at Tesla for building the human robot was incredible to see like basically Ellen said at one point, we're doing this. And then next day, basically like all these cad models started to appear and people talking about like the supply chain and manufacturing and people showed up with like screwdrivers and everything like the other day and started to like put together the body and I was like, whoa! Like all these people exist at Tesla and fundamentally building a car is actually not that different from building a robot the same. And that is true, not just for the hardware pieces and also, let's not forget hardware, not just for a demo, but um, manufacturing of that hardware at scale. It's like a whole different thing, but for software as well, basically this robot currently thinks it's a car. Uh, it's gonna

Lex  01:58:40
have a midlife crisis or something. It

Andrej  01:58:43
thinks it's a car. Um, some of the earlier demos actually, we're talking about potentially doing them outside in the parking lot because that's where all of the computer vision that was like working out of the

Lex  01:58:51
box instead

Andrej  01:58:53
of like inside. Um, but all the operating system, everything just copy paste. Computer vision mostly copy paste. I mean, you have to retrain the neural nuts, but the approach and everything and data engine and offline trackers. And the way we go about the occupancy tracker and so on everything copy paste. You just need to retrain your neural lots. Uh, and then the planning control of course has to change quite a bit, but there's a ton of copy paste from what's happening at Tesla. And so if you were to, if you were to go with the goal of like, okay, let's build a million human robots and you're not Tesla, that's that's a lot to ask if your Tesla, it's actually like, it's not, it's not that crazy. And

Lex  01:59:26
then the follow up question is, and how difficult just like we're driving. How difficult is the manipulation task such that it can have an impact at scale. I think depending on the context. The really nice thing about robotics is that unless you do a manufacturing that kind of stuff is there's more room for error. Driving is so safety critical and so that and also time critical robot is allowed to move slower which is nice.

Andrej  01:59:54
I think it's going to take a long time. But the way you want to structure the development is you need to say okay it's going to take a long time. How can I set up the uh product development roadmap so that I'm making revenue along the way. I'm not setting myself up for a 01 loss function where it doesn't work until it works. You don't wanna be in that position. You want to make it useful almost immediately and then you want to slowly deploy it uh and uh

Lex  02:00:17
at

Andrej  02:00:17
scale and you want to set up your data engine, your improvement loops, the telemetry, the evaluation, the harness and everything. Um and you want to improve the product over time incrementally and you're making revenue along the way. That's extremely important because otherwise you cannot build these large undertakings just like don't make sense economically. And also from the point of view of the team working on it, they need the dopamine along the way. They're not just going to make a promise about this being useful. This is going to change the world in 10 years when it works, it's not where you want to be, you want to be in a place like I think about a politics today where it's offering increased safety and um and uh convenience of driving today, people pay for it, people like it, people purchase it and then you also have the greater mission that you're working towards

Lex  02:00:59
and you see that so the doping you for the team that that was a source of happiness, a

Andrej  02:01:04
100% you're deploying this. People like it. People drive it, people pay for it, they care about it. There's all these YouTube videos, your grandma drives it. She gives you feedback people like it, people engage with it, you engage with it huge.

Lex  02:01:15
Do people that drive Tesla's like recognize you and give you love like like hey thanks for the for the this nice feature that is doing

Andrej  02:01:25
Yeah, I think the tricky thing is like some people really love you, some people unfortunately like you're working on something that you think is extremely valuable, useful etcetera. Some people do hate you. There's a lot of people who like hate me and the team and everything the whole project and I

Lex  02:01:39
think Tesla drivers in

Andrej  02:01:41
many cases they're not actually

Lex  02:01:43
yeah, that's that's actually makes me sad about humans or the current, the ways that humans interact, I think that's actually fixable. I think humans want to be good to each other. I think twitter and social media is part of the mechanism that actually somehow makes the negativity more viral that it doesn't deserve like disproportionately uh add like a viral viral boost the negativity, but I got, I wish people would just get excited about uh so suppressed some of the jealousy, some of the ego and just get excited for others. And then there's a karma aspect to that you get excited for others, they'll get excited for you the same thing in academia. If you're not careful, there is a like a dynamical system there. If you, if you think of in silos and get jealous of somebody else being successful, that actually perhaps counterintuitively uh leads to less productivity of you as a community and you individually, I feel like if you keep celebrating

Andrej  02:02:39
others

Lex  02:02:40
that actually makes you more successful. Yeah, I think people haven't, depending on the industry haven't quite learned that

Andrej  02:02:46
yet. Some people are also very negative and very vocal, so they're very prominently featured, but actually there's a ton of people who are cheerleaders, but they're silent, clearly cheerleaders and when you talk to people just in the world, they will tell you it's amazing. It's great, especially like people who understand how difficult it is to get this stuff working like people who have built products and makers, entrepreneurs entrepreneurs, like making making this work and changing something is incredibly hard, those people are more likely to cheerlead you.

Lex  02:03:14
Well, well, one of the things that makes me sad is some folks in the robotics community don't do the cheerleading than they should. There's uh because they know how difficult it is. Well they actually sometimes don't know how difficult it is to create a product that scale. Right? They actually deployed in the real world. A lot of the development of robots and AI system is done on very specific small benchmarks. Um, and as opposed to real world conditions.

Andrej  02:03:40
Yeah, I think it's really hard to work on robotics in academic setting

Lex  02:03:43
or AI systems that apply in the real world. You, you've criticized you um flourished and loved for a time. The image net, the famed image that data set and I've recently had some words of criticism that the academic research ml community gives a little too much love still to the Image net or like those kinds of benchmarks. Can you speak to the strengths and weaknesses of datasets used in machine learning research?

Andrej  02:04:13
Actually I don't know that I recall the specific instance where I was unhappy or criticizing Image net. I think image that has been extremely valuable. Uh it was basically a benchmark that allowed the deep learning community to demonstrate that deep neural networks actually work. It was uh there's a massive value in that. So I think that was useful but basically it's become a bit of an amnesty at this point. So feminist is like equal to 28 by 28 grayscale digits there's kind of a joke dataset that everyone like just crushes,

Lex  02:04:44
there's still papers written on amnesty, right?

Andrej  02:04:46
Maybe like strong papers

Lex  02:04:48
like papers that focus on like how do we learn the small amount of data that

Andrej  02:04:53
I could see that being helpful but not in sort of like mainline computer vision research anymore. Of course. I

Lex  02:04:57
think the way I've heard you somewhere, maybe I'm just imagining things, but I think you said like that was a huge contribution to the community for a long time and now it's time to move past those kinds of

Andrej  02:05:07
that has been crushed. I mean, you know, the air rates are uh, Yeah, we're getting like 90% accuracy in in 1000 classification way, uh, prediction and I've seen those images and it's like really high. That's really, that's really good. If I'm correctly, the top five air rate is now like 1% or something.

Lex  02:05:28
Given your experience with the gigantic real world dataset, would you like to see benchmarks moving in certain directions that the research community uses?

Andrej  02:05:36
Unfortunately, I don't think academics currently have the next image net. We've obviously, I think we've crushed em n'est, we've basically kind of crushed image net. Uh, and there's no next sort of big benchmark that the entire community rallies behind and uses. Um, you know, for further development of these networks.

Lex  02:05:52
Yeah. What what it takes for data set to captivate the imagination of everybody. Like where they all get behind it? That that could also need like a virus like a leader, right. Somebody with popularity. I mean, yeah. Why did image of that take off? Is there or is it just the accident of history?

Andrej  02:06:10
It was the right amount of difficult. Uh, it was the right amount of difficult and simple and interesting enough. It just kind of like it was it was the right time for that kind of a data set

Lex  02:06:21
question from Reddit. Uh, what are your thoughts on the role that synthetic data and game engines will play in the future of neural net model development?

Andrej  02:06:31
I think. Um, as neural nets converge to humans, uh, the value of simulation to neural nets will be similar to value of simulation to humans. So people use simulation for uh, people use simulation because they can learn something in that kind of a system. Um, and without having to actually experience it. Um,

Lex  02:06:52
but are you referring to the simulation we do in our head. No,

Andrej  02:06:56
sorry, simulation. I mean, like video games or, you know, um, other forms of simulation for various professionals.

Lex  02:07:03
So let me push back on that because maybe there's simulation that we do in our heads. Like simulate if I do this. What do I think will happen?

Andrej  02:07:12
Okay. That's like internal simulation.

Lex  02:07:13
Yeah. Internal. Isn't that what we're doing assuming before we act?

Andrej  02:07:17
Yeah, but that's independent from like the use of simulation in the sense of like computer games or using simulation for training set creation or

Lex  02:07:23
is it independent or is it just loosely correlated? Because like isn't that useful to do like um counterfactual or like educators simulation to like, you know, what happens if there's a nuclear war? What happens if there's, you know like those kinds of things? Because yeah,

Andrej  02:07:42
that's a different simulation from like Unreal engine. That's how I interpreted the question.

Lex  02:07:45
Ah So like simulation of the average case, is that what's unreal engine? What what what what what do you mean by unreal engine? So simulating a world physics of that world? Why is that different? Like because you also can add behavior to that world and you can try all kinds of stuff, right? Like you could throw all kinds of weird things into it was a real engine is not just about similar. I mean I guess it is about submitting the physics of the world. It's also doing something with that.

Andrej  02:08:18
Yeah, the graphics, the physics and the agents that you put into the environment and stuff like that.

Lex  02:08:23
See, I think you I feel like you said that it's not that important I guess for the future of ai development, is that is that correct to interpret it that way?

Andrej  02:08:31
I think humans use simulators for humans use simulators and they find them useful. And so computers will use simulators and find them useful. Okay,

Lex  02:08:43
so you're saying it's not that I I don't use simulators very often. I play a video game every once in a while, but I don't think I derive any wisdom about my own existence from, from those video games? It's a momentary escape from reality versus a source of wisdom about

Andrej  02:08:57
reality. So

Lex  02:08:58
I don't, so I think that's a very polite way of saying simulation is not that useful.

Andrej  02:09:03
Yeah, maybe. Maybe not. I don't see it as like a fundamental, really important part of like training neural nets currently. Uh, but I think as neural nets become more and more powerful, I think you will need fewer examples to train additional behaviors. And uh, simulation is of course there's a domain gap in a simulation that is not the real world is slightly something different. But with a powerful enough neural net you need um, the domain gap can be bigger I think because neural net will sort of understand that even though it's not the real world, it like has all this little structure that I'm supposed to be like, learn from.

Lex  02:09:35
So the neural net will actually, yeah, we'll be able to leverage the synthetic data better by closing the gap by understanding in which ways this is not real data. Exactly. Right. To do better questions next time. That was that was a question. But I'm just kidding. All right. Um, so is it possible do you think speaking of amnesty to construct neural nets and training processes that require very little data. So we've been talking about huge data sets, like the international training. I mean, one way to say that it's like you said like the aquarium itself as another level of training I guess and that requires a little data but do you see any value in doing research and kind of going down the direction of can we use very little data to train to construct a knowledge base?

Andrej  02:10:29
100%. I just think like at some point you need a massive data set and then when you pre train your massive neural nut and get something that you know it is like a GPT or something then you're able to be very efficient at training any arbitrary new task. So a lot of these G. P. T. S you know you can do tasks like sentiment analysis or translation or so on just by being prompted with very few examples. Here's the kind of thing I want you to do like here's an input sentence, here's the translation into german input sentence, translation to german input sentence blank and the neural net will complete the translation to german just by looking at sort of the example you've provided. And so that's an example of a very few shot learning in the activations of the neural net instead of the weights of the neural net. And so I think um basically just like humans neurons will become very data efficient at learning any other new task but at some point you need a massive data set to pre train your network

Lex  02:11:21
to get that. And probably we humans have something like that. Do we do we have something like that? Do we have a passive in the background background model constructing thing that just runs all the time in the self supervised way? We're not conscious of it.

Andrej  02:11:37
I think humans definitely. I mean obviously we have we learnt a lot during during our life span but also we have a ton of hardware that helps us initial initialization coming from sort of evolution. And so I think that's also a really big big component. A lot of people in the field I think they just talk about the amount of like seconds and the you know that person has lived pretending that this is a sort of like a zero initialization of the neural nut. And it's not like you can look at a lot of animals like for example zebras, zebras get born and they see and they can run there's zero training data in their lifespan. They can just do that. So somehow I have no idea how evolution has found a way to encode these algorithms. And these neural net initialization are extremely good into A. T. C. Gs and have no idea how this works. But apparently it's possible because here's approved by existence.

There's

Lex  02:12:28
something magical about going from a single cell to organism that is born to the first few years of life. I kind of like the idea that the reason we don't remember anything about the first few years of our life is that it's a really painful process. Like it's a very difficult challenging training process like intellectually like and maybe. Yeah, I mean I don't why don't we remember any of that? There might be some crazy training going on and that maybe that's the background model training. That is very painful. And so it's best for the system once it's trained not to remember how it's constructed. I

Andrej  02:13:11
think it's just like the hardware for long term memory is just not fully developed. I kind of feel like the first few years of uh of infants is not actually like learning its brain

Lex  02:13:21
maturing

Andrej  02:13:22
um were born premature. Um there's a theory along those lines because of the birth canal and the swelling of the brain and so were born premature and then the first few years were just the brain's maturing and then there's some learning eventually. Um it's my current view on it.

Lex  02:13:37
What do you think? Do you think can have long term memory? I like that approach is something like humans. Do you think, do you think there needs to be another meta architecture on top of it to add something like a knowledge base that learns facts about the world and all that kind of stuff?

Andrej  02:13:54
Yes, but I don't know to what extent it will be explicitly constructed. Um It might take on intuitive forms where you are telling the gPT like, hey you have a, you have a declarative memory bank to which you can store and retrieve data from and whenever you encounter some information that you find useful, just save it to your memory bank and here's an example of something you have retrieved and here's how you say it and here's how you load from it, you just say load whatever you teach it in text in english and then it might learn to use a memory bank from from that. Oh,

Lex  02:14:26
so so the neural net is the architecture for the background model, the base thing and then everything else is just on top of that.

Andrej  02:14:33
It's not just the text, right? It's you're giving it gadgets and gizmos. So uh you're teaching some kind of special language by which we can, we can save arbitrary information and retrieve it at a later time and you're, you're telling about the special tokens and how to arrange them to use these interfaces. It's like, hey you can use a calculator, here's how you use it. Just do 53 plus 41 equals and when equals is there a calculator will actually read out the answer and you don't have to calculate it yourself and you just like tell it in english this might actually work,

Lex  02:15:02
do you think in that sense Gado is interesting. The deepmind system that it's not just the language but actually throws it all uh in the same pile, images, actions, all that kind of stuff that's basically what we're moving towards. Yeah,

Andrej  02:15:18
I think so. So Gatto is, is very much a kitchen sink approach to like um reinforcement learning lots of different environments with a single fixed transformer model. Right. Um I think it's a very sort of early result in that in that realm. But I think yeah, it's along the lines of what I think things will eventually look like.

Lex  02:15:37
Right? So this is the early days of a system that eventually will look like this. Like from a rich, rich, sudden perspective.

Andrej  02:15:43
I'm not super huge fan of, I think all these interfaces that look very different. Um I would want everything to be normalized into the same ap I so for example, screen pixels very same api instead of having like different world environments that are very different physics and joint configurations and appearances and whatever and you're having some kind of special tokens for different games that you can plug. I'd rather just normalize everything to a single interface. So it looks the same to the neural net, if that makes sense. So it's

Lex  02:16:08
all gonna be pixel based pong in the end.

Andrej  02:16:11
I think so, okay,

Lex  02:16:15
uh let me ask you about your own personal life. A lot of people want to know you're one of the most productive and brilliant people in the history of ai what is a productive day in the life of Andre Karpati look like. What time do you wake up? Because imagine um some kind of dance between the average productive day and a perfect productive day. So the perfect productive day is the thing we strive towards and the average is kind of what it kind of converges to giving all the mistakes and human eventualities and so on. So what time do you wake up? Like a morning person?

Andrej  02:16:47
I'm not a morning person, I'm a night owl for sure

Lex  02:16:50
it's stable or not,

Andrej  02:16:52
it's semi stable like eight or nine or something like that. During my PhD it was even later I used to go to sleep usually at three am I think uh am hours are are precious and very interesting time to work because everyone is asleep um at at eight AM or seven AM. The East coast is awake. So there's already activity, there's already some text messages, whatever there's stuff happening, you can go on like some news website and there's stuff happening distracting at three a.m. Everything is totally quiet and so you're not gonna be bothered and you have solid chunks of time to do work. Um So I like those periods night all by default and then I think like productive time basically um what I like to do is you need you need to like build some momentum on the problem without too much distraction and um you need to load your RAM uh your working memory with that problem and then you need to be obsessed with it when you're taking a shower, when you're falling asleep. You need to be obsessed with the problem and it's fully in your memory and you're ready to wake up and work on it right there. So

Lex  02:17:52
it is the scale of uh is this in a scale temporal scale of a single day or a couple of days a week? A month.

Andrej  02:17:58
So I can't talk about one day basically in isolation because it's a whole process when I want to get when I want to get productive in the problem. I feel like I need a span of a few days where I can really get in on that problem and I don't wanna be interrupted and I'm going to just be completely obsessed with that problem and that's where I do most of my good workouts.

Lex  02:18:17
You've done a bunch of cool like little projects in a very short amount of time very quickly so that that requires you just focusing on it.

Andrej  02:18:24
Yeah basically I need to load my working memory with the problem and I need to be productive because there's always like a huge fixed cost to approach any problem. Uh you know like I was struggling with this for example at Tesla because I want to work on the small side project but okay you first need to figure out okay I need to associate into my cluster, I need to bring up a V. S. Code editor so I can work on this. I need to I run into some stupid error because of some reason like you're not at a point where you can be just productive right away you are facing barriers and so it's about really removing all that barrier and you're able to go into the problem and you have the full problem loaded in your memory

Lex  02:18:58
and somehow avoiding distractions of all different forms like uh news stories, emails but also distractions from other interesting projects that you previously worked on are currently working on and so on. You just want to really focus your mind

Andrej  02:19:13
and I mean I can take some time off for distractions and in between but I think it can't be too much uh you know most of your day is sort of like spent on that problem and then you know I drink coffee, I had my morning routine. I look at some news twitter, hacker news, Wall Street Journal etcetera so it's great.

Lex  02:19:30
So basically you wake up you have some coffee. Are you trying to get to work as quickly as possible? Do you do taking this diet of of like what the hell is happening in the world? 1st

Andrej  02:19:40
I am I do find it interesting to know about the world. I don't know that it's useful or good but it's part of my routine right now. So I do read through a bunch of news articles and I want to be informed and um I'm suspicious of it. I'm suspicious of the practice but currently that's where I am. Oh

Lex  02:19:56
you mean suspicious about the positive effect of that practice on your productivity and your well being is

Andrej  02:20:02
my well being psychologically and

Lex  02:20:04
also on your ability to deeply understand the world because there's a bunch of sources of information, you're not really focused on deeply integrating

Andrej  02:20:12
distracting your Yeah,

Lex  02:20:14
in terms of perfectly productive day for how long of a stretch of time In one session, do you try to work and focus on the thing? A couple of hours? There's one hours and 30 minutes, 10 minutes.

Andrej  02:20:27
I can probably go like a small few hours and then I need some breaks in between for like food and stuff. And yeah, but I think like it's still really hard to accumulate hours. I was using a tracker that told me exactly how much time I spent coding any one day and even on a very productive day I still spent only like six or eight hours. Yeah, and it's just because there's so much padding, commute talking to people, food etcetera, there's like the cost of life just living and sustaining and homeostasis and just maintaining yourself as a human is very high and

Lex  02:20:59
and that there seems to be a desire within the human mind to to participate in society that creates that pattern because I yeah, the most productive days I've ever had is just completely from start to finish, just tuning out everything and just sitting there and then and then you could do more than six and eight hours, Is there some wisdom about what gives you strength to do? Like uh tough days of long focus?

Andrej  02:21:24
Yeah, just like whenever I get obsessed about a problem, something just needs to work, something just needs to exist.

Lex  02:21:28
It needs to exist. And so you're able to deal with bugs and programming issues and technical issues and uh design decisions that turned out to be the wrong ones, you're able to think through all of that given, given that you want to think to exist,

Andrej  02:21:41
it needs to exist. And then I think to me also a big factor is, you know, our other humans are going to appreciate it. Are they going to like it? That's a big part of my motivation if I'm helping humans and they seem happy, they say nice things, they tweet about it or whatever that gives me pleasure because I'm doing something useful.

Lex  02:21:57
So like you do see yourself sharing it with the world, like what? Get help with the blog posts or videos?

Andrej  02:22:03
Yeah, I was thinking about it like suppose I did all these things but did not share them. I don't think I would have the same amount of motivation that I can build up.

Lex  02:22:09
You enjoy the feeling of other people gaining value and happiness from the stuff you've created. What about diet is there? I saw you play with intermittent fasting you fast. Does that help

Andrej  02:22:23
with everything

Lex  02:22:24
with the things you played? What's been most beneficial to the, your ability to mentally focus on the thing and just mental mental productivity and happiness. You're still fast

Andrej  02:22:35
so fast. But I do intermittent fasting. But really what it means at the end of the day is I skip breakfast. So I do uh 18 6 roughly by default when I'm in my steady state, if I'm traveling or doing something else, I will break the rules. But in my steady state I do 18 6, so I eat only from 12 to 6. Not a hard rule and I break it often, but that's my default. And then um yeah, I've done a bunch of random experiments for the most part right now where I've been for the last year and a half I want to say is um plant based or plant forward. I heard plant forward. It sounds

Lex  02:23:05
better. Exactly. I

Andrej  02:23:06
don't actually know the difference is, but it sounds better in my mind, but it just means that I prefer plant based food and uh

Lex  02:23:12
or cooked, I

Andrej  02:23:14
prefer cooked and plant

Lex  02:23:16
based. So plant based. Forgive me, I don't actually know how why the category of plant entails

Andrej  02:23:24
just means that you're not

Lex  02:23:26
about it

Andrej  02:23:27
and you can flex and uh you just prefer to eat plants and you know, you're not making, you're not trying to influence other people and if someone is, you come to someone's house party and they serve you a steak that they're really proud of. You will eat it. It's

Lex  02:23:40
just not judgmental. That's beautiful. I mean that's um on the flip side of that, but I'm very sort of flexible. Have you tried doing one meal a day?

Andrej  02:23:48
I have accidentally, not consistently, but I've accidentally had that. I don't, I don't like it. I think it makes me feel not good. It's too, it's too much, too much of a hit. And so currently I have about two meals a day, 12 and six.

Lex  02:24:02
I do that nonstop. I'm doing it. No one meal a day. It's interesting. It's an interesting feeling. Have you ever fasted longer than a day?

Andrej  02:24:10
Yeah, I've done a bunch of water fasts because I was curious what happens. Uh

Lex  02:24:14
Anything interesting? Yeah,

Andrej  02:24:16
I would say so. I mean, you know what's interesting is that you're hungry for two days and then starting day three or so you're not hungry. It's like such a weird feeling because you haven't eaten in a few days and you're not hungry. Is

Lex  02:24:26
that weird? It's really one of the many weird things about human biology. It figure something out. It finds, finds another source of energy or something like that or relaxes the system. I don't know how

Andrej  02:24:38
the body is, like you're hungry, you're hungry and then it just gives up. It's like, okay, I guess we're fasting now.

Lex  02:24:42
There's nothing

Andrej  02:24:43
and then it just kind of like focuses on trying to make you not hungry and you know not feel the damage of that and trying to give you some space to figure out the food situation.

Lex  02:24:53
So are you still to this day most productive at

Andrej  02:24:57
night? I would say I am, but it is really hard to maintain my PhD schedule um especially when I was working at Tesla and so on, it's a nonstarter, so, but even now like you know, people want to meet for various events, they society lives in a certain period of time and you sort of have to like so that

Lex  02:25:15
it's hard to like do a social thing and then after that return and do work.

Andrej  02:25:20
Yeah, it's just really hard.

Lex  02:25:23
That's why I tried when I do social things, I try not to do too too much drinking so I can return and continue doing work. Um but Tesla, is there is there a convergence Tesla, but any company, is there a convergence to him as a schedule or is there more, is that how humans behave when they collaborate? I need to learn about this. Do they try to keep us consistent schedule? You're all awake at the same time?

Andrej  02:25:49
I'm gonna do try to create a routine and I try to create a steady state in which I'm comfortable in, so I have a morning routine. I have a day routine. I try to keep things to a steady state and things are predictable and then you can sort of just like your body just sort of like sticks to that and if you try to stress that a little too much it will create uh you know when you're traveling and you're dealing with Jetlag, you're not able to really ascend to, you know where you need to go.

Lex  02:26:13
Yeah. Yeah. That's what about humans with the habits and stuff? What are your thoughts on work life balance throughout a human lifetime? So testing part was known for sort of pushing people to their limits in terms of what they're able to do in terms of what they're trying to do in terms of how much they work, all that kind of stuff.

Andrej  02:26:34
Yeah, I mean I will say Tesla is still too much bad rep for this because what's happening is Tesla is a it's a bursty environment. So I would say the baseline, my only point of reference is google, like where I've entered three times and I saw what it's like inside google and deepmind. Um I would say the baseline is higher than that, but then there's a punctuated equilibrium where once in a while there's a fire and someone like people work really hard and so it's spiky and bursty and then all the stories get collected

Lex  02:27:02
and

Andrej  02:27:03
then it gives the appearance of like total insanity, but actually it's just a bit more intense environment and there are fires and sprints and so I think, you know, it definitely though. I would say um it's a more intense environment than something you would get

Lex  02:27:16
your person forget all of that just in your own personal life. Um What do you think about the happiness of a human being, a brilliant person like yourself about finding a balance between work and life or is it such a thing? Not a good thought experiment?

Andrej  02:27:35
Yeah, I think, I think balance is good, but I also love to have sprints that are out of distribution and that's when I think I've been pretty uh creative. And um as well,

Lex  02:27:47
sprints out of distribution means that most of the time you have uh quote unquote balance,

Andrej  02:27:55
I have balanced most of the time. I like being obsessed with something once in a while,

Lex  02:27:59
once in a while, once a week, Once a month, once a year.

Andrej  02:28:02
Probably like once a month or something.

Lex  02:28:03
Yeah. And that's when we get and you get

Andrej  02:28:06
that's when you really care about a problem, it must exist. This will be awesome. You're obsessed with it. And now you can't just do it on that day. You need to pay the fixed cost of getting into the groove and then you need to stay there for a while and then society will come and they will try to mess with you and they will try to distract you. Yeah. The worst thing is like a person who's like, I just need five minutes of your time. Yeah. This is the cost of, that is not five minutes and society needs to change how it thinks about just five minutes of your

Lex  02:28:32
time. Right? It's never it's never just one minute. It's just just a quick what's the big

Andrej  02:28:38
deal are you being so?

Lex  02:28:39
Yeah. No. What's your computer setup? What what's like the perfect. Are you somebody that's flexible too, no matter what laptop, four screens or do you prefer a certain set up that you're most productive?

Andrej  02:28:56
Um I guess the one that I'm familiar with is one large screen 27 in um and my laptop on the side,

Lex  02:29:03
what operating system

Andrej  02:29:05
I do max that's my primary

Lex  02:29:06
for all tasks

Andrej  02:29:08
I would say was x. But when you're working on deep learning everything as Linux, your ssh into a cluster and you're working remotely,

Lex  02:29:14
but what about the actual development, like they're using the I. D.

Andrej  02:29:17
You would use I think a good way is you just run V. S. Code um My favorite editor right now on your Mac, but you are actually you have a remote folder through ssh. Um So the actual files that you're manipulating on the cluster somewhere else.

Lex  02:29:31
So what's the best I. D. V. S code? What else do people? So I use imax still uh It may be cool. I don't know if it's maximum productivity. Um So what what do you recommend in terms of editors? You worked a lot of software engineers, editors for python, c plus plus machine machine learning applications.

Andrej  02:29:54
I think the current answer is V. S. Code. Currently I believe that's the best. Um I. D. It's got a huge amount of extensions. It has Guitar, co pilot um uh integration which I think is very valuable.

Lex  02:30:06
What do you think about the co pilot integration? I was actually uh I got to talk a bunch with was a creative python and he loves co pilot. You like programs a lot with it. Uh Do you

Andrej  02:30:20
use co pilot? I love it and it's free for me but I would pay for it. Yeah I think it's very good and the utility that I found with it was isn't isn't I would say there's a learning curve and you need to figure out when it's helpful and when to pay attention to its outputs and when it's not going to be helpful where you should not pay attention to it because if you're just reading it suggestions all the time it's not a good way of interacting with it. But I think I was able to like mold myself to it. I found it very helpful number one in copy paste and replace some parts. So I don't know when the pattern is clear, it's really good at completing the pattern and number two. Sometimes it suggests a p. I is that I'm not aware of. So it it tells you about something that you didn't know. So

Lex  02:30:58
and that's an opportunity to discover and

Andrej  02:30:59
it's an opportunity to so I would never take copilot code has given, I almost always copy copy paste into a google search and you see what this function is doing and then you're like, oh it's actually actually exactly what I need, thank you co pilot. So you learn something

Lex  02:31:12
so it's in part of search engine apart, maybe getting the exact syntax correctly that once you see it. Yeah, it's that and be hard things like once you see it, you know,

Andrej  02:31:22
correct.

Lex  02:31:23
You yourself

Andrej  02:31:25
can struggle,

Lex  02:31:25
you can verify efficiently, but you can't generate efficiently and

Andrej  02:31:29
co pilot really, I mean it's it's autopilot for programming, right? And currently is doing the link following, which is like the simple copy paste and sometimes suggest, but over time it's going to become more and more autonomous. And so the same thing will play out and not just coding, but actually across many, many different things, probably

Lex  02:31:45
coding is an important one, right? Writing programs. How do you see the future of that, developing the program synthesis? Like being able to write programs that are more and more complicated because right now it's human supervised in interesting ways like what it feels like the transition will be very painful.

Andrej  02:32:05
My mental model for it is the same thing will happen as with the autopilot. So currently doing the following is doing some simple stuff and eventually we'll be doing autonomy and people will have to intervene less and less

Lex  02:32:16
and there could be like like testing mechanisms like if it writes a function and that function looks pretty damn correct. But how do you know it's correct because you're like getting lazier and lazier as a programmer, like your ability to cause like little bugs but I guess it won't make a little

Andrej  02:32:34
it will it co pilot will make off by one subtle bugs. It has done that to me. But

Lex  02:32:39
do you think future systems will or is it really off by one is actually a fundamental challenge of programming.

Andrej  02:32:46
In that case it wasn't fundamental and I think things can improve but yeah I think humans have to supervise. I am nervous about people not supervising what comes out and what happens to for example the proliferation of bugs in all of our systems. I'm nervous about that but I think there will probably be some other co pilots for bug finding and stuff like that at some point because there will be like a lot more automation for

Lex  02:33:07
man,

Andrej  02:33:09
it's

Lex  02:33:09
like a program,

Andrej  02:33:11
a co

Lex  02:33:11
pilot that generates a compiler, one that does a lint er one that does like a type checker,

Andrej  02:33:21
it's a committee of like GPT sort of like

Lex  02:33:24
and then they'll be like a manager for the committee and then there would be somebody that says a new version of this is needed. We need to regenerate it.

Andrej  02:33:30
Yeah there were 10 G. P. T. S. They were forwarded and get 50 suggestions. Another one looked at it and picked a few that they like a bug, one looked at it and it's like it's probably a bug. They got re ranked by some other thing and then a final ensemble GPT comes in. It's like okay given everything you guys have told me this is probably the next token. You

Lex  02:33:47
Know the feeling is the number of programmers in the world has been growing and growing very quickly. Do you think it's possible that it will actually level out and drop to like a very low number with this kind of world? Because then you'll be doing software 2.0 programming. Um And you'll be doing this kind of generation of co pilot type systems, programming but you won't be doing the old school software one point oh programming. I

Andrej  02:34:13
don't currently think that they're just going to replace human programmers. Um I'm so hesitant saying stuff like this right because

Lex  02:34:21
this is going to be replaced

Andrej  02:34:23
in five years.

Lex  02:34:23
I know it's going to show

Andrej  02:34:25
that like this

Lex  02:34:26
is where we thought because I I agree with you but I think we might be very

Andrej  02:34:30
surprised

Lex  02:34:32
right? Like what are the next i what's your sense of where we stand with language models? Like does it feel like the beginning or the middle or the end?

Andrej  02:34:41
The beginning? 100%. I think the big question in my mind is for sure. GPT will be able to program quite well competently and so on. How do you steer the system? You still have to provide some guidance to what you actually are looking for. And so how do you steer it? And how do you say, how do you talk to it? How do you um audited and verified that what is done is correct. And how do you like work with this? And it's as much not just an ai problem but a ui ux problem. Yeah.

Um So beautiful fertile ground for so much interesting work for V. S. Code plus plus where you're not just not just human programming anymore. It's amazing.

Lex  02:35:15
Yeah. So you're interacting with the system so not just one prompt but its iterative prompting trying to figure out having a conversation with the system. That actually I mean to me that's super exciting to have a conversation with the program I'm writing.

Andrej  02:35:29
Yeah maybe at some point you're just conversing with it. It's like okay here's what I wanna do actually this variable. Maybe it's not even that low level is variable but you

Lex  02:35:37
can also imagine like can you translate this to C. Plus plus and back to python

Andrej  02:35:42
already kind of existence

Lex  02:35:44
but just like doing it as part of the program experience. Like I think I'd like to write this function in C Plus plus or like you just keep changing from different different programs because there's different syntax, maybe I want to convert this into a functional language and so like you get to become multi lingual as a programmer and dance back and forth officially.

Andrej  02:36:06
I think the Ui ux of it though is like still very hard to think through because it's not just about writing code on a page, you have an entire developer environment, you have a bunch of hardware on it. Uh you have some environmental variables, you have some scripts that are running in a Cron job like there's a lot going on to like working with computers and how do these systems set up environment flags and work across multiple machines and set up screen sessions and automate different processes like how all that works and is auditable by humans and so on is like massive questions. The moment

Lex  02:36:36
you've built archive sanity, what is archive and what is the future of academic research publishing that you would like to see?

Andrej  02:36:45
So archive is this pre print server. So if you have a paper you can submit it for publication to journals or conferences and then wait six months and then maybe get a decision pass or fail or you can just uploaded to archive and then people can tweet about it three minutes later and then everyone sees it. Everyone reads it and everyone can profit from it in their own ways

Lex  02:37:04
and you can cite it and it has an official look to it. It feels like a like it feels like a publication process. It feels different than if you just put in a blog post.

Andrej  02:37:13
Oh yeah, I mean it's a paper and usually the bar is higher for something that you would expect on archive as opposed to and something you would see in a blog post

Lex  02:37:21
or the culture created the bar because you could probably host a pretty crappy fix for an archive. Um So what's that make you feel like, what does that make you feel about peer review? So rigorous peer review by 23 experts versus the peer review of the community? Right? As it's written

Andrej  02:37:41
basically, I think the community is very well able to peer review things very quickly on twitter and I think maybe it just has to do something with A. I. Machine learning field specifically though, I feel like things are more easily auditable. Um and the verification is easier potentially than the verification somewhere else. So it's kind of like um you can think of these scientific publications as like little block chains where everyone's building on each other's work and setting each other and you sort of have A I which is kind of like this much faster and loose Blockchain, but then you have, and any one individual entry is like very, very cheap to make and then you have other fields where maybe that model doesn't make as much sense. Um And so I think in a I at least things are pretty easily verifiable and so that's why when people upload papers, they're a really good idea and so on, People can try it out the next day and they can be the final arbiter of whether it works or not on their problem and the whole thing just moves significantly faster. So I kind of feel like academia still has a place, sort of just like conference journal process still has a place, but it's sort of like um it lags behind I think and it's a bit more maybe higher quality process, but it's not sort of the place where you will discover cutting edge work anymore. It used to be the case when I was starting my PhD that you go to conferences and journals and you discuss all the latest research now when you go to a conference or general like no one discusses anything that's there because its already like three generations ago irrelevant.

Lex  02:39:03
Which makes me sad about like Deepmind, for example, where they still they still publish in nature and these big prestigious, I mean there's still value I suppose to the prestige that comes with these big venues, but the result is that they will announce some breakthrough performance and it will take like a year to actually publish the details, I mean, and those details in if they were published immediately would inspire the community to move in certain directions with that

Andrej  02:39:30
let's speed up the rest of the community, but I don't know to what extent that's part of their objective function also,

Lex  02:39:35
that's true. So it's not just the prestige. A little bit of the delay is uh, is part of Yeah,

Andrej  02:39:40
they certainly deepmind specifically has been um, working in the regime of having slightly higher quality, basically process and latency and publishing those papers that way. Another

Lex  02:39:51
question from Reddit, Do you or have you suffered from imposter syndrome being the director of Ai. Tesla, being this person when you're stanford, where like the world looks at you as the expert in ai to teach, teach the world about machine learning.

Andrej  02:40:09
When I was leaving Tesla after five years, I spent a ton of time in meeting rooms. Uh, and you know, I would read papers in the beginning when I joined Tesla, I was writing code and then I was writing less and less code and I was reading code and then I was reading less and less code. And so this is just a natural progression that happens, I think. And uh, definitely I would say near the tail end, that's when it sort of starts to hit you a bit more that you're supposed to be an expert. But actually the source of truth is the code that people are writing the guitar and the actual, the actual code itself and you're not as familiar with that as it used to be. And so I would say maybe there's some like insecurity there.

Lex  02:40:40
Yeah, that's actually pretty profound that a lot of the insecurity has to do with not writing the code in the computer science space like that, because that is the truth, that that code

Andrej  02:40:49
is the source of truth, the papers and everything else. It's a high level summary. I don't yeah, just a high level summary. But at the end of the day you have to read code, it's impossible to translate all that code into actual, you know, paper form. So when when things come out, especially when they have a source code available, that's my favorite place to

Lex  02:41:06
go. So like I said, you're one of the greatest teachers of machine learning ai ever from CS to 31 end to today, what advice would you give to beginners? Interested in getting into machine learning,

Andrej  02:41:20
beginners are often focused on

Lex  02:41:22
like what

Andrej  02:41:23
to do, and I think the focus should be more like how much you do. So I'm kind of like believer on the high level in this 10,000 hours kind of concept where you just kind of have to just pick the things where you can spend time and you you care about and you're interested in, you literally have to put in 10,000 hours of work. Um it doesn't even matter as much like where you put it and you'll iterate and you'll improve and you'll waste some time. I don't know if there's a better way you need to put in 10,000 hours, But I think it's actually really nice because I feel like there's some sense of determinism about being an expert at a thing. If you spend 10,000 hours you can literally pick an arbitrary thing. And I think if you spend 10,000 hours of deliberate effort and work you actually will become an expert at it. And so I think it's kind of like a nice thought. Um and so uh basically I would focus more on like are you spending 10,000 hours? and

Lex  02:42:10
So and then thinking about what kind of mechanisms maximize your likelihood of getting to 10,000 hours?

Andrej  02:42:16
Exactly. Which

Lex  02:42:17
for us silly humans means probably forming a daily habit of like every single day actually doing the thing

Andrej  02:42:23
whatever helps you. So I do think to a large extent is a psychological problem for yourself. One other thing that I help that I think is helpful for the psychology of it is many times people compare themselves to others in the area I think is very harmful. Only compare yourself to you from some time ago, like say a year ago, are you better than you year ago is the only way to think. Um And I think this then you can see your progress and it's very motivating.

Lex  02:42:46
That's so interesting that focus on the quantity of hours because I think a lot of people in the beginning stage but actually throughout get paralyzed by uh the choice like which one do I pick this path of this path, like they'll literally get paralyzed by like which I d to use. Well

Andrej  02:43:06
they're worried they're worried about all these things. But the thing is some of the you will waste time doing something wrong, you will eventually figure out it's not right, you will accumulate scar tissue and next time you'll grow stronger because next time you'll have the scar tissue and next time you'll learn from it and now next time you come to a similar situation you'll be like oh I I messed up, I've spent a lot of time working on things that never materialized into anything and I have all that scar tissue and I have some intuitions about what was useful wasn't useful how things turned out. So all those mistakes were were not that work, you know? So I just think you should just focus on working what have you done, what have you done last week?

Lex  02:43:43
That's a good question actually to ask for for a lot of things, not just machine learning. Um It's a good way to cut the, I forgot what the term we use but the fluff the blubber, whatever the uh the inefficiencies in life. What do you love about teaching, You seem to find yourself often in the like drawn to teaching. You're very good at it, but you're also

Andrej  02:44:06
drawn to it. I mean I don't think I love teaching, I love happy humans

Lex  02:44:11
and

Andrej  02:44:11
happy humans. Like when I teach,

Lex  02:44:13
I

Andrej  02:44:14
wouldn't say I hate teaching, I tolerate teaching but it's not like the act of teaching that I like. It's it's that um You know I I have some I have something I'm actually okay at it. I'm okay at teaching and people appreciate a lot. And so I'm just happy to try to be helpful and teaching itself is not like the most. I mean it's really it's can be really annoying frustrating. I was working on a bunch of lectures just now. I was reminded back to my days of 231 and just how much work it is to create some of these materials and make them good. The amount of iteration and thought and you go down blind alleys and just how much you change it. So creating something good. Um in terms of educational value is really hard and it's not fun. It's

Lex  02:44:55
difficult. So people should definitely go watching new stuff you put out. There are lectures where you actually building the thing like from like you said the code is truth. So discussing back propagation by building it by looking through and just the whole thing. So how difficult that to prepare for. I think it's a really powerful way to teach. How did you have to prepare for that or are you just live thinking through it?

Andrej  02:45:18
I will typically do like say three takes and then I take like the better take. So I do multiple takes and I take some of the better takes and then I just build out a lecture that way. Sometimes I have to delete 30 minutes of content because it just went down an alley that I didn't like too much. There's about a bunch of iteration and it probably takes me, you know, somewhere around 10 hours to create one hour of content

Lex  02:45:37
to give one hour. It's interesting. I mean, is it difficult to go back to the, like, the basics? Do you draw a lot of, like, wisdom from going back to the basics?

Andrej  02:45:45
Yeah. Going back to back propagation loss functions where they come from. And one thing I like about teaching a lot, honestly is it definitely strengthens your understanding. So it's not a purely altruistic activity. It's a way to learn if you have to explain something to someone, uh you realize you have gaps in knowledge. Uh And so I even surprised myself in those lectures, like, also the result will obviously look at this and then the result doesn't look like it. And I'm like, okay, I thought I understood this, but that's why

Lex  02:46:13
it's really cool to literally code. You run it in the notebook and it gives you a result and you're like, oh wow, like actual numbers, actual input, you know, actual code,

Andrej  02:46:23
it's not mathematical symbols, etcetera. The source of truth is the code. It's not slides, it's just like, let's build

Lex  02:46:29
it, It's beautiful, You're a rare human in that sense. What advice would you give to researchers trying to develop and published idea that have a big impact in the world of aI so maybe um undergrads, maybe early graduate students.

Andrej  02:46:46
I mean, I would say like they definitely have to be a little bit more strategic than I had to be as a PhD student because of the way I is evolving. It's going the way of physics where, you know, in physics, you used to be able to do experiments on your bench top and everything was great and you can make progress and now you have to work in like LHC or like cern and and so ai is going in that direction as well. Um, so there's certain kinds of things that's just not possible to do on the bench top anymore. And uh, I think um that didn't used to be the case at the time. Do

Lex  02:47:16
you still think that there's like gan type papers to be written, were like, like very simple idea that requires just one computer to illustrate a simple example.

Andrej  02:47:28
I mean, one example that's been very influential recently is diffusion models. The fusion models are amazing. The fusion models are six years old for the longest time. People are kind of ignoring them as far as I can tell and they're an amazing generative model, especially in images and so stable diffusion and so on. It's all diffusion based. The fusion is new, it was not there and came from, well, it came from google, but a researcher could have come up with it. In fact, some of the first actually, no, those came from google as well. But a researcher could come up with that in an academic institution.

Lex  02:47:58
Yeah. What do you find most fascinating about diffusion models? So from the societal impact of the technical architecture,

Andrej  02:48:06
what I like about the fusion is it works so well.

Lex  02:48:08
Was that is that surprising to you? The amount of the variety almost the novelty of the synthetic data is generating?

Andrej  02:48:16
Yes, So the stable diffusion images are incredible. It's the speed of improvement in generating images has been insane. Uh We went very quickly from generating like tiny digits to the tiny faces and it all looked messed up. And now you're stable diffusion. And that happened very quickly. There's a lot that academia can still contribute, you know, for example, um Flash attention is a very efficient colonel for running the attention operation inside the transformer that came from academic environment. It's a very clever way to structure the colonel. Uh that that's the calculation, so it doesn't materialize the attention matrix. Um and so there's I think there's still like lots of things to contribute, but you have to be just more strategic. Do

Lex  02:48:54
you think neural networks can be made to reason?

Andrej  02:48:57
Uh Yes. Do

Lex  02:48:59
you think they're already reason.

Andrej  02:49:01
What's

Lex  02:49:02
your definition of reasoning?

Andrej  02:49:03
Uh information processing.

Lex  02:49:08
So in the way that humans think through a problem and come up with novel ideas, it feels like reasoning. So the novelty, I don't want to say, But out of distribution ideas you think it's possible?

Andrej  02:49:26
Yes. And I think we're seeing that already in the current you're able to remix the training set information into true generalization in some sense.

Lex  02:49:34
That doesn't appear it doesn't appear in the in

Andrej  02:49:37
the training set. Like you're doing something interesting, algorithmic lee, you're manipulating, you know, some symbols and you're coming up with some correct a unique cancer in a new setting.

Lex  02:49:48
What would

Andrej  02:49:49
uh

Lex  02:49:50
illustrate to you? Holy ship? This thing is definitely thinking

Andrej  02:49:54
to me thinking or reasoning is just information processing and generalization. And I think the neural nets already do that today.

Lex  02:50:01
So being able to perceive the world or perceive the whatever the inputs are and to make predictions based on that or actions based on that. That's that's the reason

Andrej  02:50:12
you're giving correct answers in novel settings. By manipulating information, you've learned to correct algorithm, You're not doing just some kind of a look up table and there's neighbor search something like

Lex  02:50:23
that. Let me ask you about A. G. I. What what are some Moonshot ideas you think might make significant progress towards A G. I. Maybe in other ways, what are big blockers that we're missing now. So

Andrej  02:50:36
basically I am fairly bullish on our ability to build a G. I. S. Uh basically automated systems that we can interact with and are very human like and we can interact with them in the digital realm or physical realm. Currently it seems most of the models that sort of do these sort of magical tasks are in a text realm. Um I think uh as I mentioned I'm suspicious that text realm is not enough to actually build full understanding of the world. I do actually think you need to go into pixels and understand the physical world and how it works. So I do think that we need to extend these models to consume images and videos and train on a lot more data that is multimodal in that way. Do

Lex  02:51:16
you think you need to touch the world to understand it also? Well that's

Andrej  02:51:18
the big open question I would say in my mind is if you also require the embodiment and the ability to sort of interact with the world run experiments and have a data of that form then you need to go to optimists

Lex  02:51:30
or something

Andrej  02:51:31
like that. And so I would say optimist in some way is like a hedge. Um in A. G. I. Because it seems to me that it's possible that just having data from the internet is not

Lex  02:51:43
enough if

Andrej  02:51:44
that is the case then optimists may lead to a G. I. Uh because optimists would to me there's nothing beyond optimists you have like this humanoid form factor that can actually like do stuff in the world, you can have millions of them interacting with humans and so on. And uh if that doesn't give rise to a G. I. At some point, like I'm not sure what will. Um So from a completeness perspective, I think that's the that's a really good platform, but it's a much harder platform because you are dealing with atoms and you need to actually like build these things and integrate them into society. So I think that path takes longer,

Lex  02:52:18
but it's

Andrej  02:52:18
much more certain. And then there's a path of the internet and just like training these compression models effectively on trying to compress all the internet. And that might also give these agents as well compress

Lex  02:52:32
the internet, but also interact with the internet, so it's not obvious to me. In fact, I suspect you can reach A. G. I. Without ever entering the physical world and which is a little bit more uh concerning because it might that results in it happening faster. So it just feels like we're like in boiling water we won't know as it's happening. I

Andrej  02:52:58
would like to

Lex  02:52:59
I'm not afraid of a G. I I'm excited about it, There's always concerns, but I would like to know when it happens.

Andrej  02:53:07
Yeah.

Lex  02:53:08
And have like hints about when it happens like a year from now, it will happen, that kind of thing. Yeah, I just feel like in the digital realm it just might happen.

Andrej  02:53:16
Yeah, I think all we have available to us because no one has built A G. I. Again so all we have available to us is uh is there enough for child ground on the periphery I would say yes and we have the progress so far which has been very rapid and there are next steps that are available. And so I would say yeah it's quite likely that we'll be interacting with digital entities.

Lex  02:53:37
How will you know that somebody is

Andrej  02:53:40
it's going to be a slow I think it's going to be a slow incremental transition is going to be product based and focused is going to be a top copilot. Getting better and then GPT is helping you right and then these oracles that you can go to with mathematical problems. I think we're on a on the verge of being able to ask very complex questions in chemistry, physics math of these oracles and have them complete solutions.

Lex  02:54:03
So A G. I. To use primarily focus on intelligence. So consciousness doesn't enter into into it.

Andrej  02:54:11
So in my mind consciousness is not a special thing, You will you will figure out and bolt on. I think it's an emergent phenomenon of a large enough and complex enough um generative model sort of So um if you have a complex in the world model that understands the world then it also understands its predicament in the world as being a language model which to me is a form of consciousness or self awareness. And

Lex  02:54:35
so in order to understand the world deeply, you probably have to integrate yourself into the world and in order to interact with humans and other living beings. Consciousness is a very useful

Andrej  02:54:45
tool. I think consciousness is like a modeling insight

Lex  02:54:49
modeling insight.

Andrej  02:54:50
Yeah, it's a you have a powerful enough model of understanding the world that you actually understand, that you are an entity in it. Yeah,

Lex  02:54:57
but there's also this um perhaps just the narrative we tell ourselves there's a it feels like something to experience the world, the hard problem of consciousness, but that could be just a narrative that we tell ourselves.

Andrej  02:55:08
Yeah, I don't think, yeah, I think it will emerge. I think it's going to be something very boring, like we'll be talking to these digital a eyes, they will claim their conscious, they will appear conscious, they will do all the things that you would expect of other humans. And it's going to just be a stalemate. I think there will

Lex  02:55:24
be a lot of actual fascinating ethical questions like Supreme Court level questions of whether you're allowed to turn off a conscious ai if you're allowed to build a conscious ai uh maybe there would have to be the same kind of the base that you have around um sorry to bring up a political topic, but, you know, abortion, which is the deeper question with abortion is what is life. And the deep question with ai is also what is life and what is conscious and I think that would be very fascinating to bring up. It might become illegal to build systems that are capable the like of such level of intelligence that consciousness would emerge and therefore the capacity to suffer would emerge. And some a system that says, no, please don't kill me.

Andrej  02:56:19
That's what the lambda compute the lambda chatbot already told this google engineer, right? Like it was talking about not wanting to die or so on.

Lex  02:56:28
So that might become illegal to do that, right? Because otherwise, you might have a lot of, a lot of creatures that don't want to die and they will just

Andrej  02:56:39
spawn infinity of them on the cluster.

Lex  02:56:42
And then that might lead to like horrible consequence because then there might be a lot of people that secretly love murder and they will start practicing murder in those systems. I mean, there's just to

Andrej  02:56:52
me all of this

Lex  02:56:53
stuff just brings a beautiful mirror to the human condition and human nature will get to explore it. And that's what like the best of the Supreme Court of all the different debates we have about ideas of what it means to be human. We get to ask those deep questions that we've been asking throughout human history. There has always been the other in human history. Uh we're the good guys and that's the bad guys. And we're going to, you know, throughout human history, let's murder the bad guys. And the same will probably happen with robots that will be the other at first and then we'll get to ask questions. What does it mean to be alive? What does it mean to be conscious?

Andrej  02:57:30
And I think there's some Canary in the coal mines even with what we have today. Um And uh you know like for example these there's these like y foods that you can like work with and some people are trying to like this company is going to shut down, but this person really like love their wife. Ooh and like it's trying to like put it somewhere else and like it's not possible. And like I think like definitely people will have feelings towards uh towards these systems because in some sense they are like a mirror of humanity because they are like sort of like a big average of humanity in a way that it's trained

Lex  02:58:02
but we can that average we can actually watch it. So it's nice to be able to interact with the big average of humanity and do like a search query on it.

Andrej  02:58:10
Yeah, that's very fascinating. And we can also of course also like shape it. It's not just a pure average. We can mess with the training data, we can mess with the objective, we can find them in various ways. So we have some um you know, impact on what those systems look like

Lex  02:58:26
if you want to achieve a G. I. Um And you could have a conversation with her and ask her talk about anything. Maybe ask her a question. What kind of stuff would you would you ask?

Andrej  02:58:37
I would have some practical questions in my mind like uh do I or my loved ones really have to die? What can we do about that?

Lex  02:58:46
Do you think it will answer clearly or would it answer poetically?

Andrej  02:58:51
I would expect it to give solutions. I would expect it to be like well I've read all of these textbooks and I know all these things that you've produced and it seems to me like here are the experiments that I think it would be useful to run next and here's some gene therapies that I think would be helpful and uh here are the kinds of experiments you should run.

Lex  02:59:05
Okay let's go to this thought experiment. Okay imagine that mortality is actually uh like a prerequisite for happiness. So if we become immortal will actually become deeply unhappy and the model is able to know that. So what is this supposed to tell you stupid human about it? Yes you can become immortal but you will become deeply unhappy if the model is if the A. G. I. System Is trying to empathize with you human, what is it supposed to tell you that? Yes you don't have to die but you're really not gonna like it is that is it going to be deeply honest? Like there's a interstellar, what is it the Ai says like humans want 90% honesty, so like you have to pick how honest I want to answer these practical questions.

Andrej  02:59:55
I love Interstellar by the way, I think it's like such a sidekick to the entire story but

Lex  03:00:01
at the

Andrej  03:00:02
same time it's like really interesting. It's kind

Lex  03:00:03
of limited in certain ways, right?

Andrej  03:00:05
Yeah it's limited and I think that's totally fine by the way, I don't think uh I think it's fine and plausible to have limited and imperfect A G. I. S.

Lex  03:00:15
Is that the feature almost as

Andrej  03:00:17
an example, like it has a fixed amount of compute on its physical body and it might just be that even though you can have a super amazing mega brain, super intelligent. Ai also can have like you know less intelligent ai so you can deploy in a power efficient way and then they're not perfect, they might make mistakes.

Lex  03:00:35
No I meant more like say you have infinite compute and it's still good to make mistakes sometimes. Like in order to integrate yourself? Like

Andrej  03:00:43
um what

Lex  03:00:45
is it going back to good Will hunting Robin Williams character says like the human imperfections, that's the good stuff, right? Isn't that isn't that like we don't want perfect, we want flaws in

Andrej  03:00:58
part

Lex  03:00:59
two to form connections with each other because it feels like something you can attach to your feelings too, the flaws in that same way you want ai that's flawed, I don't know, I feel like a perfectionist

Andrej  03:01:11
But then you're saying okay

Lex  03:01:13
but that's not a G I C A G. I would need to be intelligent enough to give answers to humans that humans don't understand. And I think perfect isn't something humans can't understand because even science doesn't give perfect answers. There's always gaps and mysteries and I don't know. I don't know if humans want perfect.

Andrej  03:01:33
Yeah. I can imagine just having a conversation with this kind of oracle entity as you'd imagine them. And yeah, maybe it can tell you about you know based on my analysis of human condition. Uh You might not want this and here's some of the things that might but

Lex  03:01:49
every every dumb human will say, yeah trust me I can give me the truth. I can handle it.

Andrej  03:01:55
But that's the beauty like people can choose. So But

Lex  03:01:58
then I think

Andrej  03:02:01
the

Lex  03:02:01
old marshmallow test with the kids and so on. I feel like too many people like I can't handle the truth. Probably including myself like the deep truth of the human condition. I don't I don't know if I can handle it. Like what if there's some dark, what if we are an alien science experiment and it realizes that what if it had I

Andrej  03:02:21
mean I mean this is the matrix. You know all over again.

Lex  03:02:26
I don't know I would what would I talk about? I don't even Yeah I

Andrej  03:02:32
probably I will

Lex  03:02:33
go with the safer scientific questions at first that have nothing to do with my own personal life immortality, just like about physics and so

Andrej  03:02:42
on.

Lex  03:02:43
Uh to build up like let's see where is that or maybe see if it has a sense of humor. That's another question. Would it be able to presumably in order to, if it understands humans deeply would be able to generate uh

Andrej  03:02:57
yeah, to

Lex  03:02:57
generate humor.

Andrej  03:02:58
Yeah, I think that's actually a wonderful benchmark almost. Like is it able, I think that's a really good point basically

Lex  03:03:04
to make you laugh

Andrej  03:03:06
if it's able to be like a very effective stand up comedian that is doing something very interesting computational e I think being funny is extremely hard.

Lex  03:03:12
Yeah,

Andrej  03:03:14
because

Lex  03:03:15
it's hard in a way like a touring test. The original intent of the touring test is hard because you have to convince humans and there's nothing that's why that's what comedians talk about this. Like there's this is deeply honest because if people can't help but laugh and if they don't laugh that means you're not funny, they laugh. That's funny

Andrej  03:03:36
and you're showing you need a lot of knowledge to create to create humor about like the occupation, human condition and so on. And then you need to be clever with it.

Lex  03:03:44
You mentioned a few movies, you tweeted movies that I've seen five plus times but I'm ready and willing to keep watching Interstellar Gladiator, contact good will hunting the Matrix Lord of the Rings all three avatar, fifth element So on it goes on to make

Andrej  03:04:00
it to

Lex  03:04:00
me and girls. I'm not gonna ask

Andrej  03:04:02
about

Lex  03:04:04
great

Andrej  03:04:05
um

Lex  03:04:07
what are some of the jump onto your memory that you love and why? Like you mentioned the Matrix as as a computer person. Why do you love the Matrix?

Andrej  03:04:18
There's so many properties that make it like beautiful interesting. So there's all these philosophical questions but then there's also a G. I. S and there's simulation and it's cool and there's you know the black you know

Lex  03:04:29
the look of it, the feel

Andrej  03:04:31
the feel of it, the action, the bullet time. It was just like innovating in so many ways

Lex  03:04:37
and then uh good will good will hunting. What do you like that one? Yeah

Andrej  03:04:41
I just I really like this uh tortured genius sort of character who's like grappling with whether or not he has like any responsibility or like what to do with this gift that he was given or like how to think about the whole thing and uh

Lex  03:04:55
there's also a dance between the genius and the the personal like what it means to love another human being and

Andrej  03:05:01
there's a lot of things there it's just a beautiful movie

Lex  03:05:03
and then the fatherly figure the mentor in the in the psychiatrist and it

Andrej  03:05:08
like really like uh it messes with you you know there's some movies that just like really messed with you uh on a deep level

Lex  03:05:14
do you relate to that movie at all?

Andrej  03:05:16
No

Lex  03:05:18
It's not your fault. As I said lord of the rings. That's self explanatory terminator two. Which is interesting. You? Re watch that a lot. Is that better than terminator 1? You like? You like I

Andrej  03:05:30
do like terminator one as well. Uh I like Terminator two a little bit more but in terms of like its surface properties

Lex  03:05:39
do you think china is at all a possibility?

Andrej  03:05:41
Yes.

Lex  03:05:43
Like the actual sort of autonomous weapons system kind of thing. Do you worry about that stuff

Andrej  03:05:51
being used

Lex  03:05:51
for war?

Andrej  03:05:53
100% worry about it. And so the I mean the you know some of these fears of A. Gs and how this will plan out. I mean this will be like very powerful entities probably at some point. And so um for a long time they're going to be tools in the hands of humans. You know people talk about like alignment of A. G. I. S. And how to make the problem is like even humans are not aligned. So how this will be used and what this is going to look like is um yes troubling. So

Lex  03:06:17
do you think it'll happen slow slowly enough that we'll be able to as a as a human civilization? Think through the problems

Andrej  03:06:25
yes that's my hope is that it happens slowly enough and an open enough way where a lot of people can see and participate in it. Just figure out how to deal with this transition I think, which is gonna be interesting. I

Lex  03:06:36
draw a lot of inspiration from nuclear weapons because I sure thought it would be would be fucked once they develop nuclear weapons. But like it's almost like uh when uh when the systems are not so dangerous, they destroy human civilization, we deploy them and learn the lessons and then we quickly, if it's too dangerous, we quickly quickly we might still deploy but very quickly learned not to use them. So they'll be like this balance achieved. Humans are very clever as a species. It's interesting we exploit the resources as much as we can, but we don't, we avoid destroying ourselves. It seems like,

Andrej  03:07:12
well, I don't know about that actually.

Lex  03:07:14
I hope it continues.

Andrej  03:07:15
Um

Lex  03:07:17
I

Andrej  03:07:17
mean I'm definitely concerned about nuclear weapons and so on, not just as a result of the recent conflict even before that, that's probably like my number one concern for humanity.

Lex  03:07:27
So if humanity destroys itself or destroys, you know, 90% of people, that would be because of nukes. I

Andrej  03:07:36
think so. Um it's not even about full destruction. To me, it's bad enough if we reset society that would be like terrible. It would be really bad. And I can't believe we're like so close to it.

Lex  03:07:47
It's like

Andrej  03:07:47
so crazy to me. It

Lex  03:07:48
feels like we might be a few tweets away from something like that. Yeah,

Andrej  03:07:52
basically it's extremely unnerving, but and has been for me for a long time

Lex  03:07:57
it seems unstable that world leaders just having a bad mood can like um take one step towards a bad direction and it escalates because of a collection of bad moods. It can escalate without being able to stop.

Andrej  03:08:18
Yeah. It's just it's a huge amount of power. And then also with the proliferation basically I don't I don't actually really see, I don't actually know what the good outcomes are here. So I'm definitely worried about it a lot. And then a gi is not currently there. But I think at some point will more and more

Lex  03:08:34
become something

Andrej  03:08:36
like it. The danger with A G. I even is that I think it's even like slightly worse in the sense that uh there are good outcomes of A. G. I. And then the bad outcomes are like an epsilon away like a tiny runway. And so I think um capitalism and humanity and so on will drive for the positive ways of using that technology. But then if bad outcomes are just like a tiny like flipping minus sign away. That's a really bad position to be in

Lex  03:09:01
a tiny perturbation of the system results in the destruction of the human species. It's a weird line to walk. Yeah.

Andrej  03:09:09
I think in general it's really weird about like the dynamics of humanity in this explosion we talked about is just like the insane coupling afforded by

Lex  03:09:15
technology and

Andrej  03:09:17
just the instability of the whole dynamical system. I think it just doesn't look good honestly.

Lex  03:09:22
Yes, that explosion could be destructive and constructive and the probabilities are non zero in both. I'm

Andrej  03:09:28
gonna have to I do feel like I have to try to be optimistic and so on. And I think even in this case I still am predominantly optimistic, but there's definitely

Lex  03:09:37
me too. Do you think will become a multi planetary species?

Andrej  03:09:42
Probably, yes, but I don't know if it's a dominant feature of uh future humanity. Uh there might be some people on some planets and so on, but I'm not sure if it's like, yeah, it's like a major player in our culture and so on. We

Lex  03:09:55
still have to solve the drivers of self destruction here on earth. So just having a backup on MArs is not going to solve the problem.

Andrej  03:10:03
So by the way, I love the backup on MArs, I think that's amazing. We should absolutely do that. And I'm so thank you.

Lex  03:10:09
Uh would you go to MARS

Andrej  03:10:12
personally? No, I do like Earth quite a lot. I'll

Lex  03:10:15
go to MArs I'll go for

Andrej  03:10:16
you. I'll

Lex  03:10:17
tweet at you from

Andrej  03:10:18
maybe eventually I would, once it's safe enough, but I don't actually know if it's on my lifetime scale unless I can extend it by a lot. I do think that for example, a lot of people might disappear into virtual realities and stuff like that and I think that could be the major thrust of um sort of the cultural development of humanity if it survives. So it might not be, it's just really hard to work in physical realm and go out there and I think ultimately all your experiences are in your brain and so it's much easier to to disappear into digital realm. And I think people will find them more compelling easier, safer, more interesting.

Lex  03:10:54
So you're a little bit captivated by virtual reality by the possible worlds, whether it's the metaverse or some other manifestation of

Andrej  03:11:00
that.

Lex  03:11:01
Yeah, it's really interesting. It's uh I'm interested just just talking a lot to Carmack where's the where's the thing that's currently preventing that?

Andrej  03:11:13
Yeah. I mean to be clear, I think what's interesting about the future is um it's not that I kind of feel like the variance in the human condition grows, that's the primary thing that's changing. It's not as much the mean of the distribution is like the variance of it. So there will probably be people on MArs and there will be people in VR and there are people here on Earth, it's just like there will be so many more ways of being. And so I kind of feel like I see it as like a spreading out of a human experience.

Lex  03:11:38
There's something about the internet that allows you to discover those little groups and they gravitate to something about your biology, likes that kind of world that you find each other

Andrej  03:11:46
and we'll have trans humanists and then we'll have the Amish and they're gonna, everything is just gonna coexist

Lex  03:11:51
the cool thing about it because I've interacted with a bunch of internet communities is um they don't know about each other. Like you can have a very happy existence just like having a very close knit community and not knowing about each other. Even you haven't sensed this just having traveled to Ukraine. There's, they don't know so many things about America you like when you travel across the world, I think you experienced this too. There are certain cultures, they're like they have their own thing going on. They don't and so you you can see that happening more and more and more and more in the future. We have little communities.

Andrej  03:12:25
Yeah. Yeah, I think so, that seems to be the, that seems to be how it's going right now and I don't see that trend like really reversing. I think people are diverse and they're able to choose their own path in existence. And I sort of like celebrate that. Um and so

Lex  03:12:39
we spend so much time in the metaverse in the virtual reality or which community are you, are you the physical ist the physical reality

Andrej  03:12:49
enjoy or or

Lex  03:12:51
do you see drawing a lot of pleasure and fulfillment in the digital world.

Andrej  03:12:57
Yeah, I think currently the virtual reality is not that compelling.

Lex  03:13:00
I do

Andrej  03:13:01
think it can improve a lot but I don't really know to what extent maybe you know, there's actually like even more exotic things you can think about like neural links or stuff like that. So um currently I kind of see myself as mostly a team human person. I love nature, I love harmony, I love people, I love humanity, I love emotions of humanity. Um and I just want to be like in this like solar punk little Utopia, that's my happy

Lex  03:13:27
place. My

Andrej  03:13:28
happy place is like people, I love thinking about cool problems surrounded by a lush, beautiful dynamic nature and secretly high tech in places that count

Lex  03:13:38
places that use technology to empower that love for other humans and nature. Yeah,

Andrej  03:13:44
I think the technology used very sparingly. I don't love when it sort of gets in the way of humanity in many ways. I like just people being humans in the way we sort of like slightly evolved and prefer I think just by default

Lex  03:13:56
people kept asking me because they know you love reading, are there particular books that you enjoyed that had an impact on you for silly or for profound reasons that you would recommend. You mentioned the vital question

Andrej  03:14:12
Many of course. I think in biology as an example. The vital question is a good one. Anything by Nick Lane really uh life ascending I would say is like a bit more potentially representative is like a summary of a lot of the things he's been talking about. I was very impacted by the selfish gene. I thought that was a really good book that helped me understand altruism as an example and where it comes from. And just realizing that, you know, the selection is on the level of jeans was a huge insight for me at the time and it's sort of like cleared up a lot of things for me.

Lex  03:14:40
What do you think about the the idea that ideas of the organisms

Andrej  03:14:45
Love It? 100%.

Lex  03:14:48
Yeah.

Andrej  03:14:49
Are you able to walk

Lex  03:14:50
around with that notion for a while that that there is an evolutionary kind of process with ideas as well?

Andrej  03:14:57
There absolutely is. There's memes just like jeans and they compete and they live in our brains. It's beautiful.

Lex  03:15:02
Are we silly humans thinking that we're the organisms? Is it possible that the primary organisms are the ideas? Yeah.

Andrej  03:15:11
I would say like the the idea is kind of live in the software of like our civilization in the in the minds and so on.

Lex  03:15:17
We think as humans that the hardware is the fundamental thing I human is a hardware entity. But it could be the software.

Andrej  03:15:26
Right? Yeah. Yeah. I would say like there needs to be some grounding at some point to like a physical reality. The

Lex  03:15:36
software is the thing. Like is this thing that makes that thing special? Right.

Andrej  03:15:41
Yeah. I guess you're right.

Lex  03:15:42
But then cloning might be exceptionally difficult. Like there might be a deep integration between the software and the hardware in ways we don't quite understand

Andrej  03:15:50
from the ocean point of view. Like what makes me special is more like the gang of genes that are writing in my chromosomes I suppose. Right. Like they're the replicating unit, I suppose. And

Lex  03:15:59
no, but that's just the thing that makes you special. Sure. Well, the reality is what makes you special is your ability to survive based on the software that runs on the hardware that was built by the genes.

Andrej  03:16:16
Um, so

Lex  03:16:17
the software is the thing that makes you survive, not the hardware. It's a

Andrej  03:16:21
little bit of both. You know, it's just like a second layer. It's a new second layer that hasn't been there before the brain. They both, they both co exist.

Lex  03:16:27
But there's also layers of the software. I mean it's, it's not, it's a so abstraction and uh, on top of abstractions,

Andrej  03:16:35
but so selfish gene um Nick Lane, I would say sometimes books are like not sufficient. I like to reach for textbooks sometimes. Um, I kind of feel like books are for too much of a general consumption sometime and they just kind of like they're too high up in the level of abstraction and it's not good enough. So I like textbooks. I like the cell. I think the cell was pretty cool. That's why also I like the writing of nick Lane is because he's pretty willing to step one level down and he doesn't,

Lex  03:17:06
uh, yeah, he's

Andrej  03:17:07
sort of he's willing to go there, but he's also willing to sort of be throughout the stack, so he'll go down to a lot of detail. But then he will come back up and I think he has a basically I really appreciate that. That's

Lex  03:17:18
why I love college, early college, even high school, just textbooks on the basics of computer science and mathematics, of biology and chemistry. Those are they condensed down like uh it's sufficiently general that you can understand both the philosophy and the details, but also like you get homework problems and you get to play with it as much as you would if you weren't Yeah, programming stuff. And

Andrej  03:17:43
then I'm also suspicious of textbooks honestly, because as an example in deep learning, there's no like amazing textbooks and the field is changing very quickly. I imagine the same is true. And say uh synthetic biology and so on. These books, like the cell are kind of outdated, there's still high level like what is the actual real source of truth is people in wet labs working with cells, you know, sequencing genomes and yeah, actually working with working with it and uh I don't have that much exposure to that or what that looks like. So I still don't fully, I'm reading through the cell and it's kind of interesting and I'm learning but it's still not sufficient, I would say in terms of understanding what

Lex  03:18:18
it's a clean summarization of the mainstream narrative. Yeah. But you have to learn that before you break

Andrej  03:18:25
out

Lex  03:18:26
towards the cutting edge.

Andrej  03:18:27
Yeah. What is the actual process of working with these cells and growing them and incubating them And you know, it's kind of like a massive cooking recipes of making sure yourself slaves and proliferate and then you're sequencing them running experiments and just how that works. I think it's kind of like the source of truth of at the end of the day what's really useful in terms of creating therapies and so on.

Lex  03:18:45
Yeah. I wonder what in the future ai textbooks will be because you know, there's an artificial intelligence, a modern approach actually haven't read if it's come out the recent version. The recent there's been a recent addition. I also saw there's a science of deep learning book. I'm waiting for textbooks that worth recommending worth reading.

Andrej  03:19:02
It's

Lex  03:19:03
tricky because it's like papers and code. Code code.

Andrej  03:19:07
Honestly I find papers are quite good especially like the appendix appendix of any paper as well. It's like it's like the most detail you can

Lex  03:19:14
have. It doesn't have to be cohesive connected to anything else. You just described a very specific way you saw the particular thing. Yeah.

Andrej  03:19:23
Many times papers can be actually quite readable. Not always but sometimes the introduction in the abstract is readable even for someone outside of the field not this is not always true. And sometimes I think unfortunately scientists use complex terms, even when it's not necessary. I think that's harmful? I think there's no reason for

Lex  03:19:39
that. And papers sometimes are longer than they need to be in the in the parts that don't matter. Yeah, appendix would be long. But then the paper itself, you know, look at Einstein, make it simple. Yeah,

Andrej  03:19:50
but certainly I've come across papers I would say and say like synthetic biology or something that I thought were quite readable for the abstract and introduction and then you're reading the rest of it and you don't fully understand, but you kind of are getting a gist and I think it's cool

Lex  03:20:01
what advice you give advice to folks interested in machine learning and research, but in general life, advice to a young person, high school, early college about how to have a career they can be proud of or a life they can be proud of.

Andrej  03:20:19
Yeah, I think I'm very hesitant to give general advice. I think it's really hard. I've mentioned, like some of the stuff I've mentioned is fairly general. I think like, focus on just the amount of work you're spending on like a thing, compare yourself only to yourself not

Lex  03:20:31
to others. I

Andrej  03:20:32
think those are fairly general.

Lex  03:20:33
How do you pick the thing,

Andrej  03:20:35
you just have like a deep interest in something uh or like try to like find the art max over, Like the things that you're interested in

Lex  03:20:42
art max at that moment and stick with it, how do you not get distracted and switch to another thing

Andrej  03:20:48
you can, if you like um

Lex  03:20:51
if you do an arg max repeatedly every week,

Andrej  03:20:54
doesn't converge,

Lex  03:20:55
doesn't you

Andrej  03:20:57
can like low pass filter yourself in terms of like what has consistently been true for you? Um But yeah, I definitely see how it can be hard, but I would say like you're going to work the hardest on the thing that you care about the most so low pass filter yourself and really introspect in your past, what are the things that give you energy and what are the things that take energy away from you? Concrete examples and usually from those concrete examples, sometimes parents can emerge, I like I like it when things look like this one of these positions, so

Lex  03:21:25
that's not necessarily the field, but the kind of stuff you're doing in a particular field. So for you, it seems like you were energized by implementing stuff, building actual things.

Andrej  03:21:34
Yeah. Being low level learning, and then also uh communicating so that others can go through the same realizations and shortening that gap um because I usually have to do way too much work to understand the thing and then I'm like, okay, this is actually like okay, I think I get it and like why was it so much

Lex  03:21:49
work,

Andrej  03:21:50
it should have been much less work and that gives me a lot of frustration and that's why I sometimes go teach.

Lex  03:21:55
So aside from the teaching you're doing now, putting out videos aside from a potential uh Godfather part two, uh would the A. G. I. At Tesla and beyond. What does the future of apathy hold? Have you figured that out yet or? No? I mean uh as you see through the fog of war, that is all of our future. Um do you, do you start seeing silhouettes of what that possible future could look like?

Andrej  03:22:24
The consistent thing I've been always interested in for me at least is is A. I. And um that's probably what I'm spending my rest of my life on because I just care about it a lot and I actually care about like many other problems as well, like say aging, which I basically view as disease and I care about that as well. But I don't think it's a good idea to go after it specifically. I don't actually think that humans will be able to come up with the answer. I think the correct thing to do is to ignore those problems and you solve AI and then use that to solve everything else. And I think there's a chance that this will work. I think it's a very high chance and uh that's kind of like the the way I'm betting at

Lex  03:23:01
least. So when you think about ai are you interested in all kinds of applications, all kinds of domains and any domain you focus on will allow you to get insights to. The big problem with a guy

Andrej  03:23:13
for me is the ultimate mental problem. I don't want to work on any one specific problem. There's too many problems. So how can you work on all problems simultaneously? You solve the meta problem, which to me is just intelligence and how do you automated

Lex  03:23:25
is their cool small projects like archive sanity and and so on that you're thinking about the the world, the ml world can anticipate.

Andrej  03:23:36
There's someone always like some fun side projects. Archive sanity is one basically like there's way too many archive papers. How can I organize it and recommend papers and so on. I transcribed all of your podcasts.

Lex  03:23:48
What did you learn from that experience? Uh from transcribing the process of like you like consuming audio books and podcasts and so on. And here's a process that achieves um closer to human level performance and annotation.

Andrej  03:24:02
Yeah, well I definitely was like surprised that transcription with opening eyes, Whisper was working so well compared to what I'm familiar with from Siri and like a few other systems, I guess it works so well. And uh that's what gave me some energy to like try it out. And I thought it could be fun to random podcasts. It's kind of not obvious to me why whisper is so much better compared to anything else because I feel like there should be a lot of incentive for a lot of companies to produce transcription systems and that they've done so over a long time. Whisper is not a super exotic model. It's a transformer, It takes mel spectrograms and you know, just outputs tokens of texts, not crazy uh model and everything has been around for a long time. I'm not 100% sure why.

Lex  03:24:43
It's not obvious to me either. It makes me feel like I'm missing something.

Andrej  03:24:48
Something. Yeah,

Lex  03:24:49
because there's a huge even google and so on youtube transcription. Yeah, it's unclear but some of it is also integrating into a bigger system that so the user interface, how is deployed and all that kind of stuff. Maybe running it as an independent thing is much easier, like an order of magnitude easier than deploying to a large integrated system like Youtube transcription or um anything like meetings like zoom has trans transcription that's kind of crappy. But creating interface where detects the different individual speakers, it's able to um display it in compelling ways running in real time, all that kind of stuff. Maybe that's difficult. But that's the only explanation I have because like um I'm currently paying quite a bit for human transcription, human captions annotation and like it seems like uh there's a huge incentive to automate that it's very confusing

Andrej  03:25:48
and I think, I mean I don't know if you look at some of the whisper transcripts but they're quite good. They're good,

Lex  03:25:53
especially in tricky cases. I've seen uh whispers performance on like super tricky cases and it does incredibly well. So I don't know, a podcast is pretty simple. It's like high quality audio and you're speaking usually pretty clearly. And so I don't know it uh I don't know what open they eyes plans are either,

Andrej  03:26:15
but there's always like fun, fun projects basically. And stable diffusion also is opening up a huge amount of experimentation, I would say in the visual realm and generating images and videos and movies. And so that's going to be pretty crazy. That's going to, that's going to almost certainly work. And it's going to be really interesting when the cost of content creation is going to fall to zero. Used to need a painter for a few months to paint a thing and now it's going to be speak to your phone to get your video.

Lex  03:26:43
Hollywood will start using that to generate scenes Um which completely opens up. Yeah. So you can make a like a movie like Avatar eventually for under $1 million, much

Andrej  03:26:56
less. Maybe just by talking to your phone? I mean I know it sounds kind of

Lex  03:26:59
crazy and then there'd be some voting mechanism like how do you have, like, would there be a show on netflix that's generated completely automated lee. So

Andrej  03:27:09
potentially. Yeah. And what does it look like? Also when you can generate on demand and it's uh and there's infinity of

Lex  03:27:17
it. Yeah. Oh man all the synthetic content. I mean it's humbling because we treat ourselves as special for being able to generate art and ideas and all that kind of stuff if that can be done in an automated way by Ai. Yeah.

Andrej  03:27:34
I think it's fascinating to me how these uh the predictions of Ai and what is going to look like and it's going to be capable of are completely inverted and wrong and sci fi of 50s and 60s was just like totally not right. They imagined a i is like super calculating here improvers and we're getting things that can talk to you about emotions. They can do art. It's just like weird.

Lex  03:27:53
Are you excited about that future? Just a eyes like hybrid systems, heterogeneous systems of humans. And Ai is talking about emotions. Netflix and Children ai system. That word. The netflix thing you watch is also generated by ai

Andrej  03:28:09
I think it's it's going to be interesting for sure. And I think I'm cautiously optimistic but it's not it's not obvious. Well

Lex  03:28:17
the sad thing is your brain and mine developed in a time where before twitter before the before the internet. So I wonder people that are born inside of it might have a different experience. Um Like I maybe you can will still resisted. Uh and the people born now will not.

Andrej  03:28:38
Well I do feel like humans are extremely malleable.

Lex  03:28:40
Yeah

Andrej  03:28:41
and

Lex  03:28:42
you're probably right. What is the meaning of life andre

Andrej  03:28:47
we we talked about sort

Lex  03:28:49
of the universe having a conversation with us humans or with the systems we create to try to answer for the university for the creator of the universe to notice us, we're trying to create systems that are allowed enough. Just answer back.

Andrej  03:29:07
I don't know if that's the meaning of life, that's like meaning of life for some people, the first level answer I would say is anyone can choose their own meaning of life because we are conscious entity and it's beautiful number one. But I do think that like a deeper meaning of life if someone is interested is along the lines of like what the hell is all this? And like why? And if you look at the into fundamental physics and quantum field theory and the standard model, they're like very complicated and There's this like you know, 19 free parameters, parameters of our universe and like what's going on with all this stuff and why is it here? And can I hack it, can I work with it? Is there a message for me? AM I supposed to create a message? And so I think there's some fundamental answers there but I think there's actually even like you can't actually really make dent in dose without more time. And so to me also there's a big question around just getting more time honestly. Yeah, that's kinda like what I think about quite a bit as well.

Lex  03:30:01
So kind of the ultimate or at least first way to sneak up to the why question is to try to escape. Uh, the system, the universe and then for that, you sort of backtrack and say, okay for that, that's gonna be take a very long time. So the white question boils down from an engineering perspective to how do we extend?

Andrej  03:30:24
Yeah, I think that's the question, number one, practically speaking, because you can't, you're not going to calculate the answer to the deeper questions in time you have and

Lex  03:30:32
that could be extending your own lifetime or extending just a lifetime of human civilization

Andrej  03:30:37
of whoever wants to. Not many people might not want that, but I think people who do want that, I think, I think it's probably possible. Uh, and I don't think, I don't know that people fully realize this. I kind of feel like people think of death as an inevitability, but at the end of the day, this is a physical system, Some things go wrong. Uh, it makes sense why things like this happen evolutionarily speaking. And there's most certainly interventions that mitigate it.

Lex  03:31:04
That would be interesting if death is eventually looked at as as a fascinating thing that used to happen to humans. I

Andrej  03:31:12
don't think it's unlikely. I think it's, I think it's likely

Lex  03:31:16
and it's up to our imagination to try to predict what the world without death looks like. It's hard to I think the values will completely change could

Andrej  03:31:28
be, I don't I don't really buy all these ideas that without that there's no meaning, there's nothing is I don't, intuitively by all those arguments. I think there's plenty of meaning, plenty of things to learn. They're interesting, exciting. I want to know, I want to calculate, I want to improve the condition of all the humans and organisms that are alive.

Lex  03:31:49
The way we find meaning might change. There is a lot of humans probably including myself that finds meaning in the finite nous of things, but that doesn't mean that's the only source of meaning.

Andrej  03:32:00
Yeah, I do think many people will will go with that, which I think is great. I love the idea that people can just choose their own adventure. Like you, you are born as a conscious free entity by default. I like to think and you have your inalienable rights for life

Lex  03:32:17
in the pursuit of happiness.

Andrej  03:32:18
I don't know

Lex  03:32:19
that in the nature of the landscape of happiness and

Andrej  03:32:23
you can choose your own adventure mostly. And that's not fully true, but

Lex  03:32:27
I still pretty sure I'm an NBC. But um and NBC can't know it's an NBC. There could be different degrees and levels of consciousness. I don't think there's a more beautiful way tended andre you're an incredible person. I'm really honored. You would talk with me everything you've done for the machine learning world for the ai world

Andrej  03:32:49
to

Lex  03:32:50
just inspire people to educate millions of people. It's been it's been great and I can't wait to see what you do next. It's been an honor, man. Thank you so much for talking today.

Andrej  03:32:58
Thank you.

Lex  03:32:59
     
Thanks for listening to this conversation with Andrej Karpathy. To support this podcast. Please check out our sponsors in the description and now let me leave you with some words from Samuel Karlin. The purpose of models is not to fit the data, but to sharpen the questions. Thanks for listening and hope to see you next time.