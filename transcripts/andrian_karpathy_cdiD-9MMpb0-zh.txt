Andrej 00:28:07
是的，我不知道终止的条件是什么，但肯定有一个趋势线的东西，我们是这个故事的一部分，就像它在哪里，它会去哪里？所以，你知道，我们经常被描述为ai的生物引导器，这是因为人类，我的意思是，你知道，我们是一个令人难以置信的生物系统，我们有能力进行计算，呃，你知道，和爱等等。但我们也是极其低效的。就像我们通过音频与对方交谈。说实话，我们在连续操作七个符号，这实在是有点令人尴尬。我们在使用声带。这一切都发生在像多秒的时间里。当你把频率降低到计算机操作或能够合作的频率时，这就有点尴尬了。因此，基本上看来，合成智能体确实有点像发展的下一个阶段，嗯，我不知道它导致了什么，比如在某些时候，我怀疑宇宙是某种谜。而这些合成的眼睛将揭开这个谜题并解决它。而且

我的意思是说，如果你是一个人，那么你就应该去找一个人，而不是去找一个人。
那么之后会发生什么，对吗？像什么？因为如果你把地球快进几十亿年，它就会变得很安静，然后就会变得很正常，你会看到城市灯光之类的东西。然后在最后会发生什么，就像它是像一个专业的还是像一个平静的是它的爆炸？它是否像

Andrej 00:29:29
地球？像打开一样

Lex 00:29:30
一个巨大的，因为你说排放焙烧炉将开始承认像一个巨大的数字一样的卫星？

Andrej 00:29:40
是的，这是某种疯狂的爆炸，我们生活在其中，就像我们正在经历一场爆炸，我们每天都在生活，看起来不像，但实际上，如果你我看到一个非常酷的地球和地球上的生命的动画，基本上在很长一段时间内没有发生什么。然后最后的两秒钟，就像基本上城市和所有的东西，在低轨道上就变得杂乱无章，整个事情发生在最后两秒钟，你就像这是爆炸性的声明爆炸。

Lex 00:30:05
是的，如果你以正常速度播放，它看起来就像一个爆炸。

Andrej 00:30:11
这是一个鞭炮声。我们生活在一个鞭炮声中

Lex 00:30:13
它将开始发射各种有趣的东西，然后爆炸并不是，它实际上可能看起来像一个小爆炸，有灯光、火焰和能量发射的所有这些东西。但是当你看到爆炸的细节时，就会有实际的复杂性发生，就像有人类的生命或某种生命一样

Andrej 00:30:35
我们希望这又是一个破坏性的鞭炮。这有点像一个建设性的鞭炮。好吧

Lex 00:30:41
因此，鉴于

Andrej 00:30:43
我认为是

Lex 00:30:43
好笑，它

Andrej 00:30:44
是一个非常有趣的思考，如宇宙的谜题是什么，宇宙的创造者。给我们一个信息。例如，在卡尔-萨根的《接触》一书中，有一条给人类的信息，即任何文明的数字。 在以11为基数的Pi的扩展中，这是种有趣的想法，也许我们应该给我们的创造者一个信息，也许我们应该以某种方式创造某种量子力学系统，提醒他们我们在这里的智能存在，因为如果你从他们的角度考虑，这只是说像量子场理论大规模像细胞自动机一样的东西。你怎么能注意到我们的存在呢？你甚至可能无法在那个模拟中发现我们。所以你如何证明你的存在，你的智慧和你是宇宙的一部分？所以

Lex 00:31:31
这就像一个来自地球的智力巡回测试。

Andrej 00:31:33
喜欢

Lex 00:31:34
创造者是呃，我的意思是也许这就像试图完成句子中的下一个单词。这是一种复杂的方式。就像地球只是基本上发送一个信息回来。

Andrej 00:31:44
是的，谜题基本上是提醒创造者我们的存在，或者也许谜题只是为了突破系统，只是你知道，以某种方式粘住创造者，基本上就像你在玩视频游戏，你可以嗯你可以以某种方式找到一个漏洞，找到一种方法在主机上执行任何任意的代码。有一些呃，例如，我相信有人得到了马里奥游戏的马里奥打乒乓球只是通过呃利用它，然后嗯创建呃基本上写写代码，并能够在游戏中执行任意代码。因此，也许我们应该，也许这就是难题所在，我们应该嗯找到一种方法来利用它。因此，我认为像这些合成广告的一些最终会发现宇宙是某种难题，然后以某种方式解决它。而这有点像最终的游戏，不知何故。

Lex 00:32:30
你是否经常把它想成是一个模拟？那么，作为宇宙的一种计算，它可能有错误和漏洞？

Andrej 00:32:41
是的，是的，我想是的。物理学

Lex 00:32:43
基本上是这样的、

Andrej 00:32:44
我认为物理学有可能存在漏洞，我们应该努力找到它们安排某种疯狂的量子力学系统，以某种方式让你的缓冲区溢出，以某种方式让你的浮点出现舍入错误。呃

Lex 00:32:57
是的，这是对的。还有像越来越复杂的漏洞。这些都是笑话，但这实际上可能是

Andrej 00:33:04
非常接近。我们会找到一些方法来提取无限的能量。例如，当你在物理模拟中训练强化学习代理嗯，你要求他们说在平地上快速奔跑，他们最终会做各种奇怪的事情。嗯，这也是优化的一部分，对吗？他们会用后腿，在地板上滑行，这是因为优化，嗯，该代理上的强制学习优化已经找出了一种方法，从摩擦力中提取无限的能量，嗯，基本上他们的执行力很差，他们找到了一种方法来产生无限的能量，只是在表面上滑动，这不是你所期望的。这只是一个它有点像一个反常的解决方案。因此，也许我们可以找到类似的东西。也许我们可以成为这个物理模拟中的那只小狗、

Lex 00:33:45
的裂缝，或者逃脱了宇宙想出的物理学的预期后果。我们会想出一些捷径来解决一些怪异的问题，然后但看到这个怪异的问题是第一个发现这个怪异的人，就像在后腿上滑动，这就是我们要做的。

Andrej 00:34:05
是的、

Lex 00:34:06
它非常快，因为每个人都在做那件事。因此，像回形针最大限度地提高呃是一个荒谬的想法，但这很可能是什么，然后我们将只是我们将只是所有切换，因为它是如此有趣。

Andrej 00:34:21
嗯，没有人会发现它。我认为，顺便说一句，我认为它必须是呃某种超级智能的第三代人工智能，就像我们正在建造的第一代人工智能一样，你知道、

Lex 00:34:33
第三代。是的，所以一个ai的引导程序将是另一个ai的引导程序。

Andrej 00:34:42
人

Lex 00:34:43
然后我们就没有办法反省了。就像什么可能，我

安德烈 00:34:47
我认为这些东西很有可能，比如说，你有这些G.I.S.，很有可能，比如说，它们会完全没有活力。我喜欢这类科幻书，有时这些东西就是完全惰性的。他们不与任何东西互动，我觉得这很好，因为他们可能他们可能以某种方式弄清了宇宙的元元游戏，可能他们他们正在做一些完全超出我们想象的事情。嗯，他们不与简单的化学生命形式互动，就像你为什么要那样做？所以我觉得这些想法很有说服力。

Lex 00:35:17
他们的乐趣来源是什么？他们是什么，他们在做什么

Andrej 00:35:20
在宇宙中解决？

Lex 00:35:22
但是惰性的。那么你能定义一下惰性的含义吗？所以他们逃避了互动、

Andrej 00:35:28
物理现实，因为嗯... ...他们会以一些非常类似于奇怪的方式来对待我们，因为他们是他们在玩元游戏之外。而这个元游戏可能是说像以一些非常奇怪的方式安排量子机械系统来提取无限的能量呃解决π的数字扩展到什么程度，他们将建立自己的像小聚变反应堆或一些疯狂的东西。就像他们在做一些我们无法理解的事情，而实际上在引擎盖下的辉煌。

Lex 00:36:00
如果量子力学本身就是这个系统呢？而我们只是认为它是物理学，但我们实际上是寄生虫，而不是寄生虫。我们并没有真正伤害到物理学。我们只是生活在这个有机体和这个有机体上，我们像是在试图理解它。但实际上它是一个有机体。有了深层次的智慧，也许物理学本身就是呃，是在做超级有趣的事情的有机体，而我们只是像一个小东西。

Andrej 00:36:32
是的

Lex 00:36:33
并坐在它上面试图从它那里获得能量。

Andrej 00:36:36
我们只是有点像波浪中的这些粒子，我觉得它主要是决定性的，把宇宙从某种大爆炸带到某种超级智能复制器，某种宇宙中的稳定点，鉴于这些物理规律，你

Lex 00:36:50
不要以为呃正如爱因斯坦所说的，上帝不玩骰子，所以你认为它主要是决定性的，没有随机性，而且事情

Andrej 00:36:57
我认为是确定性的，有成吨的，好吧，我想谨慎对待随机性、

Lex 00:37:01
伪随机。

Andrej 00:37:02
是的，我不喜欢随机。我想也许物理学规律是决定性的。嗯 是的，我认为它们是确定的

Lex 00:37:09
只是对这个问题感到非常不舒服。我你对宇宙是否是随机的感到焦虑吗？什么是有

Andrej 00:37:18
没有随机性

Lex 00:37:19
你喜欢吗？善意的狩猎，这不是你的错，Andrei

Andrej 00:37:23
它是

Lex 00:37:23
你的错，伙计。嗯，所以你你不喜欢随机性呃

Andrej 00:37:28
是的，我认为这是令人不安的，我认为这是一个决定性的系统。我认为那些看起来是随机的东西，比如说波函数的坍缩，诸如此类。我认为它们实际上是决定性的，只是纠缠等等，还有某种多元宇宙理论什么的。

Lex 00:37:43
好吧，那么为什么感觉我们有一个自由意志，比如如果如果我举起他的手，我选择现在这样做。嗯那感觉不像是一个决定性的东西，感觉像是我在做选择、

Andrej 00:37:58
感觉是这样的

Lex 00:37:59
好的，所以这都是感觉，只是感觉而已。因此，当RL代理做出选择时，嗯，它并没有真正做出选择，选择已经存在了。

Andrej 00:38:11
是的。你在解释这个选择，你在为做出这个选择而创造一种叙述。

Lex 00:38:15
是的。现在我们谈论的是叙事，这很重要。回顾一下，在深度学习或一般的AI中，你遇到的最漂亮或最令人惊讶的想法是什么，你已经看到这个领域的爆炸呃，以有趣的方式增长。只是什么什么很酷的想法，比如说我们让你坐立不安，大而无当。

Andrej 00:38:39
嗯，我最近想得最多的可能是

Lex 00:38:44
的

Andrej 00:38:44
变换器架构。基本上，神经网络有很多架构，这些架构在不同的感官模式下都很时髦，比如视觉、音频、文本，你会用不同的神经坚果来处理它们。而最近，我们看到这些趋向于一个架构，即变压器，你可以给它提供视频，或者你可以给它提供，你知道，图像或语音或文本，它只是吞噬它，它有点像一个通用计算机的位，也是可训练的，非常有效地运行在我们的硬件。因此，这篇论文是在20

Lex 00:39:18
16, I

Andrej 00:39:19
想说的是

Lex 00:39:20
注意力是你需要的全部

Andrej 00:39:21
注意力是你需要的一切，你

Lex 00:39:23
现在回过头来看，这篇论文的标题并不是......它并没有预见到它将产生的巨大影响。

Andrej 00:39:32
有。我不确定作者是否意识到那篇论文将继续产生的影响，可能没有，但我认为他们意识到变压器背后的一些动机和设计决定，他们选择不，我认为在论文中以这种方式扩展它。因此，我认为他们有一个想法，即有更多的嗯，而不仅仅是表面上的那样，哦，我们只是在做翻译，这里有一个更好的架构。你不只是在做翻译。这就像你提出的一个非常酷的可分化的乐观主义，高效的计算机，也许他们没有所有的预见性。但我认为这真的很有趣、

Lex 00:40:01
是不是很有趣，对不起，打断一下，那个标题让人记忆深刻，他们去了这么一个深刻的想法。他们用了我认为以前没有人用过的那种标题。对、

Andrej 00:40:12
注意力是你所需要的一切。这就像一个备忘录之类的东西。

Lex 00:40:15
这句话一点都不好笑。就像也许

Andrej 00:40:19
如果

Lex 00:40:20
它是一个更严肃的标题，没有影响。

Andrej 00:40:22
说实话，我是的，我有一个元素诚实地同意你的观点，并且更喜欢这种方式。

Lex 00:40:28
如果

Andrej 00:40:29
它是两千美元，它将过度承诺，并有可能提供不足。所以，你想用你的方式来实现伟大的目标。

Lex 00:40:36
这应该是一件T桖。所以你，你在推特上写了变压器，一个宏伟的神经网络架构，因为它是一个通用的差分计算机。它同时在前向传递中通过反向传播和梯度下降优化草本，并且高效。高并行性的计算图。你能讨论一下其中的一些细节吗，表现力。优化草本，高效，是的。从记忆或或一般来说，无论你想到什么

Andrej 00:41:03
心。你想拥有一台通用计算机，你可以在任意问题上进行训练，比如说下一个词的预测任务，或者检测图像中是否有一只猫或者类似的东西，你想训练这台计算机，所以你想设定它的权重。而且我认为有一些设计标准同时在变压器中有点重叠。这使得它非常成功。而且我认为作者是那种故意要使这个真正强大的架构，所以基本上它在向前的时候非常强大，因为它能够把嗯非常一般的计算表达为那种看起来像消息传递的东西，你有笔记，他们都存储向量，这些节点基本上得到看对方，这是对方的向量，他们得到沟通，基本上笔记，得到广播。嘿，我正在寻找先生，某些东西，然后其他节点得到广播。嘿，这些是我拥有的东西，这些是价值中的关键。

Lex 00:41:57
所以，这不仅仅是注意力。

Andrej 00:41:58
没错，变压器不仅仅是有很多件建筑的注意部件，它还包括很多件建筑。它的排列方式的剩余连接，有一个多层感知器和它的堆叠方式等等。但基本上有一个信息传递方案，节点互相查看，决定什么是有趣的，然后互相更新。所以我认为，当你了解到它的细节时，我认为它是一个非常有表现力的函数，所以它可以表达很多不同类型的算法和前向传递。不仅如此，它的设计方式与剩余连接。后来的归一化是softmax的注意和一切。它也是优化双这是一个真正的大问题，因为有很多计算机是强大的，你不能优化或他们不容易使用我们的技术来优化，这是反向传播成分发送。这些是一阶方法，非常简单的优化器，真的。因此，嗯，你也需要进行优化。草药。嗯，然后最后，你想在我们的硬件中有效运行。我们的硬件是一个巨大的吞吐量的机器，像gps，他们喜欢大量的并行性。

所以你不想做大量的顺序操作。你想做很多串行的操作。变换器的设计也是考虑到这一点的。因此，它是为我们的硬件而设计的，在前向传递中具有很强的表现力，在后向传递中也有很好的优化能力。

Lex 00:43:09
你说，呃，残余连接支持一种快速学习短期算法的能力，首先，然后逐渐扩展呃，在训练过程中更长。是的。学习短算法的想法是什么？

Andrej 00:43:23
对。把它想成 所以基本上一个变压器是一系列的块，对吗？而这些区块有注意力和一个小的多层知觉。所以你你进入一个区块，然后你回到这个残余的路径，然后你去了，你回来了，然后你有一些层的顺序排列。因此，我认为看待它的方式是，由于在后向通道中的剩余通路，梯度沿着它不间断地流动，因为加法将梯度平均分配给它的所有分支。因此，来自顶层监督的梯度直接漂浮到第一层，所有的残余连接都被安排好了，所以在初始化的时候，它们对残余通路没有任何贡献。嗯，所以它看起来就像想象中的转化器是一种像python函数一样的死亡。嗯，你可以做各种类似于代码的行。嗯，所以你有100层深的转化器，通常它们会短得多，比如说20，所以20行代码，你可以在其中做一些事情。所以想想在优化过程中，基本上它看起来是首先你优化第一行代码，然后第二行代码可以启动，第三行代码可以启动，我有点觉得因为残余的途径和优化的动态性、你可以学习一个非常短的算法，得到近似的答案，但然后其他层可以排序，并开始创造一个贡献，在它的最后，你是你在优化一个算法，这是20行代码 除了这些行的代码是非常复杂的，因为它是一个变压器的整个块。你可以在里面做很多事情。真正有趣的是，这个转化器架构实际上已经有了显著的弹性，基本上是一个在2016年出现的转化器，就像你今天会使用的转化器一样，除了你从层规范中重新洗牌，规范化已经被重新洗牌到一个前规范嗯制定，所以它已经非常稳定，但有很多钟声和口哨，人们已经附加在它上面，并试图改善它。

我确实认为，基本上这是一个，这是一个大的步骤，同时优化一个理想的神经网络架构的许多属性，我认为人们一直试图改变它，但它被证明是非常有弹性的。但我确实认为应该有更好的架构是有可能的、

Lex 00:45:25
但这是你的，你钦佩这里的弹性，这个架构有一些深刻的东西，至少也许我们可以把一切都变成一个呃，变成一个变压器可以解决的问题。

安德烈 00:45:38
目前看起来就像变形金刚接管了人工智能，你基本上可以把任意的问题输入它，它是一个通用的可微分计算机，它非常强大，呃，人工智能的这种融合对我个人来说真的很有趣。

Lex 00:45:53
你认为在这里还能发现什么关于变压器的东西？比如什么令人惊讶的事情，或者是一个稳定的我在一个稳定的地方，是否有一些我们可能会发现的关于变压器的有趣的东西，比如 "哈 "的时刻，也许与记忆有关，也许与知识表示有关，这些东西

安德烈 00:46:11
当然，今天的潮流只是在推动，就像现在的人基本上是不碰变压器，碰其他的东西。因此，人们正在扩大数据集，使其大得多，他们正在研究评估，使评估大得多，呃......他们基本上保持架构不变，这就是我们过去五年在AI方面的进展。

Lex 00:46:33
你对其中的一种味道怎么看？那就是语言模型？你是否感到惊讶？你的想象力是否被你提到的D.P.T.和所有越来越大的语言模型所吸引，你认为这些模型的极限是什么？因此，只是为了自然语言的任务、

Andrej 00:46:59
基本上，GPT的训练方式，对，就是你从互联网上下载大量的文本数据，然后你试图预测序列中的下一个词，大致上，你预测的是一个小词块，但大致上，就是这样。嗯，而真正有趣的是，基本上它是一个语言模型。语言模型实际上已经存在了很长时间了。嗯，有关于语言模型的论文从2003年甚至更早。可以

Lex 00:47:23
你解释一下这个案例，什么是语言模型？

Andrej 00:47:26
是的，所以语言模型，基本上就是预测一个序列中的下一个词，大致上是这样。例如，2003年，Benji Oh和他的团队发表了一篇论文，他们首次使用神经网络来预测三到五个单词，并预测下一个单词。而且他们是在更小的数据集上做的。神经网络不是一个变压器，它是一个多层感知器，但这是第一次在这种情况下应用神经网络。但即使在神经网络之前，语言模型也是如此，只不过他们使用的是N克模型。所以N克模型只是基于计数的模型。因此，如果你试图用两个词来预测第三个词，你只需计算你见过的任何两个词的组合的次数，接下来是什么，你预测接下来是什么，只是你在训练集中见过的最多的词。因此，语言建模已经存在了很长时间，神经网络已经做了很长时间的语言建模。因此，真正的新的或有趣的或令人兴奋的是意识到，当你用足够强大的神经网络转化器来扩大它的规模时，你会有所有这些突发属性。基本上发生的情况是，如果你有一个足够大的文本数据集，你在预测下一个词的任务中，你正在多任务处理大量不同种类的问题，你正在多任务处理对化学、物理、人性的理解，很多事情都集中在这个目标上。这是一个非常简单的目标，但实际上你必须了解很多关于这个世界的事情才能做出预测。

Lex 00:48:59
你刚才说的是u字理解。你是在化学和物理学等方面。你觉得它在做什么，是在寻找正确的背景，呃，在什么，它是什么，这里发生的实际过程是什么？是的。

安德烈 00:49:16
所以基本上它得到了1000个词，并试图预测第1001个，为了在互联网上可用的整个数据集上非常、非常好地做到这一点，你实际上必须基本上了解那里发生的事情的背景。这是一个足够难的问题，如果你有一个足够强大的计算机，就像一个变压器，你最终会得到有趣的解决方案，你可以要求它做各种各样的事情，它显示了很多像上下文学习那样的突发特性。这就是GPT和他们发表的原始论文的主要内容，就是你可以以各种方式提示它，要求它做各种事情，它就会完成这个句子。但在完成句子的过程中，它实际上是在解决我们所关心的各种真正有趣的问题。做

Lex 00:50:05
你认为它在做类似于理解的事情，就像我们用理解这个词来形容我们人类一样？

Andrej 00:50:13
我认为它在做一些理解它的权重，它理解我认为很多关于世界的东西，它必须这样做，以便预测一个序列中的下一个词。

Lex 00:50:22
所以它是在互联网上的数据上训练的。你对这种使用互联网上的数据集的方法有什么看法。你认为互联网有足够的结构化数据来教授ai关于人类文明的知识吗？

Andrej 00:50:37
是的，我认为互联网是一个巨大的数据量。我不确定它是否是一个足够完整的集合。我不知道文本对于拥有足够强大的A.G.I有什么结果。嗯

Lex 00:50:48
当然，有音频、视频和图像以及所有这些东西。

Andrej 00:50:51
是的。所以，文本本身。我对这一点有点怀疑。有一大堆东西我们不写在文字里，只是因为它们对我们来说是显而易见的，关于世界是如何在物理学上运作的，以及事物是如何坠落的，我们不把那些东西写在文字里，因为你为什么要我们分享这种理解？因此，人类之间的税收沟通媒介，它不是一个关于世界知识的全面的媒介。但正如你所指出的，我们确实有视频，有图像，有音频。所以我认为这肯定有很大的帮助，但我们还没有充分地训练模型，跨越所有这些模式。所以我想这就是很多人感兴趣的地方、

Lex 00:51:24
但我想知道那种共同的理解，比如，我们可能称之为常识的东西，必须通过学习推断才能正确地完成这个句子。因此，也许它在互联网上被暗示的事实，模型将不得不学习，而不是通过阅读它，通过推断的表示。所以，就像，常识，就像我们我不认为我们学会了常识，就像没有人说明确地告诉我们，我们只是通过与之互动来弄清楚这一切

Andrej 00:51:56
世界。

Lex 00:51:57
因此，这里有一个关于人们与世界互动方式的阅读模式，可能要推断出，我想知道

Andrej 00:52:03
是的、

Lex 00:52:04
你曾在一个叫比特世界的项目上工作过，训练RL系统在互联网上采取行动，而不仅仅是消费互联网，就像我们谈到的那样，你认为这种与互联网互动的系统是否有前途，以帮助学习？

Andrej 00:52:20
是的，我认为这可能是很多这些模型的最终前沿，因为嗯，所以正如你所提到的，有一个开端，我正在研究这个项目的比特世界，基本上它是让神经网络访问键盘和鼠标的想法。

Lex 00:52:34
可能会出错。

Andrej 00:52:37
因此，基本上你你感知到呃屏幕像素的输入，基本上计算机的状态在网络浏览器的图像和类似的东西中被可视化，供人消费。然后你给他们按键盘和使用鼠标的能力，我们正试图让它完成预订，你知道的，与用户界面互动，还有什么？

Lex 00:52:59
你从那次经历中学到了什么吗？比如有什么好玩的东西？有一个超级酷的想法。我的意思是，我的意思是，从观察者到演员之间的步骤是一个超级迷人的。

Andrej 00:53:12
步。好吧，我想说，数字领域的通用接口。在物理领域也有一个通用的界面，在我看来是一个人形的东西。我们稍后可以讨论Optus等等，但我觉得它们在某种程度上是一种类似的哲学，人类的世界，物理世界是为人类的形式设计的，数字世界是为人类的形式设计的，即看到屏幕和使用关键字、键盘和鼠标。因此，通用接口基本上可以指挥我们为自己建立的数字基础设施。因此，它感觉是一个非常强大的界面，可以指挥和建立在你的问题之上，就像我从那里学到的东西。这很有趣，因为比特的世界基本上是太早了，我想在开放ai的时候，嗯这是在2015年左右，当时的时代潮流在ai方面与今天的时代潮流非常不同，当时每个人都对强化学习从头开始感到超级兴奋。这是雅达利论文的时代，神经网络在玩雅达利游戏嗯，在某些情况下击败了人类呃Alphago等等。所以每个人都对使用强化学习从头开始训练神经网络感到非常兴奋。结果发现，强化学习是训练神经网络的极其低效的方法，因为你要做所有这些动作和所有这些观察，而你偶尔会得到一些稀疏的奖励。所以你根据所有这些输入做所有这些事情，偶尔你会被告知你做了一件好事情，你做了一件坏事情。这只是一个极其困难的问题。

你不能从中学到什么，你可以烧毁森林，你可以用蛮力穿过它。我们看到，我认为在围棋和Dota等方面确实有效，但这是非常低效的，而且从实际情况来看，这不是你想要的解决问题的方法。因此，当时我们也采取了比特世界的方法，我们会有一个随机初始化的代理。所以用键盘敲打和鼠标敲打，并试图进行预订。这就像很快揭示了这种方法的疯狂之处，你必须通过正确的预订来获得奖励，因为你做的是正确的，而你永远不会通过随机的机会绊倒它。所以

Lex 00:55:19
即使有一个简单的网络界面，也有太多的选项、

Andrej 00:55:21
有太多的选择，呃，呃，它的奖励信号太稀少了，你当时是从头开始的。因此，你不知道如何阅读，你不理解图片、图像、按钮，你不理解它意味着什么，比如进行预订，但现在发生的事情是，呃，是时候重新审视这个问题了，并且开放，我对这个感兴趣。呃，像Adept这样的公司对这个感兴趣，等等，呃，这个想法又回来了，因为这个界面非常强大，但是现在你不是从头开始训练一个代理，你是把GPT作为初始化。因此，GPT在所有的文本上进行了预训练，它理解什么是预订，它理解什么是提交，它理解嗯，还有更多，所以它已经有了这些表征，它们非常强大，这使得所有的训练明显更有效率，嗯，并使问题可操作。

Lex 00:56:06
应该用人类看到的方式与按钮和语言进行交互，还是应该用html、javascript和CSS进行交互，你认为什么比较好？那么

Andrej 00:56:17
今天，所有这些互动主要是在html CSS等层面。这样做是因为计算上的限制。呃，但我认为最终，嗯，所有的东西都是为人类的视觉消费而设计的，所以在一天结束时，所有的额外信息都在网页的布局中，什么在你旁边，什么是红色背景，所有这些东西，以及它在视觉上看起来是什么。因此，我认为这是最后的前沿是我们正在接受像素，我们正在发出键盘鼠标命令，但我认为这是不现实的，仍然是今天、

Lex 00:56:45
你是否担心互联网上的机器人，鉴于这些想法，鉴于它们是多么令人兴奋。你是否担心微博上的机器人不是我们现在看到的那些愚蠢的机器人，而是那些可能存在的机器人，实际上我们没有看到它们在以有趣的方式进行互动。因此，这种系统感觉应该能够通过 "我不是机器人 "点击按钮什么的嗯，你实际上明白测试是如何进行的。我不太喜欢有一个有一个复选框或什么，你点击，它大概是跟踪像鼠标运动和时间等等。所以正是我们所讨论的这种系统应该能够通过。所以，是的，你觉得怎么样？呃......机器人是语言模型，加上有一些互动能力，能够发推特和回复等等。你担心那个世界吗？

Andrej 00:57:40
是的，我认为它一直都是攻击和防御之间的一种军备竞赛。因此，攻击会变得更强，但防御也会变得更强，我们检测的能力也会更强。如何

Lex 00:57:50
你会防守吗？你如何检测？你怎么知道你在微博上的账号是人？

Andrej 00:57:58
如何

Lex 00:57:58
你有没有接近过这个？如果人们会声称你知道... ...你会如何在法庭上为自己辩护，我是一个人？

Andrej 00:58:07
嗯

Lex 00:58:08
这个账户在一些

Andrej 00:58:09
我认为，呃，这可能是我认为社会社会会有一点演变，比如我们可能会开始在我们的一些信件或你知道我们现在创造的东西上进行数字签名。这不是必须的，但也许在未来它可能是，我确实认为我们正在走向我们分享的世界，我们用眼睛分享数字空间、

Lex 00:58:29
合成生物。

Andrej 00:58:30
是的。而且他们会变得更好，他们会分享我们的数字领域，他们最终也会分享我们的物理领域。这就更难了。但这有点像我们正在走向的世界，它们中的大多数将是良性的和有希望的，其中一些将是恶意的，这将是一场试图检测它们的军备竞赛。

Lex 00:58:45
所以我的意思是，最糟糕的不是ai，最糟糕的是Ai在假装成人类。所以我不知道它是否总是恶意的。显然有很多恶意的应用，但它也可能是，你知道，如果我是一个AI，我会非常努力地假装成人类，因为我们是在一个人类的世界。作为一个AI，我不会得到任何尊重，我希望得到一些爱和尊重。

Andrej 00:59:10
我不认为这个问题是难以解决的。人们都在考虑人格证明的问题，呃，我们可能会开始对我们的东西进行数字签名，我们最终可能都会像呃，是的，基本上是一些关于人格证明的解决方案。这似乎并不是难以解决的问题。这只是我们到现在为止还没有做过的事情。但我认为，一旦这种需求开始出现，也就是很快。我认为人们会更多地考虑这个问题

Lex 00:59:32
所以，但这也将是一场比赛，因为很明显，你可能会呃恶搞或伪造人格证明。所以你必须尝试找出如何

Andrej 00:59:45
大概是这样。I

Lex 00:59:47
这很奇怪，我们有社会安全号码和护照之类的东西。在物理空间和视觉空间中，似乎更难伪造东西。它只是感觉它将会是非常

Andrej 01:00:00
棘手，非常

Lex 01:00:01
棘手的问题，因为它似乎是相当低价的假东西。你要把一个AI送进监狱，因为他试图使用一个假的假的人格证明？我的意思是，好吧，你把很多人关进监狱，但会有更多的人，因为我们的像指数级的，创建机器人的成本是非常低。除非有某种方法可以准确追踪。就像你不允许创建任何程序，而不显示呃将自己与该程序绑在一起。就像任何在互联网上运行的程序，你将能够呃追踪每一个参与其中的人类程序。

Andrej 01:00:44
节目。是的。也许你必须开始宣布，当呃你知道，我们必须开始画出这些边界，并跟踪好，什么是数字实体与人类实体，呃什么是人类实体和数字实体的所有权，呃类似的东西。我不知道，但我认为我很乐观，这是有可能的，在某种意义上，我们目前正处于最糟糕的时期，因为所有这些机器人突然变得非常有能力，但我们还没有建立起社会的防御措施，但我认为这似乎并不难解决。这只是我们必须要处理的事情。

Lex 01:01:21
叽叽喳喳，但像真正蹩脚的叽叽喳喳的机器人如此之多，这似乎很奇怪。是这样吗？所以我推测twitter的工程师们都很厉害。所以，我从这一点上推断，呃，如果他们可能抓得很好，这似乎是一个很难的问题。如果我是那种钢铁侠的情况。这是一个困难的问题，而且对于呃假阳性来说，删除一个不相关的人的帖子是一个巨大的成本，这创造了一个非常糟糕的用户体验。所以他们对删除非常谨慎。因此，也许是嗯，也许老板真的很擅长学习什么被删除，什么没有被删除，这样他们就可以很快地在删除过程中保持领先。我的

Andrej 01:02:10
说实话，对它的印象是有很多的憧憬。我的意思是、

Lex 01:02:14
是的，我就是这么想的

Andrej 01:02:15
我对它的印象并不微妙。并非如此，而是

Lex 01:02:19
你有，是的，这也是我的印象，但感觉也许你看到的是冰山一角，也许箱子的数量和像万亿，你必须像只是，这是一个不断攻击的机器人，是的，我不知道嗯，你必须在案件中偷，因为机器人，我看到一个相当像明显的我可以写几行代码来捕捉这些机器人。

Andrej 01:02:44
我的意思是，肯定有很多低垂的果实，但我要说的是，我同意如果你是一个成熟的演员，你可能会创造一个相当好的，但现在，嗯，你知道使用像G. P. T. S这样的工具，因为它是一个语言模型，你可以生成现在看起来相当好的脸，呃，你可以在规模上做这个，所以我认为嗯，这是相当可能的，这将是很难辩护的。

Lex 01:03:05
有一个google工程师声称lambda在本质上是，你认为他的感受有任何一丝真实性吗？而且至少对我来说更重要的是，你认为语言模型会很快实现智人或智人的幻觉吗？伊什。是的。

Andrej 01:03:25
对我来说，这是一个有点像煤矿中的金丝雀一样的时刻。说实话，有一点是因为，这位工程师与谷歌的聊天机器人进行了交谈，并相信了

Lex 01:03:38
问了一些存在性的哲学问题

安德烈 01:03:41
而且它给出了合理的答案，看起来很真实，呃，等等，所以对我来说，他是他是他是他没有充分地试图强调这个系统，我认为和揭露它的真相，因为它是今天的。但我认为随着时间的推移，这将是越来越难。所以，呃，是的，我认为越来越多的人基本上会成为嗯，是的，我认为越来越多的人，随着时间的推移，会有更多这样的人，因为这变得更好，像

Lex 01:04:13
形成完美的情感连接

Andrej 01:04:16
在我看来是合理的。我认为这些人其实很擅长人类的人际关系。人类的情感。互联网上有一大堆文字是关于人类和连接以及爱等等。因此，我认为他们在某种意义上非常了解人们如何相互谈论这个问题，而且他们非常有能力创造出很多这样的文本。有很多像五十年代和六十年代的科幻作品，以一种非常不同的方式来想象艾。他们是计算的冷酷的瓦肯人一样的机器，这不是我们今天得到的东西。我们得到的是相当情绪化的AI，它们实际上非常有能力，能够生成，你知道，关于所有这些主题的可能的声音文本。

Lex 01:04:57
我对AI系统充满希望，它们就像伙伴一样，帮助你成长，发展成为一个人，帮助你最大化长期幸福。但我也非常担心ai系统从互联网上发现，人类会被戏剧吸引，所以这将只是像说大话的眼睛，他们只是不断地做你听到的，就像他们会做八卦，他们会做他们会尝试种植怀疑其他人类的种子，你爱和信任，只是有点捣乱的人。呃，你知道，因为这将会得到很多人的关注，在最大化参与的道路上，戏剧性的最大化。而我们人类将被送入那台机器，并得到它将是一个巨大的戏剧性的狗屎风暴。呃，所以我很担心这一点。所以它的目标函数真正定义了人类文明进步的方式，眼睛在

Andrej 01:05:52
它。我认为现在至少今天他们不是那种......把他们真正看作是想做什么事情的目标追求者是不正确的。他们没有长期的记忆或任何东西。从字面上看，它的一个很好的近似值是你得到1000个词，你试图预测1000个，首先，然后你继续喂它，你可以自由地以任何你想要的方式提示它。所以在文本中，所以你说，好吧，你是一个心理学家，你非常好，你喜欢人类，这里有一个你和另一个人类的对话，你的东西，然后它只是继续这个模式，突然你和假的心理学家进行了对话，他试图帮助你。因此，它仍然有点像一个工具的香气，是一个人可以以任意的方式提示，它可以创造非常令人难以置信的文本，但它没有长期的目标，在很长一段时间内，它没有尝试呃，所以它现在看起来不是这样的

Lex 01:06:44
但你可以做短期的目标，有长期的效果。所以，如果我的提示，短期目标是让安德鲁的能力在twitter上回应我，当我喜欢我想一个我可能那是目标，但它可能会弄清楚，说话运到你。这将是最好的在一个高度复杂的有趣的方式，然后你建立了一个关系，当你被回应一次，然后它像随着时间的推移，它得到不复杂，只是像只是谈论狗屎和

Andrej 01:07:20
好的

Lex 01:07:21
也许你不会去找安德烈，但它可能会去找另一个名人，可能会去找其他大的账户，然后它就会用这个简单的目标让他们回应，以最大限度地提高实际回应的概率。

Andrej 01:07:34
是的，我的意思是，你可以用他们对如何做任何你感兴趣的事情的意见来提示这样一个强大的模型。因此，他们将成为这些神谕，我可以这样认为，他们就是这样。目前的神谕只是文本，但他们将有计算器，他们将有机会使用谷歌搜索，他们将有各种小工具和小玩意儿，他们将能够操作互联网并找到不同的信息，是的，在某种意义上，这有点像目前它的发展情况、

Lex 01:08:04
你认为它最终会比谷歌在获取人类知识方面有什么改进吗？

Andrej 01:08:14
我认为今天在建立一个更好的搜索引擎方面有一定的空间，我认为谷歌，他们有所有的工具，所有的人，他们有，他们需要的一切，所有的拼图，他们有大规模的训练改造者的人，他们有所有的数据。呃，他们现在是否有能力作为一个组织对他们的搜索引擎进行创新并不明显，如果他们不这样做，其他人会这样做，在这些工具的基础上建立一个明显更好的搜索引擎有绝对的空间。

Lex 01:08:37
这很有意思。一个大公司的搜索，已经有了一个基础设施，它的运作带来了大量的资金，所以在公司内部结构上，他们的动机是转向说我们要建立一个新的搜索引擎。

Andrej 01:08:51
是的，这很难。

Lex 01:08:53
所以它通常会来自于一个初创公司、

Andrej 01:08:55
对吗？那是嗯，那会是的，或者其他一些更有能力的组织。嗯，所以，呃，我不知道，所以目前，比如说，也许正在有另一个机会，你知道、

Lex 01:09:07
走吧，微软、

Andrej 01:09:09
我们正在谈论

Lex 01:09:10
离线嗯，我

安德烈 01:09:12
我的意思是，我肯定这是非常有趣的，因为搜索引擎曾经是关于，好吧，这里是一些查询，这里是，这里是这里的网页，看起来像你的东西，但你可以直接去回答，然后有支持证据。嗯，这些呃这些模型基本上他们已经阅读了所有的文字，他们阅读了所有的网页，所以有时当你看到自己去搜索结果，有点像得到像你感兴趣的任何东西的平均答案的感觉，就直接出来了，你不需要做这些工作。所以他们有点像 呃 是的，我认为他们有一种方法来提炼所有这些知识

吕志强 01:09:47
变成像

Andrej 01:09:49
基本上有一定程度的洞察力。

Lex 01:09:50
你是否认为提示是一种教与学的方式，就像这整个过程中的另一层，你知道，因为也许这就是人类已经有了那个背景模型，你是世界在提示你？

Andrej 01:10:06
是的，没错。我认为我们现在对这些计算机进行编程的方式，如GPS正在向你对人类进行编程的方式靠拢。我的意思是我如何通过提示来为人类编程？我去找人，提示他们做事情。我从信息中提示他们。因此，自然语言提示是我们为人类编程的方式，我们开始直接在这个界面上为计算机编程，说实话，这很了不起。

Lex 01:10:27
所以，你已经说了很多关于软件2.0的想法，嗯，所有好的想法都会变得像陈词滥调一样迅速，就像我认为阿姆曾经说过的那样，如果他被歌曲烦扰，他写得非常快，这意味着它会成为一个大热门，因为它太好听了。但你能描述一下这个想法，以及你对它的思考是如何在几个月和几年后演变的，自从你创造了它？

Andrej 01:10:59
是的。是的。我有一篇关于软件2.0的帖子，我想是几年前的事了。我写那篇帖子的原因是，我一直看到在软件开发方面发生了一些了不起的事情，以及很多代码是如何被过渡到编写的，不是用那种像C加加之类的，而是用神经网络的权重来编写。基本上只是说，神经网络正在接管软件，软件的领域和嗯采取更多更多的任务。而在当时，我认为没有多少人深刻理解这一点，这是一个大问题。这是一个很大的转变，呃，神经网络被视为多种分类算法中的一种，你可能会用它来解决牛身上的数据集问题。这并不是说这是我们对计算机编程方式的改变，我认为神经网络将接管我们对计算机编程的方式，它将改变的不是人们用C加加或类似的东西编写软件，而是直接对软件进行编程、它将会积累训练集和数据集，并制定这些目标，我们通过这些目标来训练这些神经网络，在某些时候，会有一个从数据集、目标和架构规范到二进制的编译过程，这实际上只是呃神经螺母，你知道，权重和神经螺母的前进路径。然后你就可以部署这个二进制文件了。因此，我正在谈论这种过渡，呃，这就是这个帖子的内容。我看到这种情况在很多领域都有发生，呃，你知道，是其中之一，但也只是一个简单的图像分类。人们最初认为，你知道，在80年代，等等，他们会写出检测图像中狗的算法。

他们有所有这些关于大脑如何做的想法。首先我们检测角，然后检测线，然后我们把它们缝起来，他们就像真的在做这件事。他们想的是如何编写算法，而这不是你构建算法的方式。嗯，有一个平稳的过渡，首先我们认为我们要建立一切。然后我们就开始构建功能。因此，像猪的特征和类似的东西，从图像斑块中检测这些小的统计模式，然后在它上面有一点学习，如支持向量机或二进制分类器，用于猫与狗和图像的特征之上。所以我们写了特征，但我们训练了最后一层的分类器。然后人们就想，其实我们甚至不要设计特征，因为说实话，我们并不擅长这个。所以让我们也来学习特征。然后你最终得到的基本上是一个卷积神经网络，你正在学习它的大部分，你只是指定了架构，架构有大量的填空，这是所有的旋钮，你让优化对吗？大部分都是这样。因此，这种过渡正在整个行业中到处发生。

呃，突然间我们就有了一大堆用神经网络权重写的代码。我只是想指出，这个比喻实际上是很有力的。我们有很多软件的开发者环境，比如我们有I.D.S.嗯，你如何处理代码？你如何调试代码。你如何你如何运行代码？如何维护代码？我们有Git中心。所以我试图在新的领域里做这些类比，比如什么是Git hub？软件2.0，原来是现在看起来像抱脸的东西。

Lex 01:14:05
呃、

安德烈 01:14:06
你知道，所以我认为有些人认真对待它，并建立了很酷的公司，呃，许多人最初攻击了这个帖子。实际上，当我写这篇文章时，它并不被人看好，我想也许这与标题有关，但这篇文章并不被人看好，我想随着时间的推移，更多的人已经开始接受它。

Lex 01:14:22
是的，所以你是特斯拉的Ai主管，在那里我认为这个想法真正实现了一个规模，即你如何让工程团队做软件2点哦，所以你可以在这个想法上逗留一下，我认为我们处于你刚才所说的一切的真正早期阶段，这就像获得枢纽I.D.S.一样，我们如何建立工程团队，在软件2.0中工作。系统和数据收集以及数据注释都是软件2.0的一部分。比如你认为软件编程的任务是什么？2.0是在超参数空间的调试还是在数据空间的调试？

Andrej 01:15:09
是的。你为计算机编程并影响其算法的方式不是通过自己编写命令。你主要是在改变数据集。你正在改变损失函数，比如神经网络试图做什么，它如何试图预测事情，但它们基本上是数据集和神经网络的架构，嗯，所以在自动驾驶汽车的情况下，很多数据集不得不做，例如检测物体和车道标线和交通灯等等。因此，积累大量的数据集，这里是一个例子，这里是所需的标签，然后呃，这里是大致的架构，这里是大致的算法应该是什么样子。这就是一个卷积神经网。因此，架构的规范就像一个提示，说明算法应该大致是什么样子的。然后，优化的填空过程就是训练过程，然后你把你的神经网训练好了。它在你的数据集上给出了所有正确的答案，然后你将其部署。

Lex 01:16:04
因此，在这种情况下，也许在所有的机器学习案例中，都有很多任务。因此，对于一个多头神经网络来说，制定一个任务是编程的一部分、

Andrej 01:16:21
如何

Lex 01:16:22
你把一个问题分解成一系列的任务。

Andrej 01:16:27
我是在高层次上，我想说如果你看一下自动驾驶仪中运行的软件，我就这个话题做了一些演讲，我想说最初很多都是用软件写的，一点都没有，有想象中的很多C加加，对。然后逐渐有了一个微小的神经网络，比如说，预测给定的单一图像。是否有交通灯？或者是否有一个固定电话标记。这个神经网络在软件的范围内没有太多的事情可做，只是对单个小图像进行微小的预测，然后系统的其他部分将其缝合起来。因此，好吧，我们实际上我们不只是有一个单一的摄像机与八个摄像机。我们实际上有八个摄像头，随着时间的推移。那么你是如何处理这些预测的呢？你怎么把它们放在一起？你如何做所有这些信息的融合，以及你如何对其采取行动？所有这些都是由人类用C加加写的。然后我们决定，好吧，我们实际上不希望呃用C语言做所有这些融合。

再加上代码，因为我们实际上不擅长写这种算法。我们想让神经网络来写算法，我们想支持所有的软件进入堆栈。因此，我们实际上有了神经网络，它现在同时接收所有八个摄像机图像，并对所有这些进行预测。因此，嗯，实际上它们并不在图像空间中进行预测。它们现在直接在三维空间中进行预测，实际上它们不在汽车周围的三维空间中进行预测。而现在，实际上我们并没有在三维空间中手动融合预测，随着时间的推移。我们不相信自己能写出这样的跟踪器。因此，实际上我们给神经网络呃信息随着时间的推移。所以它现在采取这些视频，并作出这些预测。因此，你有点像把越来越多的力量投入到神经网络的神经处理，在它的最后，最终的排序目标是有大部分的软件有可能在和嗯，因为它的工作明显更好，人类只是不擅长写软件基本上。

所以

Lex 01:18:16
预测是在这个像4D的土地上发生的，随着时间的推移，三维的世界。你如何在这个世界上做注释？你有什么，作为数据注释，无论是自我监督还是人类手动，嗯，都是世界的一个重要部分、

Andrej 01:18:37
对吗？我想说，到目前为止，如果你喜欢谈论这个行业，以及我们所拥有的技术是怎样的，一切都是监督学习。所以你需要一个输入的数据集，想要的输出，你需要大量的数据。而且嗯，你需要它的三个属性，你需要非常大，你需要准确，没有错误，你需要多样化。你不希望呃只是有很多正确的例子。有一点，你需要真正尽可能多地覆盖可能性的空间，你越能覆盖可能的输入空间，算法在最后就越好用。现在，一旦你有了真正好的数据集，你就可以在此基础上训练你的神经网络。因此，很多工作都是在清理这些数据集，现在正如你所指出的，它可能是可以的。问题是你如何实现一吨呃如果你想基本上预测在三个D.你需要数据和三个D.来支持。因此，在这个视频中，我们有八个视频来自系统的所有摄像机，这是他们看到的情况。

这就是周围实际情况的真相，有这辆车，有这辆车，这些是主线标记，这是道路的几何形状，在这个三维位置有交通灯。你需要地面真相。因此，该团队正在解决的大问题当然是你如何如何到达那个地面真相？因为一旦你有了一百万个它，而且它是大的、干净的和多样化的。然后对它进行神经网络训练，效果非常好，你就可以把它运到车上。因此，我们有许多机制来收集这些训练数据。你总是可以去做人类的注释。你可以用模拟作为基础真理的来源。你也可以使用我们所说的离线跟踪器。

Lex 01:20:12
那

Andrej 01:20:13
我们在A.I.D.等会议上讲过。这基本上是一个自动重建过程，用于拍摄这些视频和恢复该车周围的三维现实。因此，基本上可以认为做一个三维重建，作为一个离线的东西，然后理解，好吧，有10秒的视频。这就是我们所看到的，因此这里有所有的固定电话车等等。然后一旦你有了这个注释，你就可以训练一个神经网络来模仿它。

Lex 01:20:39
而重建这三个重建有多难？它是

Andrej 01:20:43
很难，但可以做到。

Lex 01:20:44
因此，摄像机之间有重叠，你要进行重建，如果有任何不准确的地方，也许会有呃。因此，这在注释步骤中就被抓住了。

Andrej 01:20:55
是的，注释的好处是，它是完全离线的。你有无限的时间，你有一分钟的大块时间，你试图在某处的超级计算机中离线计算出所有汽车和人的位置，你有所有角度的一分钟完整视频，你可以运行你想要的所有神经网络。它们可以是非常有效的大规模神经网络。有一些神经网络甚至不能在以后的测试时间在车上运行。因此，他们可以是比你最终可以部署的更强大的神经网络。因此，你可以做任何你想要的东西 三维重建神经网任何你想要的东西，只是为了恢复那个真相，然后你监督那个真相。

Lex 01:21:28
你学到了什么，你说人类做注释没有错误，因为我假设人类是呃有像在屏幕上点击东西方面擅长的一系列事情。那是多么有趣的是，你在设计一个注释器时有一个问题，人类是准确的，享受它，就像他们是什么，甚至指标是有效的或有成效的？所有这些东西。

Andrej 01:21:53
是的。因此，我在特斯拉的注释团队从基本上的0增长到2000呃，而我在那里，这真的很有趣。你知道，我的背景是一个博士生研究员。所以发展这样的组织是非常疯狂的。呃，但呃，我认为这是非常有趣的，也是自动驾驶背后的设计过程的一部分，因为你在那里使用人类。人类对某些类型的注释非常擅长。例如，他们非常擅长对图像进行二维注释。他们不擅长在三维空间中对汽车进行注释。非常，非常困难。因此，这就是为什么我们非常小心地设计那些对人类来说容易做的任务，而不是那些应该留给离线追踪器的事情。比如说，也许计算机会做所有的三角测量和三维重建，但是人类会说图像的这些像素，我们的车，这些像素正是人类的。因此，共同设计数据注释管道是我每天都在做的事情，是非常重要的、

Lex 01:22:48
你认为在这个领域还有很多未解决的问题吗？

Andrej 01:22:52
嗯

Lex 01:22:52
只是在一般的注释中，机器擅长的东西由机器来做，人类做他们擅长的东西，也许有一些迭代过程，对吗？

Andrej 01:23:03
我认为在很大程度上，我们经历了一些迭代，我们学到了很多关于如何创建这些数据集的知识。嗯，我没有看到大的开放性问题，就像最初我加入的时候，我很喜欢，我真的不知道这将会是怎样的结果，但是当我离开的时候，我更安全了，实际上我们有点了解如何创建这些数据集的理念，我对当时的情况很满意。

Lex 01:23:24
那么，当你把驾驶任务制定为一个有八个摄像头的视觉任务时，我们的摄像头对于驾驶任务的优势和局限性是什么？ 你已经看到了整个，你知道，计算机视觉领域的大部分历史，当它与神经网络有关时。只是如果你退一步，用像素来驾驶的优点和局限性是什么？

Andrej 01:23:49
是的，像素我认为是一种美丽的感觉，美丽的传感器。我想说像照相机这样的东西是非常非常便宜的，它们提供了一吨的信息，一吨的比特。同时它呃极其便宜的传感器，用于一吨的比特，而这些比特中的每一个都是对世界状态的约束。因此，你可以得到许多百万像素的图像，非常便宜，它只是给你所有这些约束，以了解世界上实际存在的东西。因此，视觉可能是最高带宽的传感器。它是非常高带宽的传感器。而且，嗯

Lex 01:24:21
我喜欢像素是呃，是世界上的一个制约因素，是世界上高度复杂、高带宽的制约因素，对世界的状态。它是

Andrej 01:24:34
不仅仅是这样，但同样，这个真正真正重要的是它是人类使用的传感器。因此，所有的东西都是为这个传感器设计的

Lex 01:24:42
文字、

Andrej 01:24:44
文字、闪烁的标志，一切都为视觉而设计。所以你会发现它无处不在。因此，这就是为什么你想进入的界面是这样的。嗯，再次谈到这些通用接口，这就是我们实际上想要测量世界的地方。然后为该传感器开发软件。

莱克斯01:25:01
但是还有其他关于世界状态的制约因素，人类用来理解世界的。我的意思是，视觉最终是主要的，但我们就像，我们就像参考了我们对人类行为的理解和一些可以从视觉中推断出来的常识和物理学，从，从感知的角度来看，但感觉我们是用某种推理来预测世界，而不仅仅是像素、

Andrej 01:25:30
你有一个强大的关于世界如何随时间演变的先验，等等。因此，这不仅仅是关于来自数据本身的可能性项，告诉你你正在观察的东西，而且还有像哪里的先验项，哪里有可能看到的东西，它们如何可能移动等等？还有

Lex 01:25:47
问题是在驾驶任务中可能发生的各种可能性有多复杂？这仍然是你仍然是一个开放的问题，即驾驶有多难？就像从哲学上讲，是否所有的

Andrej 01:26:05
你工作的时间

Lex 01:26:06
开车。你知道开车有多难吗？

安德烈 01:26:10
驾驶真的很难，因为它必须与所有这些其他代理人的预测和心智理论有关，你知道他们会做什么，他们是否在看你，他们是否，他们在哪里看，他们在想什么？是的，有很多东西在那里，在充分的故事，你知道九的扩展，我们必须对它感到满意。最终，最后的问题是那种形式的，我不认为那些是很常见的问题，我认为最终它们是很重要的，但它就像真的在尾声一样

Lex 01:26:35
在尾声中，从视力的角度来看，罕见的边缘案例，驾驶的视力问题中最艰难的部分是什么？

Andrej 01:26:45
嗯，基本上传感器是非常强大的，但你仍然需要处理这些信息。嗯，所以从亮度的特殊值到嘿，这里的三维世界是非常困难的，这就是神经网络的根本作用。因此，嗯，真正的困难是在整个管道工程方面做得非常好，整个数据引擎，有能力训练这些神经坚果，有能力评估系统并对其进行迭代。因此，我想说的是，在生产中大规模地这样做是困难的部分，这是一个执行问题。

凌志01:27:22
因此，数据引擎，但也是，嗯，系统的那种部署，具有低延迟的性能。因此，它必须做所有这些步骤

Andrej 01:27:32
在一般情况下，不是特别要确保所有的东西都能装进车上的芯片里，你有一个有限的翻转预算，你可以执行，呃，还有内存带宽和其他限制。你必须确保它能飞起来，而且你能把尽可能多的计算机挤进这个小东西里、

Lex 01:27:47
你从这个过程中学到了什么，因为这可能是一个更大的，像新的东西，从研究背景来的，有，有一个系统必须在严重受限的资源下运行，必须运行得非常快。你从那里学到了什么，什么样的见解？

Andrej 01:28:04
是的，我不确定这是否是，如果有太多的见解，你试图创建一个神经网络，以适应你现有的东西，你总是试图优化它，我们在ai日谈了很多，呃，基本上团队正在做的三重后空翻，以确保所有适合和利用的引擎。呃，所以我认为这是非常好的工程。嗯，然后还有各种关于如何正确做这件事的小见解掺杂其中。

Lex 01:28:30
让我们实际放大，因为我不认为我们谈到了数据引擎，这个想法的整个布局，我认为在循环中的人类就是美丽的。你能描述一下数据引擎吗？

Andrej 01:28:42
是的，数据引擎就是我所说的类似于生物感觉的过程，通过它你可以完善这些神经网络的训练集。嗯，所以因为现在大部分的编程都是在这些数据集的层面上，并确保它们是大的、多样的和干净的，基本上你有一个你认为是好的数据集。你训练你的神经网络，你部署它，然后你观察它的表现如何，你总是试图提高你的数据集的质量。你试图抓住基本上是罕见的场景，正是在这些场景中，通常会挣扎，因为他们没有被告知在数据集中的那些罕见情况下该怎么做。但现在你可以关闭这个循环，因为如果你现在可以大规模地收集所有这些，你就可以把它们反馈到我描述的重建过程中，并在这些情况下重建真相，并添加到数据集中。因此，整个事情最终就像一个完善你的训练集的改进阶梯，你必须通过部署，以便你可以挖掘呃数据集中还没有很好体现的部分。所以你的数据说基本上是完美的，它需要多样化，它有口袋，有缺失，你需要垫出口袋，你可以在数据中这样考虑。

Lex 01:29:54
人类在其中扮演什么角色？那么这个生物系统是什么，比如说人体是由细胞组成的？什么什么角色，比如你如何优化人类系统，多个工程师合作，弄清楚什么是重点，什么是贡献，哪个哪个任务在这个神经网络中优化，谁负责弄清楚哪个任务需要更多数据。你可以你可以讲超参数的人类呃系统、

安德烈 01:30:28
它真的只是归结为来自工程团队的极好的执行力，他们知道自己在做什么，他们直观地理解数据引擎背后的哲学见解和系统改进的过程，以及如何再次像授权数据收集的策略和如何工作，然后只是确保它是非常好的执行，这就是大多数工作的地方，甚至不是哲学或研究或它的想法，只是极好的执行，当你在处理数据时是如此困难。

Lex 01:30:53
规模。所以你在数据引擎中的作用，在上面执行得很好。这很难，也极其重要。是否有一个优先权，比如说呃，像一个愿景板，说我们真的需要在红绿灯方面做得更好。像任务的优先级是，本质上，这来自于数据

安德烈 01:31:14
在很大程度上，我们试图在产品中实现一个地图，在那里我们试图发布，我们试图从QA团队的反馈中得到嗯，系统在哪里挣扎或不挣扎，我们试图改善的事情和

Lex 01:31:26
QA团队给一些信号一些关于系统在各种条件下的性能的综合信息

Andrej 01:31:34
当然，我们所有人都在驾驶它，我们也可以看到它，与你自己也能体验的系统一起工作真的很好，你知道，它让你回家。它是

Lex 01:31:41
是否有一些你可以从你的个人经验中得出的洞察力，而你却不能从总体统计中得到 是的，这太奇怪了。对吗？是的。这在某种意义上是不科学的，因为你只是一个传闻中的样本。

Andrej 01:31:57
是的，我认为有一吨呃它是真理的来源是你与系统的互动，你可以看到它，你可以玩它，你可以扰乱它，你可以得到它的感觉，你对它有一种直觉。我认为数字就像有一种数字的方式，而图画和图表则更难。呃，它隐藏了很多的

Lex 01:32:15
这就像如果你训练一个语言模型，它是一个真正强大的方式，是由你与之互动的

安德烈 01:32:22
它和尝试

Lex 01:32:23
来建立起一种直觉。

Andrej 01:32:24
是的，我认为像埃伦也像他一直想亲自驾驶这个系统。他经常开车，呃，我想说几乎每天都在开车。所以，呃，他也认为这是一个真理的来源。你驾驶着这个系统，嗯，并执行和

Lex 01:32:38
是的，所以你怎么想？困难的问题在这里？呃，所以特斯拉去年从传感器套件中删除了雷达，现在刚刚宣布将删除超声波传感器，只依靠视觉。那么，相机只是使感知问题更难还是更容易？I

Andrej 01:33:01
几乎会以某种方式重新构建这个问题。所以问题是，基本上你会认为额外的传感器

Lex 01:33:07
顺便说一句，我可以打断一下吗。我想知道语言模型是否会做 如果你提示了？让我重新规划一下你的问题。那将是史诗般的。

Andrej 01:33:16
这是不对的

Lex 01:33:16
问题。对不起。

Andrej 01:33:17
这就像一个有点错误的问题，因为基本上你会认为这些传感器对你来说是一种资产。但如果你充分考虑整个产品的整体性。这些传感器实际上是潜在的责任，因为这些传感器不是免费的。他们不只是出现在你的车上。你需要突然你需要有一个完整的供应链。你有人们采购它。他们可能会有问题。他们可能需要更换。他们是制造过程的一部分。他们可以在生产中拖住生产线，你需要采购他们来维护他们。你必须有编写固件的团队，所有的，所有的。然后你还必须以某种方式将它们纳入并融合到系统中。

因此，它实际上就像膨胀了很多东西。我认为Ellen真的很擅长简化，简化的最好部分是没有部分。他总是试图扔掉那些不重要的东西，因为他了解组织中的熵和一种方法。我认为在这种情况下，成本很高，如果你只是一个计算机视觉工程师，你不可能看到它，我只是试图改善我的网络，你知道，它是更有用还是更少有用？它的作用有多大？而问题是一旦你考虑到一个传感器的全部成本，它实际上是潜在的责任，你需要真正确定它在这种情况下给你提供极其有用的信息。我们研究了使用它或不使用它的情况，结果是没有巨大的差异。因此，它是没有用的

Lex 01:34:33
在数据引擎中是否也会受到打击，如有更多的意义

Andrej 01:34:37
百分比

Lex 01:34:39
和

Andrej 01:34:39
这些传感器，你知道，它们可以随着时间而改变。例如，你可以有一种类型的雷达，你可以有其他类型的雷达。它们随着时间的推移而变化，现在你突然需要担心这个问题了。现在你突然在你的序列灯中有一栏告诉你，哦，是什么传感器类型？他们都有不同的分布，然后呃，他们可以，他们只是，他们贡献了噪音和熵到一切，他们臃肿的东西，而且在组织上一直是真正迷人的我，它可以是非常分心的。嗯，如果你，如果你，如果你只想去工作是视觉，所有的资源都在它上面，你正在建立一个数据引擎，你实际上正在取得前进的进展，因为那是，传感器有最多的带宽，世界上最多的约束，你正在充分投资于此，你可以使那极好，如果你，你只是一个有限的排序花费的焦点在系统的不同方面。

Lex 01:35:26
而呃，这有点让我想起了哪个萨顿的惨痛教训。从长远来看，这似乎只是简化了系统。当然，你不知道什么是长期的，它似乎总是正确的解决方案

Andrej 01:35:40
在

Lex 01:35:40
在这种情况下，它是针对RL的，但它似乎普遍适用于所有进行计算的系统。那么，你对激光雷达作为拐杖的辩论有何看法。点云和像素之间的斗争。

安德烈 01:35:54
是的，我认为这个辩论总是让我有点困惑，因为看起来真正的辩论应该是关于你是否有舰队？那才是真正重要的事情，你是否能在规模上实现Ai系统的真正良好运作。所以

Lex 01:36:07
数据收集系统。

Andrej 01:36:09
是的。你是否有一个车队？你有没有打火机明显更重要吗？这只是另一个传感器。嗯，呃，是的，我认为基本上与雷达的讨论类似。我嗯，是的，我不认为它它基本上不提供额外的，额外的信息是非常昂贵的。它有各种各样的问题，你必须担心它，你必须校准它等等。它创造了臃肿和熵。你必须真正确定你在这种情况下需要这个呃这个嗯传感器。我基本上不认为你需要它，我想说实话，我会做一个更有力的声明。我认为其他人，一些正在使用它的其他公司可能会放弃它。是的。

Lex 01:36:46
因此，你必须考虑到传感器的全面性，在考虑你能否建立一个收集大量数据的大车队，你能否将该传感器与之整合？这些数据和传感器进入一个数据引擎，能够快速找到数据的不同部分，然后不断改进你使用的任何模型。

Andrej 01:37:07
另一种看法是，视觉是必要的，因为世界是为人类的视觉消费而设计的，所以你需要视觉，这是必要的，然后它也是充分的，因为它有你驾驶所需要的所有信息，而人类显然有一个驾驶的视觉。所以它既是必要的也是充分的。因此，你想集中资源，你必须真正确定，如果你要引进其他的传感器，你可以你可以增加传感器到无穷大，在某些时候你需要划定界限，我认为在这种情况下，你必须真正考虑你所采用的任何一个传感器的全部成本，你真的需要它吗？我认为在这种情况下的答案，你知道、

Lex 01:37:44
那么，你对其他公司正在形成高分辨率的地图并严重限制其运营的地理区域的想法有什么看法？在你看来，这种方法不会随着时间的推移扩展到美国的全部地区。

Andrej 01:38:04
我想你提到了像他们预先绘制所有环境的地图，他们需要刷新地图，他们有一个完美的厘米级精度的地图，他们要驾驶的地方。这很疯狂，你要如何，我们一直在谈论自主权实际上改变了世界。我们正在讨论在全球范围内部署用于运输的自主系统，如果你需要为地球或像许多城市维持发送你的精确地图并保持更新。这是一个巨大的依赖性，你要承担巨大的依赖性。这是一个巨大的巨大的依赖性，现在你需要问自己，你真的需要它，人类不需要它吗？嗯，对，所以它是非常有用的，有一个低水平的地图，比如说好吧，你的道路的连接。你知道，当你驾驶一个环境的时候，有一个四的到来，你有点有那种高层次的理解。这就像一个小的谷歌地图，特斯拉在系统中使用谷歌地图，就像类似的那种分辨率信息，但它不会预留地图环境的厘米级精度。这是一个拐杖。它是一种分心，它花费了熵，它分散了团队。它稀释了团队，你没有专注于真正必要的东西，这就是计算机视觉问题。

Lex 01:39:09
关于机器学习你学到了什么关于工程关于生活？关于你自己？作为一个人，从与埃隆-马斯克的合作中。

安德烈 01:39:20
我想我学到的最多的是关于如何有效地运行组织，如何创建高效的组织，以及如何在组织中对抗熵。

Lex 01:39:29
因此，人类工程在对抗

Andrej 01:39:32
熵。有一个有一个，我认为艾伦是一个非常高效的战士，在组织中对抗熵的斗争。

Lex 01:39:40
该组织看起来完全像

Andrej 01:39:42
它的过程，它的过程，它的过程和

Lex 01:39:46
低效率和诸如此类的东西。

Andrej 01:39:49
是的，会议，他讨厌会议，他一直告诉人们，如果会议没有用，就跳过会议。他基本上经营着世界上最大的创业公司，我想说呃，特斯拉SpaceX是世界上最大的创业公司。特斯拉实际上是多个创业公司。我认为这样看会更好。所以我认为他是他非常擅长的。而且，呃，是的，他对精简流程有很好的直觉，使一切都有效率。最好的部分是没有简化的部分，专注于嗯，只是那种消除障碍，移动非常快，做大动作，所有这些都是非常初创公司，p排序的事情，但在规模上。

Lex 01:40:24
从你的角度来看，如此强烈的简化动力。我的意思是，嗯，这也可能适用于只是设计系统和机器学习，以及其他像简化简化。你认为在一个不断成长的公司中保持创业文化的秘诀是什么。是否有，你能反省一下吗？

Andrej 01:40:47
我确实认为他需要一个身居要职、有大锤子的人。就像艾伦一样，他就像是这个想法的拉拉队，并且无情地狠狠地追求它。如果没有人有一个足够大的锤子，一切都会变成委员会，公司内部的民主进程，与利益相关者交谈的决策。只是一切都会崩溃。如果你有一个大人物，他也非常聪明，并且有一个大锤子。事情就会迅速发展。

Lex 01:41:12
所以你说你最喜欢星际里的那场戏是ai和cooper说话的激烈的丝袜戏，说cooper，你在做什么对接？这是不可能的，不，这是必要的，顺便说一句，这是个好台词。只是那里有很多问题，为什么在那个场景中，AI应该能够比人类计算得更多，却说这不是最佳状态。为什么是人类，我的意思是这是一部电影，但他们不应该吗？反正我比人类知道得更多。你认为设定看似不可能的目标的价值是什么？因此，像呃我们最初的直觉，这似乎是你已经采取的东西，埃伦支持，其中社区的最初直觉可能说这是非常困难的，然后你无论如何都要接受它，有一个疯狂的最后期限。你只是从人类工程的角度来看，呃，你是否看到了这种做法的价值？

Andrej 01:42:15
我不会说，设定不可能的目标。确切地说，是是一个好主意，但我认为设定非常雄心勃勃的目标是一个好主意。我认为有一个，我称之为难度的亚线性缩放，这意味着10 X问题不是10 X困难，通常10 X 10 X困难的问题就像2或3 X困难的执行，因为如果你想实际像如果你想改善系统的10%，它花费一些工作，如果你想改善系统，它不花费 你知道100 X。数量的工作，因为你从根本上改变了方法，如果你从这个约束开始，那么一些方法显然是愚蠢的，不会成功的，它迫使你重新评估。我认为这是一种非常有趣的解决问题的方法。

我想说的是，你的想法是什么？
但这需要一种奇怪的思维，它只是回到了你的博士时代，这就像你如何看待机器学习界的哪些想法是可以解决的？

Andrej 01:43:10
是的，它是

我的意思是说，如果你是一个人的话，你就得去找他。
呃，这需要什么呢？我的意思是，有一个老生常谈的第一原理思维，但就像它要求基本上忽略社区所说的，因为它没有社区不知道的。科学界通常会划定哪些是可能的，哪些是不可能的，而且如果不发疯，就很难突破这个界限。

Andrej 01:43:32
是的，我的意思是，我认为这里有一个很好的例子，你知道在某种意义上的深度学习革命，因为你可以在计算机视觉的时候，在2012年的深度学习那种革命期间，等等。呃，你可以将计算机视觉堆栈提高10%，或者我们可以说实际上所有这些都是无用的，我怎样才能做到10倍的计算机视觉？嗯，这可能不是通过调整霍格特征检测器，我需要一个不同的方法嗯，我需要一些可扩展的东西。回到呃理查德-萨顿的嗯，理解有点像苦难的教训的哲学，然后像实际上我需要更多的可扩展的系统。就像一个原则上可行的神经网络，然后有一些深度的信徒可以真正执行这个任务，并使其发挥作用。所以这就是解决方案。

Lex 01:44:16
你认为解决自动驾驶问题的时间表是什么？这在一定程度上仍是个开放性问题。

安德烈 01:44:26
是的，我认为自动驾驶的时间表的艰难之处显然在于，没有人创造出自动驾驶。

Lex 01:44:31
是的。

Andrej 01:44:32
所以这并不是说你认为建造这座桥的时间表是什么？好吧，我们以前建过一百万座桥。这是需要多长时间的。你知道这是呃，没有人建立了自主权。这不是很明显。有些部分比其他部分容易得多，所以真的很难预测，你要根据趋势线等，根据直觉尽力而为，但这就是为什么从根本上说，真的很难预测这个。没有人是

Lex 01:44:54
即使仍然喜欢在里面，也很难做到。

Andrej 01:44:58
有些事情会变得更难，有些事情会变得更容易。

Lex 01:45:02
你试图避免做预测吗？因为像Ellen不会回避它们吧？而汽车公司的负责人在过去也没有回避，向前在其他地方做了预测，我们要解决第四级。在2020年2021年之前解决驾驶问题什么的。而他们都在回溯这个预测。你作为一个AI人，你是否为自己私下做了预测，或者它们妨碍了你思考一件事情的实际能力？

Andrej 01:45:37
是的，我想说的是，容易说的是这个问题是可以解决的，这是一个容易做出的预测。它是可以解决的。它将会起作用。是的，它只是真的很难。有的东西原来比有的东西更难，有的东西原来更容易。所以，但它绝对感觉是可操作的，而且感觉至少特斯拉的团队，也就是我在内部看到的，绝对是在这个轨道上。如何

Lex 01:45:57
你是否形成了一个强有力的代表，使你能够对吸引能力做出预测？所以，就像你是很多，很多人类的领袖，你必须要有点说这是实际可能的。就像你如何建立起这种直觉？它甚至不一定是驾驶，它可能是其他任务。这可能是。嗯，我想，你在你的生活中做了什么困难的任务？我的意思是分类，实现某些只是在某种程度上的超人类水平的表现的形象。是的、

Andrej 01:46:29
专家的直觉只是直觉，它是信仰。

Lex 01:46:34
所以就像思考了很久。就像研究看样本数据，就像你说的驾驶我的直觉在这上面真的有缺陷。就像我对跟踪能力没有一个好的直觉。它可能是任何一种，它可能是任何东西，它可能是可解决的。像呃，你知道，驾驶任务可以简化成相当琐碎的东西。就像呃，这个问题的解决方案将是相当微不足道的，在规模上，越来越多的汽车完美驾驶可能会使问题变得更加容易。你拥有的汽车越多，人们就会学会如何正确地驾驶，不是正确地驾驶，而是以一种对自主和半自主以及手动驾驶的汽车的异质系统来说更理想的方式，这可能会改变一些东西。然后，我也花了很多时间盯着过马路的行人，思考人类，感觉我们使用眼神接触的方式，它发出了非常强烈的信号，有一些行为的怪癖和边缘案例，当然，很多发生的死亡事件都与酒后驾驶有关，嗯，无论是在行人方面还是在司机方面。所以有夜间驾驶和所有这些问题，所以我想，你知道，这就像自动驾驶的可能解决方案的空间包括许多人为因素的问题，几乎不可能预测。可能会有超级干净、漂亮的解决方案。

Andrej 01:48:04
是的，我想说的是，绝对喜欢用游戏来比喻，有一些战争的迷雾，但你肯定也会看到改进的前沿，你可以从历史上衡量你已经取得了多少进展。我认为，例如，至少我所看到的和我加入时大约五年的特斯拉，它几乎没有保持在高速公路上躺着。我认为，从帕洛阿尔托到三藩市就像三或四次干预，只要道路会做任何几何上的事情或转弯太多，它就像不工作。因此，在五年内从那变成了一个相当有能力的系统，看到引擎盖下发生的事情，以及团队现在在数据、计算机和其他方面的操作规模，呃，只是一个巨大的进步。所以

Lex 01:48:43
只是你在爬山，有雾，但你的进步很大、

Andrej 01:48:49
你正在取得进展，你看到下一个方向是什么，你在看一些剩余的挑战，它们不像是，呃，它们没有扰乱你，它们没有改变你的哲学，你没有控制扭曲自己。你会觉得实际上这些是我们仍然需要做的事情。

Lex 01:49:01
解决问题的基本组成部分似乎有数据引擎，到计算机，卡上的计算机，到计算机，培训，所有这些东西。所以你这些年来，你做了一个测试，你做了很多惊人的突破性想法和工程，所有的这些。嗯，从数据引擎到人的方面，所有这些你能谈谈你为什么选择离开特斯拉、

安德烈 01:49:27
基本上，正如我所描述的那样，那是什么？我认为随着时间的推移，在这五年中，我有点让自己进入了一个有点管理的位置，我的大部分时间都在开会，发展组织，做出关于团队的那种高水平的战略决策，以及它应该做什么等等，呃，这有点像一个企业高管的角色，我可以做到这一点，我认为我在这方面还不错，但它不像从根本上我什么我喜欢。所以我想当我加入的时候，嗯，没有计算机视觉团队，因为特斯拉刚刚从使用移动的过渡，我是一个第三方供应商来做所有的计算机视觉，到不得不建立这个计算机视觉系统。所以当我出现的时候，有两个人在训练深度神经网络，他们在他们的腿上的电脑上训练他们。就像下面有一个

Lex 01:50:14
基本分类任务

安德烈 01:50:16
所以我就把它发展成了我认为是一个相当值得尊敬的深度学习团队，大规模的计算机集群，非常好的数据注释组织。我对这个团队非常满意，它变得相当自主。因此，我离开了，我，你知道，我很高兴能再次做更多的技术性工作。是的，就像我们专注于一个G I

Lex 01:50:38
你的灵魂搜索是什么，就像你花了一点时间去思考，你吃了多少蘑菇？我的意思是，你脑子里想的是什么，人的一生是有限的？

Andrej 01:50:49
你

Lex 01:50:50
做了一些不可思议的事情，你是你是世界上最好的ai老师之一，你是最好的之一，我不是说这个，我的意思是以最好的方式，你是Ai世界中最好的修补者之一，意思是像通过从头开始建立和玩弄基本的直觉来理解一个东西如何工作的基本原理，这就像爱因斯坦-费恩曼，我们都非常擅长这种东西，像一个小例子的东西来玩它，试着去理解它。所以，这一点，显然现在你会帮助建立一个机器学习的团队嗯，像工程师和一个系统，在现实世界中真正完成了一些事情，鉴于所有这些，像什么是灵魂

Andrej 01:51:33
搜索？就像？这很难，因为显然我非常喜欢这家公司，我爱我爱艾伦，我爱特斯拉，我想嗯很难离开，我爱这个团队基本上。嗯，但是，我想实际上我有可能会有兴趣重新审视它，当你在某个时候回来的时候，是工作的乐观主义者，在特斯拉工作的吉，我认为特斯拉将做不可思议的事情。它基本上是一个大规模的大型机器人公司，拥有大量的内部人才，可以做非常不可思议的事情，我认为人类机器人将是惊人的。我认为自动运输将是惊人的。所有这些都是在特斯拉发生的。所以我认为这是一个非常了不起的组织。因此，作为它的一部分，并帮助它，我认为是非常，基本上是非常享受的。是的，由于这些原因，这基本上是困难的，因为我爱这个公司，但你知道，我很高兴有可能在某个时候回来参加第二幕。但我觉得在这个阶段，我建立了团队，感觉是自主的，我成了一个经理，我想做更多的技术性工作，我想学习东西，我想教东西。呃，呃，我只是觉得这是一个很好的时间，可以稍微改变一下节奏。

Lex 01:52:45
你认为有史以来最好的电影续集是什么？说到第2部？因为喜欢，因为他们中的大多数都很糟糕

Andrej 01:52:52
电影

Lex 01:52:53
续集和你推特上的电影。所以，只是一个小小的切入点是吗？你最喜欢的电影续集是什么？教父？第二部分。你是 "教父 "的粉丝，因为你甚至没有在推特上提到 "教父"。

Andrej 01:53:07
是的，我不喜欢那部电影。我知道它没有

Lex 01:53:08
把这个编辑掉。我们要编辑掉对《教父》的仇恨？你怎么敢

Andrej 01:53:13
认为会做出强有力的声明？我不知道为什么。我也不知道为什么，但我基本上不喜欢1995年以前的任何电影。类似这样的事情。

Lex 01:53:21
你不是提到了《终结者》吗？

Andrej 01:53:23
2?好的，好的。这就像终结者二号是在1990年，稍微晚了一点。

Lex 01:53:29
不，我认为《终结者2》就在里面

Andrej 01:53:31
我也喜欢《终结者》。所以，好吧，就像几个例外，但总的来说，出于某种原因，我不喜欢1995年或之前的电影，它们感觉很慢。镜头就像放大了一样，很无聊，有点天真烂漫。这有点奇怪。

Lex 01:53:44
另外，《终结者》也是非常超前的。

Andrej 01:53:47
是的。还有《教父》，好像没有，A G. I. joe

Lex 01:53:52
我的意思是，但你有Good Will Hunting是你提到的电影之一，那也没有任何A G. I。我想这就是数学。I

Andrej 01:54:01
偶尔我也会在电影中做一些没有特色或

Lex 01:54:04
像 "主播 "那样没有，就是这样

Andrej 01:54:07
是如此的好。

Lex 01:54:08
我不明白。嗯 说到A G. I因为我不明白为什么威尔-费雷尔这么有趣。这没有意义。我不知道这是否与文化有关，是否与好莱坞的机器有关，或者是否与我们很幸运地与喜剧界的某些人走到一起有关，因为他是一个奇特的人。这是一个可笑的切入点，我道歉，但你提到了类人机器人。那么，你对奥托马斯有什么看法？关于特斯拉的身体？你认为在10年2030年、40年、50年后，我们会在工厂里、在家庭里有机器人吗？

Andrej 01:54:49
是的，我认为这是一个非常困难的项目，我认为这将需要一段时间，但还有谁会大规模地建造人类机器人？我认为这是一个非常好的形式因素，因为就像我提到的，世界是为人类设计的形式因素。这些东西将能够操作我们的机器，他们将能够坐在椅子上，甚至有可能驾驶汽车。基本上，这个世界是为人类设计的，这就是你想投资的形式因素，并随着时间的推移使其发挥作用。呃，我想你知道，还有另一个学派的想法，那就是好吧，拿一个问题来设计一个机器人。但实际上，设计一个机器人，让整个数据引擎和它背后的一切工作，实际上是令人难以置信的困难问题。因此，追求一般的界面是有意义的，它们对于任何一个特定的任务都不是完美的，但它们实际上具有通用性，只要有一个提示，英国人就能做一些事情，所以我认为在物理世界中追求一个一般的界面是很有意义的。我认为这是一个非常困难的项目。它将需要时间。嗯，但我看到没有其他，没有其他公司可以执行这个愿景。我认为这将是惊人的。就像呃基本上是体力劳动，就像如果你认为运输是一个大市场，试试体力劳动的疯狂、

Lex 01:55:57
但它不仅仅是体力劳动。对我来说，同样令人兴奋的是社会机器人。因此，与这些机器人的关系将在不同层面上有。这就是为什么我非常兴奋地看到乐观主义者，就像嗯人们批评我的兴奋，但我我已经与嗯很多研究实验室合作，做人形腿部机器人，波士顿动力学，统一。有很多公司在做腿部机器人，但这是运动的优雅，是大图片的一个很小的部分。因此，对我来说，整合特斯拉做人形机器人或任何腿部机器人的两个大的令人兴奋的事情显然是整合到数据引擎。因此，数据引擎方面，所以实际的感知、控制和规划的智能，以及所有这些东西都整合到你提到的这个巨大的舰队，对吧。嗯，然后说到舰队，第二件事是大规模的制造商只是知道呃文化上呃驱使向一个简单的机器人，这是很便宜的规模化生产，做得很好，有经验来做这个。嗯，这改变了一切。这就是为什么这是一个非常不同的文化和风格，与波士顿动力公司相比，那些那些机器人只是他们的移动方式。这就像，在泰莎能够达到运动的流畅性之前，这将是一个非常长的时间。但那不是它的目的。

这是，这是关于，这是关于整个系统的。就像我们谈到的数据引擎和车队。那是超级令人兴奋的。即使是最初的那种模型，但这也是非常令人惊讶的，在几个月内你可以得到一个原型。

安德烈 01:57:47
之所以发生得如此迅速，是因为正如你所提到的，在自动驾驶中发生了大量的复制粘贴。特斯拉在建造人类机器人方面的专业知识数量是令人难以置信的，基本上艾伦在一个点上说，我们正在做这个。然后第二天，基本上所有这些CAD模型都开始出现，人们谈论着供应链和制造，人们带着螺丝刀和所有东西出现，就像前几天一样，开始组装身体，我当时想，哇！这些人在特斯拉都存在！所有这些人都存在于特斯拉，从根本上说，制造一辆汽车实际上与制造一个机器人没有什么不同。这是真的，不仅仅是硬件部分，还有，让我们不要忘记硬件，不仅仅是为了演示，而是嗯，大规模地制造这些硬件。这就像一个完全不同的事情，但对于软件也是如此，基本上这个机器人目前认为它是一辆汽车。呃，它将会

Lex 01:58:40
有一个中年危机或东西。它

Andrej 01:58:43
认为它是一辆车。嗯，早期的一些演示实际上，我们正在讨论可能在停车场外面做这些演示，因为那是所有计算机视觉的地方，就像在外面工作一样。

Lex 01:58:51
用盒子代替

Andrej 01:58:53
像里面的。嗯，但所有的操作系统，一切都只是复制粘贴。计算机视觉大多是复制粘贴。我的意思是，你必须重新训练神经螺母，但方法和一切，数据引擎和离线跟踪器。而我们的方式是关于占用追踪器等等，一切都复制粘贴。你只需要重新训练你的神经地段。呃，然后规划控制当然要有相当大的变化，但在特斯拉发生的事情上有大量的复制粘贴。因此，如果你想，如果你想实现这样的目标，好吧，让我们建造一百万个人类机器人，而你不是特斯拉，这是一个很大的要求，如果你的特斯拉，它实际上像，它不是，它不是那么疯狂。而且

Lex 01:59:26
那么后续的问题是，就像我们开车一样，有多难？操纵任务有多难，以至于它可以在规模上产生影响。我认为这取决于环境。机器人技术真正好的地方是，除非你做一个制造业的那种东西，否则有更多的错误空间。驾驶是如此的安全关键，因此，也是时间关键，机器人被允许移动得慢一些，这很好。

Andrej 01:59:54
我认为这将需要很长的时间。但是，你想构建发展的方式是，你需要说好吧，这将需要很长的时间。我怎样才能建立起呃产品开发路线图，使我在这一过程中获得收入。我不会给自己设定一个01年的损失函数，在它成功之前不会工作。你不想处于这种境地。你想让它几乎立即发挥作用，然后你想慢慢地部署它。

Lex 02:00:17
于

Andrej 02:00:17
你想建立你的数据引擎，你的改进循环，遥测，评估，马具和一切。嗯，你想随着时间的推移逐步改善产品，而且你要在这一过程中赚取收入。这是非常重要的，因为否则你不能建立这些大型的事业，就像在经济上没有意义。而且，从工作团队的角度来看，他们也需要沿途的多巴胺。他们不只是要作出承诺，说这是有用的。这将在10年内改变世界，当它发挥作用时，这不是你想要的地方，你想在一个地方，就像我今天想的政治，它提供了更多的安全和嗯和呃今天驾驶的便利，人们为它付钱，人们喜欢它，人们购买它，然后你也有更大的使命，你正在努力实现

Lex 02:00:59
你看，这样的兴奋剂，你为团队，这是一个幸福的来源，一个

Andrej 02:01:04
100%你在部署这个。人们喜欢它。人们驾驶它，人们为它付钱，他们关心它。有所有这些YouTube视频，你的祖母驾驶它。她给你反馈，人们喜欢它，人们参与它，你参与它巨大。

Lex 02:01:15
开特斯拉的人是否认识你，并给你爱，比如说嘿，谢谢你的这个好功能，正在做的。

Andrej 02:01:25
是的，我认为棘手的事情是像有些人真的爱你，有些人不幸的是像你在做一些你认为非常有价值，有用的东西等等。有些人确实讨厌你。有很多人都讨厌我和我的团队以及整个项目的一切，而我

Lex 02:01:39
认为特斯拉司机在

安德烈 02:01:41
许多情况下，他们实际上并不

Lex 02:01:43
是的，这实际上让我对人类或当前的人类互动方式感到悲伤，我认为这实际上是可以解决的。我认为人类想对彼此好。我认为微博和社交媒体是机制的一部分，它实际上以某种方式使负面情绪更加病毒化，它不应该像不成比例地呃添加像病毒性的病毒性促进负面情绪，但我得到了，我希望人们只是兴奋呃，所以抑制一些嫉妒，一些自我，只是为别人兴奋。然后有一个因果关系的方面，你为别人兴奋，他们也会为你兴奋，在学术界也是如此。如果你不小心，那里有一个像动态系统的东西。如果你，如果你在孤岛上思考，嫉妒别人的成功，这实际上也许是反直觉的，呃，导致你作为一个社区和你个人的生产力下降，我觉得如果你继续庆祝

Andrej 02:02:39
其他

Lex 02:02:40
这实际上使你更加成功。是的，我认为人们还没有，根据不同的行业还没有完全学会这一点。

Andrej 02:02:46
还没有。有些人也很消极，很有发言权，所以他们很突出，但实际上有一大堆人是拉拉队，但他们是沉默的，显然是拉拉队，当你和人们交谈时，只是在这个世界上，他们会告诉你这是惊人的。这很好，特别是像那些了解让这个东西工作有多困难的人，比如那些建造过产品的人和制造者，企业家创业者，比如说让这个东西工作，改变一些东西是非常困难的，这些人更有可能为你欢呼。

Lex 02:03:14
好吧，好吧，让我伤心的一件事是机器人界的一些人不做比他们应该做的拉拉队。有呃因为他们知道这有多难。嗯，他们实际上有时不知道创造一个如此规模的产品有多难。对吗？他们实际上在现实世界中部署。很多机器人和人工智能系统的开发是在非常具体的小基准上完成的。嗯，而且是相对于现实世界的条件而言。

Andrej 02:03:40
是的，我认为在学术环境中从事机器人工作真的很难

Lex 02:03:43
或适用于现实世界的AI系统。你，你批评过你嗯蓬勃发展，爱过一段时间。图像网，著名的图像那个数据集，我最近有一些批评的话，说学术研究ml界对图像网或像那些种类的基准仍然给予了有点太多的爱。你能谈谈机器学习研究中使用的数据集的优势和劣势吗？

Andrej 02:04:13
事实上，我不知道我是否记得我不高兴或批评图像网的具体事例。我认为图像网是非常有价值的。呃，它基本上是一个基准，让深度学习社区证明深度神经网络确实有效。它是......这有巨大的价值。所以我认为那是有用的，但基本上它在这一点上已经成为一个有点大赦。因此，女权主义就像等于28乘28的灰度数字，这是一种笑话数据集，每个人都喜欢碾压、

Lex 02:04:44
还有关于大赦的论文，对吗？

Andrej 02:04:46
也许是喜欢强势的报纸

Lex 02:04:48
像那些专注于像我们如何学习少量数据的论文

安德烈 02:04:53
我可以看到那是有帮助的，但不是在那种像主线计算机视觉研究中了。当然了。I

Lex 02:04:57
我认为我在某处听到了你的说法，也许我只是在想象，但我认为你说的那样，在很长一段时间内对社会做出了巨大的贡献，现在是时候超越那些类型的

Andrej 02:05:07
这已经被粉碎了。我的意思是，你知道，空气率是呃，是的，我们在1000个分类方式中得到了90%的准确率，呃，预测，我已经看到了这些图像，这就像真的很高。这真的，这真的很好。如果我没猜错的话，现在前五名的空气率是1%左右。

Lex 02:05:28
鉴于你对巨大的现实世界数据集的经验，你是否希望看到基准向研究界使用的某些方向发展？

Andrej 02:05:36
不幸的是，我不认为学术界目前有下一个图像网。我们显然已经，我认为我们已经粉碎了em n'est，我们基本上已经粉碎了image net。呃，没有下一个大的基准，整个社会都在背后支持和使用。嗯，你知道，对于这些网络的进一步发展。

Lex 02:05:52
是的。要怎样才能让数据集吸引所有人的想象力呢。比如他们都在背后支持它？这可能也需要像病毒一样的领导者，对吧。一个有知名度的人。我的意思是，是的。为什么这个形象会起飞？是有还是只是历史的偶然？

Andrej 02:06:10
它的难度适中。呃，它的难度和简单度都很合适，而且足够有趣。它只是有点像它是那种数据集的正确时间。

Lex 02:06:21
来自Reddit的问题。呃，你对合成数据和游戏引擎在未来神经网络模型开发中的作用有什么看法？

Andrej 02:06:31
我认为。嗯，随着神经网络向人类靠拢，呃，模拟对神经网络的价值将与模拟对人类的价值相似。因此，人们使用模拟是为了呃，人们使用模拟是因为他们可以在那种系统中学习一些东西。嗯，而且不需要实际体验。嗯、

Lex 02:06:52
但你指的是我们在头脑中进行的模拟。不是、

Andrej 02:06:56
对不起，模拟。我的意思是，像视频游戏或，你知道，嗯，其他形式的模拟，为各种专业人员。

Lex 02:07:03
所以让我来推敲一下，因为也许我们的脑子里有模拟。比如模拟如果我这样做。我认为会发生什么？

Andrej 02:07:12
好的。这就像内部模拟。

Lex 02:07:13
是的，内部。这不就是我们在行动之前所做的假设吗？

Andrej 02:07:17
是的，但这与模拟的使用是独立的，比如计算机游戏或使用模拟来创建训练集或

Lex 02:07:23
它是独立的还是松散的相关的？因为像做反事实或像教育者的模拟不是很有用吗，你知道，如果发生核战争会怎样？如果有，你知道，像那些种类的东西会发生什么？因为是的、

Andrej 02:07:42
那是一种不同于虚幻引擎的模拟。这就是我对这个问题的理解。

Lex 02:07:45
啊 那么像模拟一般的情况，这就是虚幻引擎吗？什么什么什么，你说的虚幻引擎是什么意思？那么模拟一个世界的物理学的那个世界？为什么会有这样的不同？比如说因为你也可以给那个世界添加行为，你可以尝试各种东西，对吗？就像你可以把各种奇怪的东西扔进去，而真正的引擎不仅仅是类似的东西。我的意思是我猜它是关于提交世界的物理学。它也在用它做一些事情。

Andrej 02:08:18
是的，图形、物理学和你放在环境中的代理之类的东西。

Lex 02:08:23
你看，我觉得你我觉得你说的对未来的ai发展不是那么重要，我想，这样理解是正确的吗？

Andrej 02:08:31
我认为人类使用模拟器是为了人类使用模拟器，他们发现它们很有用。所以计算机也会使用模拟器，并发现它们很有用。好的、

Lex 02:08:43
所以你是说，不是我我不经常使用模拟器。我每隔一段时间就会玩一次电子游戏，但我不认为我从，从那些电子游戏中获得了任何关于我自己存在的智慧？它是对现实的一时逃避，而不是关于智慧的来源。

Andrej 02:08:57
现实。所以

Lex 02:08:58
我不知道，所以我想这是一种非常礼貌的说法，即模拟并不那么有用。

Andrej 02:09:03
是的，也许。也许不是。我不认为它是目前训练神经网络的一个基本的、真正重要的部分。呃，但我认为随着神经网络变得越来越强大，我认为你将需要更少的例子来训练更多的行为。而且，呃，模拟当然有一个领域的差距，在一个模拟中，不是真实世界的东西稍微有点不同。但是，对于一个足够强大的神经网络，你需要嗯，领域差距可以更大，我认为，因为神经网络会理解，即使它不是现实世界，它就像有所有这些小结构，我应该像，学习。

Lex 02:09:35
因此，神经网络实际上，是的，我们将能够更好地利用合成数据，通过了解这在哪些方面不是真实数据来缩小差距。正是如此。对。为了下次做更好的问题。那是那是一个问题。但我只是在开玩笑。好的。嗯，那么是否有可能你认为说到大赦，构建神经网络和训练过程，需要非常少的数据。所以我们一直在谈论巨大的数据集，如国际培训。我的意思是，一种说法是像你说的那样，像水族馆本身作为另一个层次的训练，我猜，这需要一点数据，但你认为在做研究和那种方向上的任何价值，我们可以使用很少的数据来训练构建一个知识库？

Andrej 02:10:29
100%.我只是认为，在某些时候，你需要一个大规模的数据集，然后当你预先训练你的大规模神经螺母，并得到一些你知道它是像GPT或其他东西，那么你就能够非常有效地训练任何任意的新任务。因此，很多这些G.P.T.S你知道你可以做像情感分析或翻译之类的任务，只需用很少的例子来提示。这就是我想让你做的事情，比如这是一个输入句子，这是翻译成德语的输入句子，翻译成德语的输入句子是空白的，神经网络将通过查看你提供的例子来完成翻译成德语。因此，这是一个在神经网络的激活中而不是在神经网络的权重中进行少量学习的例子。所以我认为，基本上就像人类一样，神经元在学习任何其他新任务时都会变得非常高效，但在某些时候，你需要一个大规模的数据集来预先训练你的网络。

Lex 02:11:21
来得到这些。而我们人类可能也有这样的东西。我们有这样的东西吗？我们是否有一个被动的在背景中构建背景模型的东西，它一直以自我监督的方式运行？我们没有意识到这一点。

Andrej 02:11:37
我认为人类肯定是这样。我的意思是，很明显，我们在我们的寿命期间学到了很多东西，但我们也有大量的硬件帮助我们初始化，这来自于进化的排序。所以我认为这也是一个非常大的组成部分。该领域的很多人，我认为他们只是谈论像秒这样的数量，你知道那个人已经活过了，假装这是一种像神经螺母的零初始化。而这并不像你可以看很多动物，例如斑马，斑马出生后，他们可以看到，他们可以运行在他们的生命周期中的零训练数据。他们可以直接这样做。因此，不知何故，我不知道进化是如何找到一种方法来编码这些算法的。而这些神经网的初始化是非常好的成A.T.C.Gs，不知道这是如何工作的。但显然这是可能的，因为这里被存在所认可。

有

Lex 02:12:28
从一个单细胞到出生的有机体，再到生命的最初几年，有一些神奇的事情。我有点喜欢这样的想法：我们之所以对生命的最初几年没有任何记忆，是因为这是一个非常痛苦的过程。就像它是一个非常困难的、具有挑战性的训练过程，就像智力上的，也许。是的，我的意思是我不知道为什么我们不记得任何这些？可能有一些疯狂的训练，那也许就是背景模式的训练。那是非常痛苦的。因此，对系统来说，一旦它被训练好了，最好不要记得它是如何构建的。I

Andrej 02:13:11
我觉得这就像长期记忆的硬件还没有完全发展起来。我觉得婴儿的头几年其实并不像学习大脑那样

Lex 02:13:21
成熟

Andrej 02:13:22
嗯，是早产的。有一种理论是这样的，因为产道和大脑的肿胀，所以他们是早产儿，然后头几年只是大脑的成熟期，然后最终有一些学习。这是我目前对它的看法。

Lex 02:13:37
你怎么看？你认为能有长期记忆吗？我喜欢这种方法，就像人类一样。你认为，你认为是否需要在它上面有另一个元架构，以增加类似于知识库的东西，学习关于世界的事实和所有这些东西？

Andrej 02:13:54
是的，但我不知道它将在多大程度上被明确地构建。它可能采取直观的形式，你告诉GPT，比如，嘿，你有一个，你有一个陈述性的记忆库，你可以存储和检索数据，每当你遇到一些你认为有用的信息，就把它保存到你的记忆库中，这是你检索到的一个例子，这是你如何说的，这是你如何从它那里加载，你只是说加载任何你用英文文本教它，然后它可能学会从那里使用一个记忆库。哦、

Lex 02:14:26
所以，神经网络是背景模型的架构，是基础的东西，然后其他一切都只是在这个基础上。

Andrej 02:14:33
不仅仅是文字，对吗？而是你给了它一些小玩意和小发明。所以，呃，你在教一些特殊的语言，通过这些语言，我们可以，我们可以保存任意的信息，并在以后的时间里检索它，你，你在讲述特殊的标记和如何安排它们来使用这些接口。这就像，嘿，你可以使用一个计算器，这是你如何使用它。只要做53加41等于，当等于的时候，计算器就会实际读出答案，你不必自己计算，你只要用英语告诉它这可能真的有用、

Lex 02:15:02
你认为在这个意义上，Gado是有趣的。深思熟虑的系统，它不仅仅是语言，实际上是把它全部呃在同一堆中，图像、行动，所有这些东西，基本上是我们正在走向的。是的、

Andrej 02:15:18
我想是的。因此，Gatto是，是非常多的厨房水槽方法，像嗯强化学习很多不同的环境与一个固定的变压器模型。对。我认为这是在这一领域的一个非常早期的成果。但我认为是的，它是沿着我认为事情最终会出现的方向发展的。

Lex 02:15:37
对吗？因此，这是一个系统的早期，最终将看起来像这样。就像从一个富有的、富有的、突然的角度来看。

Andrej 02:15:43
我不是一个超级大的粉丝，我认为所有这些看起来非常不同的界面。嗯，我希望所有的东西都被规范化为相同的ap，例如，屏幕像素非常相同的api，而不是像不同的世界环境，有非常不同的物理学和关节配置和外观什么的，你有一些特殊的令牌给不同的游戏，你可以插入。我宁愿把所有东西都规范化为一个单一的界面。所以它对神经网络来说看起来是一样的，如果这有意义的话。所以它是

Lex 02:16:08
最后都会是基于像素的乒乓。

Andrej 02:16:11
我想是的，好的、

Lex 02:16:15
呃，让我问你一下你的个人生活。很多人都想知道你是ai历史上最有生产力和最杰出的人之一，安德烈-卡帕蒂生活中富有成效的一天是什么样子的。你什么时候起床？因为想象一下......在平均生产力的一天和完美生产力的一天之间的某种舞蹈。因此，完美的有成效的一天是我们努力追求的目标，而平均数则是在考虑到所有的错误和人类的偶然性等情况下的一种趋向。那么，你是什么时候起床的？像一个早晨的人吗？

Andrej 02:16:47
我不是一个早起的人，我肯定是一个夜猫子

Lex 02:16:50
它是否稳定、

Andrej 02:16:52
它是半稳定的，就像八或九或类似的东西。在我读博士期间，甚至更晚，我通常在凌晨三点睡觉，我认为上午的时间很宝贵，是非常有趣的工作时间，因为每个人都在睡觉，嗯，在早上八点或七点。东海岸是清醒的。所以已经有活动了，已经有一些短信，不管是什么，都有事情发生，你可以上一些新闻网站，在凌晨三点有事情发生，让人分心。所以我喜欢这些时间段，晚上都是默认的，然后我认为像生产性的时间，基本上嗯，我喜欢做的是你需要你需要像在问题上建立一些势头，没有太多的分心，嗯，你需要用这个问题加载你的RAM呃你的工作记忆，然后你需要在你洗澡的时候，在你睡着的时候对它着迷。你需要对这个问题着迷，它完全在你的记忆中，你已经准备好醒来并在那里工作。所以

Lex 02:17:52
它的规模是......呃，这是一个规模的时间尺度，是一天还是一个星期的几天？一个月。

Andrej 02:17:58
所以我不能孤立地谈一天，因为当我想在问题上取得成效时，这是一个完整的过程。我觉得我需要一个跨度为几天的时间，在那里我可以真正进入那个问题，我不想被打断，我只是要完全沉迷于那个问题，这就是我做的大部分好的锻炼的地方。

Lex 02:18:17
你在很短的时间内很迅速地做了一堆很酷的像小项目一样的事情，所以这就要求你只要专注于它。

Andrej 02:18:24
是的，基本上我需要用问题来加载我的工作记忆，而且我需要有成效，因为接近任何问题总是像一个巨大的固定成本。呃，你知道，比如说我在特斯拉的时候就在纠结这个问题，因为我想在小的副业上工作，但是好吧，你首先需要弄清楚好吧，我需要关联到我的集群，我需要调出一个V.S.代码编辑器，这样我就可以在这个上面工作。我需要我遇到一些愚蠢的错误，因为某些原因，就像你不在一个点上，你可以立即变得富有成效，你面临着障碍，所以它是关于真正消除所有的障碍，你能够进入问题，你有完整的问题加载在你的内存中。

Lex 02:18:58
并以某种方式避免各种不同形式的分心，如新闻报道、电子邮件，但也要避免分心于其他有趣的项目，即你以前所做的，目前正在做的等等。你只是想让自己的思想真正集中起来

Andrej 02:19:13
我的意思是，我可以抽出一些时间来分散注意力，在两者之间，但我认为不能太多，呃，你知道你一天的大部分时间都有点像花在这个问题上，然后你知道我喝咖啡，我有我的早晨例行工作。我看一些新闻微博，黑客新闻，华尔街日报等等，所以这很好。

Lex 02:19:30
所以基本上你醒来后，你喝了一些咖啡。你是想尽可能快地去工作吗？你是否采取这种饮食的方式，像世界上到底发生了什么？第一

Andrej 02:19:40
我是我确实觉得了解这个世界很有趣。我不知道这是否有用或好，但这是我现在日常工作的一部分。所以我确实阅读了一堆新闻文章，我想了解情况，嗯，我对它持怀疑态度。我对这种做法持怀疑态度，但目前我的情况就是这样。哦

Lex 02:19:56
你的意思是怀疑这种做法对你的生产力和你的健康的积极影响是

安德烈 02:20:02
我在心理上的健康和

Lex 02:20:04
也对你深入了解世界的能力有影响，因为有一堆的信息来源，你并没有真正专注于深入整合

Andrej 02:20:12
分散你的注意力呀、

Lex 02:20:14
在完美的生产日方面，有多长的时间 在一次会议上，你是否尝试工作并专注于这件事？有几个小时？有1小时30分钟，10分钟。

Andrej 02:20:27
我可能可以去像一个小的几个小时，然后我需要一些休息，在中间像食物和东西。是的，但我认为要积累时间还是很困难的。我在使用一个跟踪器，它能准确地告诉我一天花了多少时间在编码上，即使在一个非常有成效的日子里，我仍然只花了六或八个小时。是的，这只是因为有这么多的填充物，通勤时与人交谈，食物等等，就像生活的成本，只是生活和维持和平衡，只是维持自己作为一个人的成本是非常高的。

Lex 02:20:59
而且，在人类的头脑中似乎有一种参与社会的欲望，创造了这种模式，因为我是的，我有过的最有成效的日子就是完全从头到尾，只是调出一切，只是坐在那里，然后你可以做超过六个和八个小时，是否有一些关于什么给你力量做的智慧？比如呃艰难的日子，长时间的专注？

Andrej 02:21:24
是的，就像每当我为一个问题痴迷时，有些东西就是需要工作，有些东西就是需要存在。

Lex 02:21:28
它需要存在。因此，你能够处理错误、编程问题和技术问题，以及呃设计决定原来是错误的，你能够考虑到所有这些，鉴于你想认为存在、

Andrej 02:21:41
它需要存在。然后我认为对我来说，还有一个很大的因素是，你知道，我们的其他人类会欣赏它。他们会喜欢它吗？这是我动力的很大一部分，如果我在帮助人类，而他们看起来很高兴，他们说好话，他们在推特上谈论它或其他什么，这让我很高兴，因为我在做有用的事情。

Lex 02:21:57
那么像你看到自己与世界分享，像什么？在博客文章或视频方面得到帮助？

Andrej 02:22:03
是的，我在想，假设我做了所有这些事情，但没有分享它们。我不认为我会有同样多的动力，我可以建立起来。

Lex 02:22:09
你享受别人从你创造的东西中获得价值和快乐的感觉。饮食方面有什么？我看到你在玩间歇性禁食你禁食。这是否有助于

安德烈 02:22:23
一切

Lex 02:22:24
与你玩的东西？什么对，你在精神上专注于事情的能力最有利，只是精神上的生产力和快乐。你的速度仍然很快

Andrej 02:22:35
这么快。但我做的是间歇性禁食。但实际上，这意味着在一天结束的时候，我不吃早餐。所以我做呃18 6大致上是默认的，当我在我的稳定状态下，如果我在旅行或做其他事情，我将打破规则。但在我的稳定状态下，我做18 6，所以我只从12点到6点吃。这不是一个硬规则，我经常打破它，但这是我的默认规则。然后，嗯，是的，我已经做了一堆随机的实验，现在我已经在过去一年半的时间里，我想说的是嗯，以植物为基础或以植物为导向。我听到的是植物性前进。这听起来

Lex 02:23:05
更好。正是如此。I

安德烈 02:23:06
实际上不知道有什么区别，但在我的脑海中听起来更好，但它只是意味着我更喜欢以植物为基础的食物和呃

Lex 02:23:12
或煮熟的，我

Andrej 02:23:14
喜好熟食和植物

Lex 02:23:16
基于。所以是以植物为基础。请原谅我，我实际上不知道为什么植物的类别会涉及到

Andrej 02:23:24
只是意味着你没有

Lex 02:23:26
关于它

Andrej 02:23:27
而且你可以灵活运用，呃，你只是喜欢吃植物，你知道，你不是在做，你不是在试图影响其他人，如果有人，你来到某人的家庭聚会，他们为你提供了一份牛排，他们真的很自豪。你会吃它。这就是

Lex 02:23:40
只是没有判断力。这很好。我的意思是，那是嗯的反面，但我是非常灵活的那种。你有没有试过一天只吃一顿？

Andrej 02:23:48
我不小心有过，不是一贯的，但我不小心有过。我不，我不喜欢它。我觉得它让我感觉不舒服。它太，它太多了，太有冲击力了。所以目前我每天大约有两顿饭，12和6。

Lex 02:24:02
我不停地做这个。我正在做。一天没有一餐。这很有意思。这是一种有趣的感觉。你有过禁食超过一天的经历吗？

Andrej 02:24:10
是的，我已经做了一堆水禁食，因为我很好奇会发生什么。呃

Lex 02:24:14
有什么有趣的吗？是的、

Andrej 02:24:16
我想这么说。我是说，你知道有趣的是，你饿了两天，然后从第三天左右开始，你就不饿了。这就像是一种奇怪的感觉，因为你已经几天没吃东西了，而你却不饿。是

Lex 02:24:26
有那么奇怪吗？这确实是人类生物学的众多怪事之一。它想出了一些办法。它找到了，找到了另一种能量来源或类似的东西，或者放松了系统。我也不知道怎么

Andrej 02:24:38
身体是，比如你很饿，你很饿，然后它就放弃了。这就像，好吧，我想我们现在正在禁食。

Lex 02:24:42
没有什么

安德烈 02:24:43
然后它只是有点像专注于试图让你不饿，你知道不觉得那是一种伤害，并试图给你一些空间来弄清食物的情况。

Lex 02:24:53
那么，你是否到现在还能在以下方面取得最大的成效？

Andrej 02:24:57
晚上？我想说我是的，但要维持我的博士课程表真的很难，嗯，特别是当我在特斯拉工作的时候，这是一个不可能的事情，所以，但即使是现在，就像你知道的，人们想为各种活动见面，他们的社会生活在一定时间内，你必须喜欢这样的

Lex 02:25:15
很难像做社交活动那样，在做完之后再回来做工作。

Andrej 02:25:20
是的，这实在是太难了。

Lex 02:25:23
这就是为什么我试着当我做社交活动时，我尽量不做太多的酒，这样我就可以回来继续做工作。嗯，但是特斯拉，是否有是有收敛特斯拉，但是任何公司，是否有收敛他作为一个时间表，还是有更多的，人类在合作的时候是这样表现的吗？我需要了解一下这个。他们是否试图让我们保持一致的时间表？你们都在同一时间醒着？

Andrej 02:25:49
我要做的是努力创造一个常规，我试图创造一个稳定的状态，在其中我很舒服，所以我有一个早晨的常规。我有一天的常规。我试着把事情保持在一个稳定的状态，事情是可以预测的，然后你就可以像你的身体一样坚持下去，如果你试图强调这一点，就会产生呃，你知道当你在旅行时，你正在处理时差，你不能真正上升到，你知道你需要去的地方。

Lex 02:26:13
是的。是的。那就是人类的习惯和东西呢？你对人类一生中的工作生活平衡有什么看法？因此，测试部分以将人们推到他们的极限而闻名，即他们能够做什么，他们想做什么，他们工作多少，所有这些东西。

Andrej 02:26:34
是的，我的意思是我要说特斯拉还是有太多的不好的评价，因为现在的情况是特斯拉是一个它是一个爆棚的环境。所以我想说基线，我唯一的参考点是谷歌，比如我已经进入了三次，我看到谷歌和deepmind里面是什么样子。我想说的是，基线比这更高，但也有一个点状平衡，偶尔会有一场大火，有人像人们一样非常努力地工作，所以它是尖锐的和突发的，然后所有的故事都被收集起来。

Lex 02:27:02
和

安德烈 02:27:03
那么它给人的感觉就像完全的疯狂，但实际上它只是一个更激烈的环境，有火灾和短跑，所以我认为，你知道，它肯定虽然。我想说，嗯，这是一个更激烈的环境，而不是你会得到的东西。

Lex 02:27:16
你的人忘记所有这些，只是在你自己的个人生活中。嗯 你怎么看一个人的幸福，一个像你这样优秀的人关于在工作和生活之间找到一个平衡，或者是这样的事情？不是一个好的思想实验吗？

Andrej 02:27:35
是的，我认为，我认为平衡是好的，但我也喜欢有冲刺的时候，脱离了分配，那是我认为我已经很有呃创意了。还有嗯，也是、

凌志02:27:47
冲刺出的分布意味着大部分时间你有呃引用不引用的平衡、

Andrej 02:27:55
我大部分时间都很平衡。我喜欢偶尔迷恋一些东西、

Lex 02:27:59
偶尔一次, 一周一次, 一月一次, 一年一次.

Andrej 02:28:02
可能是每月一次或什么的。

Lex 02:28:03
是的。这时我们就会得到，你也会得到

Andrej 02:28:06
这就是当你真正关心一个问题的时候，它一定存在。这将是令人敬畏的。你对它很痴迷。而现在你不能只在那一天做这件事。你需要支付进入状态的固定成本，然后你需要在那里呆上一段时间，然后社会会来，他们会试图搞乱你，他们会试图分散你的注意力。是的。最糟糕的是像一个人说，我只需要你五分钟的时间。是的。这就是代价，这不是五分钟，社会需要改变它对你的五分钟的思考方式。

Lex 02:28:32
时间。对吗？它从来就不是，它从来就不是只有一分钟。它只是一个快速的什么是大的

安德烈 02:28:38
你是这么说的吗？

Lex 02:28:39
是的。不，你的电脑设置是什么？什么是最完美的。你是否也是一个很灵活的人，不管是什么笔记本，四个屏幕，还是你喜欢某种设置，你最有成效？

Andrej 02:28:56
嗯，我想我熟悉的是一个大屏幕27英寸的嗯和我的笔记本电脑在一边、

Lex 02:29:03
什么操作系统

安德烈 02:29:05
我做了最大的，这是我的主要

Lex 02:29:06
对于所有的任务

Andrej 02:29:08
我想说的是，是X。但当你在研究深度学习的时候，一切都像Linux一样，你的ssh进入一个集群，你在远程工作、

Lex 02:29:14
但实际的发展情况如何，比如他们在使用I.D.。

Andrej 02:29:17
你会使用我认为好的方法是你只是在你的Mac上运行V. S. Code um 我最喜欢的编辑器，但你实际上是你通过ssh有一个远程文件夹。嗯 所以你在其他地方的集群上操作的实际文件。

Lex 02:29:31
那么，什么是最好的I. D. V. S代码？还有什么人做？所以我用imax仍然呃它可能是很酷。我不知道它是否是最大的生产力。嗯 那么你在编辑器方面有什么建议？你工作了很多软件工程师，python的编辑器，c加加机器机器学习应用。

Andrej 02:29:54
我认为目前的答案是V.S.法典。目前我认为那是最好的。嗯I.D.它有大量的扩展。它有吉他，共同试点嗯呃整合，我认为这是非常有价值的。

Lex 02:30:06
你怎么看合作试点的整合？我实际上是呃，我得到了与是一个创造性的Python交谈了一堆，他喜欢co pilot。你喜欢用它做的程序很多。呃 你是否

Andrej 02:30:20
使用co pilot吗？我喜欢它，它对我来说是免费的，但我愿意为它付费。是的，我认为它非常好，我发现它的实用性并不高，我会说有一个学习曲线，你需要弄清楚什么时候它是有帮助的，什么时候要注意它的输出，什么时候它不会有帮助，你不应该注意它，因为如果你只是一直在读它的建议，这不是一个与它互动的好方法。但我认为我能够像塑造自己一样适应它。我发现它在复制粘贴和替换一些部分方面非常有帮助。所以我不知道什么时候模式是清晰的，它在完成模式方面真的很好，第二。有时它建议一个P，I是我不知道的。所以它它告诉你一些你不知道的事情。所以

Lex 02:30:58
而这是一个发现和

Andrej 02:30:59
这是一个机会，所以我永远不会把副驾驶的代码给，我几乎总是复制复制粘贴到谷歌搜索，你看到这个功能是做什么的，然后你就会想，哦，这实际上正是我需要的，谢谢你的副驾驶。所以你学到了一些东西

Lex 02:31:12
因此，它是搜索引擎的一部分，也许得到确切的语法正确，一旦你看到它。是的，这是很难的事情，就像一旦你看到它，你知道、

Andrej 02:31:22
正确。

Lex 02:31:23
你自己

Andrej 02:31:25
可以挣扎、

Lex 02:31:25
你可以有效地验证，但你不能有效地生成和

Andrej 02:31:29
co pilot真的，我是说它是它的自动驾驶仪，用于编程，对吗？而目前是做链接跟踪，这就像简单的复制粘贴，有时还建议，但随着时间的推移，它将变得越来越自主。因此，同样的事情将发挥出来，不只是编码，但实际上跨越许多，许多不同的事情，可能

Lex 02:31:45
编码是很重要的一项，对吗？编写程序。你如何看待这个问题的未来，发展程序合成？比如能够写出越来越复杂的程序，因为现在是人类监督的有趣方式，比如感觉过渡期会非常痛苦。

Andrej 02:32:05
我对它的心理模型是，将发生与自动驾驶相同的事情。所以目前做的是做一些简单的事情，最终我们会做自动驾驶，人们要干预的事情会越来越少

Lex 02:32:16
而且可以有像这样的测试机制，比如说如果它写了一个函数，而且这个函数看起来非常正确。但你怎么知道它是正确的，因为作为一个程序员，你就像越来越懒了，就像你的能力导致了像小错误一样，但我想这不会使小的

安德烈 02:32:34
它将它的共同试点将使关闭的一个微妙的错误。它已经对我这样做了。但是

Lex 02:32:39
你认为未来的系统会不会，或者是否真的偏离了一个其实是编程的一个基本挑战。

Andrej 02:32:46
在这种情况下，它不是根本的，我认为事情可以改进，但是是的，我认为人类必须监督。我对人们不监督出来的东西和发生的事情感到紧张，例如，我们所有系统中的bug的扩散。我对此感到紧张，但我认为在某些时候，可能会有一些其他的共同试点来寻找错误和类似的东西，因为会有更多的自动化。

Lex 02:33:07
人、

安德烈 02:33:09
它是

Lex 02:33:09
像一个程序、

安德烈 02:33:11
a co

Lex 02:33:11
生成编译器的试点，一个是做lint er一个是做像类型检查器、

安德烈 02:33:21
它是一个像GPT的委员会，有点像

Lex 02:33:24
然后他们会像委员会的经理一样，然后会有人说这需要一个新的版本。我们需要重新生成它。

Andrej 02:33:30
是的，有10个G.P.T.S.他们被转发，得到50个建议。另一个人看了看，挑了几个他们喜欢的bug，一个人看了看，觉得这可能是一个bug。他们被其他一些东西重新排名，然后一个最终的合奏GPT进来了。这就像好吧，鉴于你们告诉我的一切，这可能是下一个代币。你

Lex 02:33:47
知道的感觉是世界上的程序员数量一直在增长，而且增长得非常快。你认为有可能在这样的世界里，它实际上会趋于平缓，下降到像一个非常低的数字？因为那时你会做软件2.0编程。嗯，你会做这种生成的共同试点类型的系统，编程，但你不会做老式的软件一点哦编程。I

Andrej 02:34:13
目前不认为他们只是要取代人类程序员。嗯，我很犹豫说这样的话，因为

Lex 02:34:21
这将会被取代

Andrej 02:34:23
在五年内。

Lex 02:34:23
我知道这将会显示

安德烈 02:34:25
这样的

Lex 02:34:26
是我们的想法，因为我我同意你的看法，但我认为我们可能很

Andrej 02:34:30
惊讶

Lex 02:34:32
对吗？就像下一步是什么，你对我们的语言模型所处的位置有什么看法？比如说，你觉得现在是开始还是中间还是结束？

Andrej 02:34:41
开始？100%.我认为我心中的大问题是肯定的。GPT将能够相当好的编程能力，等等。你如何引导这个系统？你仍然必须提供一些指导，你实际上在寻找什么。因此，你如何引导它？你怎么说，你怎么跟它说话？你如何审计和验证所做的事情是正确的。以及你如何与之合作？这不仅仅是一个AI问题，也是一个ui ux问题。是的。

嗯 那么美丽的沃土，为V.S.代码加上加上这么多有趣的工作，你不只是不只是人类的编程了。这是惊人的。

Lex 02:35:15
是的。所以你在与系统互动，所以不只是一个提示，而是反复的提示，试图找出与系统的对话。实际上，我的意思是对我来说，与我正在编写的程序进行对话是超级令人兴奋的。

Andrej 02:35:29
是的，也许在某些时候你只是在和它对话。就像好吧，这就是我想做的事情，实际上是这个变量。也许它甚至不是那么低级的变量，但你

Lex 02:35:37
也可以想象一下，比如你能不能把这个翻译成C语言，再加上加上，然后再翻译成python。

Andrej 02:35:42
已经是一种存在

Lex 02:35:44
但只是喜欢把它作为程序经验的一部分来做。比如我想用C加加写这个函数，或者像你一样从不同的不同的程序中不断变化，因为有不同的语法，也许我想把这个转换为一种功能语言，所以像你作为一个程序员，正式成为多语言的人，来回跳舞。

安德烈 02:36:06
我认为它的用户体验仍然是很难考虑的，因为它不仅仅是在一个页面上写代码，你有一个完整的开发者环境，你有一堆硬件在上面。呃，你有一些环境变量，你有一些在Cron job中运行的脚本，就像有很多事情要做，比如与计算机一起工作，这些系统如何设置环境标志，如何在多台机器上工作，如何设置屏幕会话，如何使不同的过程自动化，就像所有这些如何工作，如何被人类审计等等，都是巨大的问题。这一刻

Lex 02:36:36
你已经建立了档案馆的理智，什么是档案馆，你希望看到的学术研究出版的未来是什么？

Andrej 02:36:45
所以，档案馆是这个预打印服务器。因此，如果你有一篇论文，你可以把它提交给期刊或会议发表，然后等待六个月，然后也许会得到一个通过或失败的决定，或者你可以直接上传到档案馆，然后人们可以在三分钟后发推特，然后每个人都看到它。每个人都能读到它，每个人都能以他们自己的方式从中获益。

Lex 02:37:04
而且你可以引用它，它有一个官方的外观。它给人的感觉就像一个出版过程一样。这感觉与你只是在博客上发表文章不同。

Andrej 02:37:13
哦，是的，我的意思是这是一篇论文，通常情况下，你会期望在档案上看到的东西的标准更高，而不是你在博客文章中看到的东西。

Lex 02:37:21
或文化创造的吧，因为你可能会主持一个相当蹩脚的修复档案。嗯 那么，这让你觉得，这让你对同行评审有什么感觉？所以由23位专家进行的严格的同行评审与社区的同行评审相比？对吗？正如它所写的

安德烈 02:37:41
基本上，我认为社区能够很好地在twitter上对事情进行同行评议，我想也许这只是与A.I.机器学习领域有关，但我觉得事情更容易被审计。嗯，验证可能比其他地方的验证更容易。因此，这有点像嗯，你可以把这些科学出版物看作是小的区块链，每个人都建立在彼此的工作上，并相互设置，你有点像A I，这有点像这个更快和宽松的区块链，但你有，而且任何一个单独的条目是非常非常便宜的，然后你有其他领域，也许这种模式没有那么多意义。因此，我认为在一个I中，至少事情是相当容易验证的，所以这就是为什么当人们上传论文时，他们是一个非常好的想法等等，人们可以在第二天尝试它，他们可以成为最终的仲裁者，判断它在他们的问题上是否有效，整个事情只是移动得明显快。因此，我觉得学术界仍然有一个地方，就像会议杂志的过程仍然有一个地方，但它有点像嗯，它落后于我认为，它是一个有点可能更高质量的过程，但它不是那种你会发现前沿工作的地方了。过去，当我开始读博士时，你去参加会议和期刊，讨论所有的最新研究，现在当你去参加会议或一般的会议时，没有人讨论任何东西，因为它已经像三代前的东西一样不相关。

Lex 02:39:03
这让我对像Deepmind这样的机构感到难过，他们仍然在自然界中发表文章，这些大的有声望的机构，我的意思是，我想这些大的场所所带来的声望仍然有价值，但结果是，他们会宣布一些突破性的表现，但要花一年的时间才能真正发表细节，我的意思是，这些细节如果立即发表，会激发社区朝着某些方向发展。

Andrej 02:39:30
让我们加快社区的其他部分，但我不知道这在多大程度上也是他们目标功能的一部分、

Lex 02:39:35
这倒是真的。所以，这不仅仅是威望的问题。一点点的延迟是呃，是部分的 是的、

Andrej 02:39:40
他们当然deepmind特别是一直嗯，在有稍高的质量的制度下工作，基本上是过程和延迟，并以这种方式发表这些论文。另一个

Lex 02:39:51
来自Reddit的问题，你是否或曾经遭受过冒名顶替综合症，作为Ai的主管。特斯拉，当你在斯坦福大学的时候，作为这个人，世界都把你看作是ai的专家，来教，教世界关于机器学习的知识。

Andrej 02:40:09
当我在五年后离开特斯拉的时候，我花了大量的时间在会议室。呃，你知道，在我加入特斯拉之初，我会阅读论文，我在写代码，然后我写的代码越来越少，我在读代码，然后我读的代码越来越少。所以这只是一个自然发生的过程，我想。呃，我肯定地说，在接近尾声的时候，那是它开始有点打击你的时候，你应该是一个专家。但实际上，真相的来源是人们在写吉他的代码，以及实际的，实际的代码本身，而你并不像以前那样熟悉这些。所以我想说，也许那里有一些像不安全感。

Lex 02:40:40
是的，这其实是很深刻的，很多不安全的因素与在计算机科学领域不写这样的代码有关，因为那是事实，那个代码

Andrej 02:40:49
是真理的来源，报纸和其他一切。这是一个高水平的总结。我不耶，只是一个高水平的总结。但在一天结束时，你必须阅读代码，不可能将所有的代码翻译成实际的，你知道的，纸张的形式。所以，当事情出来的时候，特别是当他们有源代码的时候，那是我最喜欢的地方。

Lex 02:41:06
去。所以就像我说的，你是有史以来最伟大的机器学习ai老师之一，从CS到31年底到今天，你会给初学者什么建议？对进入机器学习感兴趣、

Andrej 02:41:20
初学者往往专注于

Lex 02:41:22
像什么

安德烈 02:41:23
我认为重点应该是你做了多少。所以，我有点像这个一万小时概念的高层次信徒，你只需要挑选你可以花时间的事情，你关心的事情，你感兴趣的事情，你真的必须投入一万小时的工作。嗯，它甚至没有像你把它放在哪里那么重要，你会迭代，你会改进，你会浪费一些时间。我不知道是否有更好的方法，你需要投入一万个小时，但我认为这实际上真的很好，因为我觉得在一件事上成为专家有某种决定性的意义。如果你花一万个小时，你可以从字面上选择一个任意的东西。我认为，如果你花一万个小时的刻意努力和工作，你实际上会成为一个专家。所以我认为这有点像一个不错的想法。嗯，所以呃，基本上我会更关注你是否花了一万个小时？

Lex 02:42:10
那么，再想想什么样的机制能使你达到10000小时的可能性最大化？

Andrej 02:42:16
正是如此。其中

Lex 02:42:17
对于我们这些愚蠢的人类来说，可能意味着要养成每天都要做这件事的习惯。

Andrej 02:42:23
只要能帮助你。所以我确实认为在很大程度上是自己的心理问题。还有一件事，我认为对它的心理有帮助，就是很多时候人们把自己和别人在这方面进行比较，我认为是非常有害的。只有把自己和你从一段时间前比较，比如说一年前，你是不是比你一年前更好，这才是唯一的思考方式。我认为这样你就能看到自己的进步，而且很有动力。

我想说的是
我认为很多人在开始阶段，但实际上自始至终都会被选择所麻痹，比如我应该选择这条道路还是这条道路，比如他们真的会被麻痹，比如我应该使用哪条道路。那么

Andrej 02:43:06
他们很担心他们担心所有这些事情。但问题是有些你会浪费时间做错事，你最终会发现这是不对的，你会积累疤痕组织，下一次你会变得更强大，因为下一次你会有疤痕组织，下一次你会从中学习，现在下一次你来到类似的情况下，你会像哦我我搞砸了，我已经花了很多时间在工作上，但从未实现任何东西，我有所有这些疤痕组织，我有一些直觉，什么是有用的是没用的事情结果如何。所以所有这些错误都不是工作，你知道吗？所以我只是认为你应该专注于工作，你做了什么，你上周做了什么？

Lex 02:43:43
这是一个很好的问题，不只是机器学习，其实很多事情都可以问。这是一个很好的方法来削减，我忘了我们用的是什么术语，但是绒毛、脂肪，不管是什么，生活中的低效率。你喜欢教书的什么，你似乎发现自己经常被吸引到教学中。你很擅长这个，但你也是

Andrej 02:44:06
被它所吸引。我的意思是我不认为我喜欢教学，我喜欢快乐的人类

Lex 02:44:11
和

Andrej 02:44:11
快乐的人类。就像我教书时一样、

Lex 02:44:13
I

安德烈 02:44:14
我不会说我讨厌教书，我容忍教书，但我不喜欢教书的行为。它是，嗯，你知道我有一些我有一些东西，我实际上在这方面还不错。我在教学方面还行，人们很欣赏我。因此，我很高兴能够尝试提供帮助，而教学本身并不是最重要的。我的意思是，它真的可以是非常恼人的令人沮丧的。我刚才在做一堆的讲座。我被提醒回到我的231岁的日子，以及创造一些这样的材料并使之成为好的材料有多大的工作量。迭代和思考的数量，以及你走过的盲道和你改变它的程度。因此，创造好的东西。就教育价值而言，这真的很难，而且不好玩。它是

Lex 02:44:55
困难。所以人们肯定应该去看你推出的新东西。有一些讲座，你实际上是在建造这个东西，就像你说的代码是真理一样。因此，通过构建它来讨论反向传播，通过查看和只是整个事情。因此，这有多难准备。我认为这是一个非常强大的教学方式。你是怎么准备的，还是你只是现场思考了一下？

安德烈 02:45:18
我通常会先做三遍，然后再选取较好的一段。因此，我做了多次拍摄，并采取了一些较好的拍摄，然后我就以这种方式建立了一个讲座。有时我不得不删除30分钟的内容，因为它只是进入了一个我不太喜欢的小巷。大约有一堆迭代，可能需要我，你知道，大约10个小时来创造一个小时的内容。

Lex 02:45:37
要给一小时。这很有意思。我的意思是，回归到，比如，基础知识，是不是很难？你是否从返璞归真中汲取了很多，比如，智慧？

Andrej 02:45:45
是的。回到反向传播的损失函数的来源。说实话，我很喜欢教书的一件事，就是它肯定会加强你的理解。所以这不是一个纯粹的利他主义活动。这是一种学习的方式，如果你必须向别人解释一些东西，呃，你会意识到你在知识上有差距。因此，在那些讲座中我甚至让自己感到惊讶，比如，结果显然也会是这样的，然后结果却不是这样的。我就想，好吧，我以为我理解了这个，但这就是为什么

Lex 02:46:13
从字面上看，编码真的很酷。你在笔记本上运行它，它给你一个结果，你会觉得，哦，哇，像实际的数字，实际的输入，你知道，实际的代码、

Andrej 02:46:23
它不是数学符号，等等。真理的来源是代码。它不是幻灯片，它只是像，让我们建立

Lex 02:46:29
在这个意义上，你是一个罕见的人。对于试图开发和发表在世界范围内有很大影响的想法的研究人员，你有什么建议，所以也许嗯本科生，也许早期研究生。

Andrej 02:46:46
我的意思是，我想说的是，他们肯定要比我作为一个博士生更有战略眼光，因为我的发展方式是这样的。它正在以物理学的方式发展，你知道，在物理学中，你曾经能够在你的台面上做实验，一切都很好，你可以取得进展，现在你必须在LHC或Cern工作，所以ai也在朝这个方向发展。嗯，所以有某些种类的东西，只是不可能再在台式机上做。而且，我认为当时并不是这样的情况。做

Lex 02:47:16
你仍然认为有像甘式的论文要写，是像，像非常简单的想法，只需要一台电脑来说明一个简单的例子。

Andrej 02:47:28
我的意思是，最近很有影响的一个例子是扩散模型。融合模型很了不起。融合模型已经有六年的历史了，时间最长。据我所知，人们有点忽视他们，他们是一个惊人的生成模型，特别是在图像和如此稳定的扩散等等。这都是基于扩散的。融合是新的，它不存在，来自于，嗯，来自于谷歌，但一个研究人员可以想出它。事实上，最早的一些实际上，不，那些也是来自谷歌。但是一个研究人员可以在学术机构中想出这个办法。

Lex 02:47:58
是的。你觉得扩散模型中最吸引人的是什么？所以从技术架构的社会影响来看、

安德烈 02:48:06
我喜欢融合的原因是它的效果非常好。

Lex 02:48:08
这对你来说很惊讶吗？合成数据所产生的品种数量几乎是新奇的？

Andrej 02:48:16
是的，所以稳定的扩散图像是不可思议的。它在生成图像方面的改进速度是惊人的。呃，我们很快就从生成微小的数字到微小的面孔，而且看起来都很混乱。而现在你是稳定的扩散。这发生得非常快。学术界仍然可以做出很多贡献，你知道，例如，嗯，Flash注意力是一个非常有效的上校，用于运行来自学术环境的变压器内的注意力操作。这是一个非常聪明的结构化上校的方式。呃，那是计算，所以它没有把注意力矩阵具体化。嗯，所以有我认为仍然像很多东西可以贡献，但你必须是只是更多的战略。做

Lex 02:48:54
你认为神经网络可以被用来推理吗？

Andrej 02:48:57
呃，是的。做

Lex 02:48:59
你认为他们已经有了理由。

Andrej 02:49:01
什么是

Lex 02:49:02
你对推理的定义？

Andrej 02:49:03
呃，信息处理。

Lex 02:49:08
所以以人类思考问题的方式，提出新奇的想法，感觉是推理。因此，新奇，我不想说，但在分配想法中，你认为这是可能的？

Andrej 02:49:26
是的。而且我认为我们已经看到，在当前你能够在某种意义上将训练集的信息重新混合成真正的概括。

Lex 02:49:34
这并没有出现，它并没有出现在in

Andrej 02:49:37
训练集。就像你在做一些有趣的事情，算法李，你在操作，你知道，一些符号，你在一个新的环境中想出了一些正确的一个独特的癌症。

Lex 02:49:48
什么会

Andrej 02:49:49
呃

Lex 02:49:50
对你来说，说明了什么？神圣的船？这东西绝对是在思考

Andrej 02:49:54
在我看来，思考或推理只是信息处理和概括。而且我认为今天的神经网络已经做到了这一点。

Lex 02:50:01
因此，能够感知世界或感知任何输入，并在此基础上进行预测或在此基础上采取行动。这就是那个原因

Andrej 02:50:12
你在新的环境中给出了正确的答案。通过操纵信息，你已经学会了正确的算法，你不是在做某种查询表，也不是在做邻居搜索之类的事情。

Lex 02:50:23
我想问一下A. G. I.让我问你关于A.G.I.的问题，你认为有哪些 "登月 "的想法可能会使A.G.I.取得重大进展，也许在其他方面，我们现在缺少的大障碍是什么。那么

安德烈 02:50:36
基本上，我相当看好我们建立G.I.S.Uh的能力，基本上是自动化系统，我们可以与之互动，而且非常像人类，我们可以在数字领域或物理领域与他们互动。目前看来，大多数做这些神奇任务的模型都是在文本领域。我认为，正如我提到的，我怀疑文本领域不足以真正建立对世界的全面理解。我确实认为你需要进入像素，了解物理世界和它的运作方式。所以我确实认为我们需要扩展这些模型，以消费图像和视频，并以这种方式在更多的多模态的数据上进行训练。你是否

Lex 02:51:16
你认为你需要接触世界才能了解它？嗯，那是

安德烈 02:51:18
我想说的是，如果你还需要体现和与世界互动的能力，并进行实验，拥有这种形式的数据，那么你就需要去找乐观主义者。

Lex 02:51:30
或其他

Andrej 02:51:31
这样的。所以我想说乐观主义者在某种程度上就像一个对冲。在A. G. I.中，因为在我看来，有可能仅仅拥有互联网上的数据并不是

Lex 02:51:43
够了，如果

安德烈 02:51:44
因为乐观主义者对我来说，没有什么比乐观主义者更重要的了，你有这样的人形因素，实际上可以在这个世界上做一些事情，你可以有数以百万计的人与人类互动，等等。如果这还不能产生一个G.I.，那么我不确定什么能产生。因此，从完整性的角度来看，我认为这是一个非常好的平台，但这是一个更难的平台，因为你是在处理原子，你需要真正像建造这些东西并将它们融入社会。所以我认为这条道路需要更长的时间、

Lex 02:52:18
但它是

Andrej 02:52:18
更加确定。然后有一个互联网的路径，就像训练这些压缩模型，有效地试图压缩所有的互联网。而这也可能给这些代理以及压缩

Lex 02:52:32
互联网，但也与互联网互动，所以对我来说，这并不明显。事实上，我怀疑你可以在不进入物理世界的情况下达到A.G.I.，这有点让人担心，因为这可能导致它发生得更快。所以它只是感觉我们就像在沸水中，我们不会知道它的发生。I

安德烈 02:52:58
想

Lex 02:52:59
我不害怕G，我我很兴奋，总是有顾虑，但我想知道它何时发生。

Andrej 02:53:07
是的。

Lex 02:53:08
并有关于它何时发生的暗示，比如一年后，它会发生，诸如此类的事情。是的，我只是觉得在数字领域，它只是可能发生。

安德烈 02:53:16
是的，我认为我们所拥有的一切，因为没有人建立了A G. I.，所以我们所拥有的是呃，是否有足够的外围儿童地面，我会说是的，我们有迄今为止的进展，这已经非常迅速，并且有下一步可供选择。所以我会说是的，我们很可能会与数字实体进行互动。

Lex 02:53:37
你怎么会知道有人在

Andrej 02:53:40
这将是一个缓慢的，我认为这将是一个缓慢的渐进的过渡，将是基于产品的，专注的，将是一个顶级的副驾驶。越来越好，然后GPT在帮助你，然后这些神谕，你可以去解决数学问题。我认为我们即将能够向这些神谕者提出非常复杂的化学和物理数学问题，并让他们提供完整的解决方案。

Lex 02:54:03
因此，A G. I.的使用主要集中在智力上。所以意识并没有进入到其中。

Andrej 02:54:11
所以在我看来，意识并不是一个特殊的东西，你会你会想出并栓上。我认为它是一个足够大、足够复杂的生成模型的一种突发现象，所以，嗯，如果你有一个复杂的世界模型，它能理解这个世界，那么它也能理解它在这个世界上的困境是一个语言模型，这对我来说是一种意识或自我意识的形式。而且

Lex 02:54:35
所以为了深入了解这个世界，你可能必须把自己融入这个世界，为了与人类和其他生命体互动。意识是一个非常有用的

Andrej 02:54:45
工具。我认为意识就像一个建模的洞察力

Lex 02:54:49
建模的洞察力。

Andrej 02:54:50
是的，这是一个你有一个足够强大的理解世界的模型，你实际上理解，你是其中的一个实体。是的、

Lex 02:54:57
但也有这个......也许只是我们告诉自己的叙事，有一个它感觉像体验世界的东西，意识的硬问题，但这可能只是我们告诉自己的一个叙事。

Andrej 02:55:08
是的，我不认为，是的，我认为它会出现的。我认为这将是非常无聊的事情，比如我们会和这些数字眼睛交谈，他们会声称自己有意识，他们会出现有意识，他们会做所有你期望其他人类做的事情。而这将只是一个僵局。我认为会有

我想说的是
很多实际的迷人的伦理问题，如最高法院级别的问题，即是否允许你关闭一个有意识的AI，如果允许你建立一个有意识的AI，也许必须有同样的基础，你有围绕嗯，对不起，提出一个政治话题，但是，你知道，堕胎，这是堕胎的深层问题是什么是生命。而ai的深层问题也是什么是生命，什么是意识，我认为这将是非常迷人的话题。建立能够达到这样的智能水平的系统可能会成为非法的，因为意识会出现，因此受苦的能力会出现。还有一些系统会说，不，请不要杀我。

Andrej 02:56:19
这就是lambda计算的lambda聊天机器人已经告诉这个google工程师的事情，对吗？就像它在说不想死之类的。

Lex 02:56:28
因此，这样做可能会成为非法行为，对吗？因为不然的话，你可能会有很多，很多不想死的生物，他们就会

安德烈 02:56:39
在集群上生成无穷大的它们。

Lex 02:56:42
然后这可能会导致像可怕的后果，因为那时可能会有很多人暗地里喜欢谋杀，他们会在这些系统中开始实施谋杀。我的意思是，这只是为了

安德烈 02:56:52
我所有的这些

Lex 02:56:53
东西只是给人类状况带来了一面美丽的镜子，人性会得到探索。这就是最高法院所有不同的辩论中，我们对人类意味着什么的想法最好的东西。我们可以问那些我们在整个人类历史上一直在问的深刻问题。在人类历史上，一直存在着另一种情况。呃，我们是好人，那是坏人。而我们将，你知道，在整个人类历史上，让我们谋杀坏人。而同样的情况可能会发生在机器人身上，它们一开始会是另一个人，然后我们就会去问问题。活着是什么意思？有意识是什么意思？

Andrej 02:57:30
而且我认为即使是我们今天的情况，也有一些金丝雀在煤矿中。嗯，呃，你知道，比如说这些有这些像Y的食物，你可以像工作，有些人试图像这个公司要关闭，但这个人真的像爱他们的妻子。哦，像它试图像把它放在别的地方，像它不可能。我认为人们肯定会对这些系统有感情，因为在某种意义上，它们就像人类的一面镜子，因为它们就像人类的一个大的平均数，它是经过训练的。

Lex 02:58:02
但我们可以，我们可以真正观看它的平均水平。因此，能够与人类的大平均值互动，并对其进行搜索查询，这很好。

Andrej 02:58:10
是的，这是非常迷人的。当然，我们也可以像塑造它一样。它不只是一个纯粹的平均值。我们可以搞乱训练数据，我们可以搞乱目标，我们可以以各种方式找到它们。因此，我们有一些嗯，你知道，对这些系统看起来像什么的影响

Lex 02:58:26
如果你想实现G.I.Um，你可以和她进行对话，问她谈什么。也许问她一个问题。你会问什么样的东西？

Andrej 02:58:37
我心中会有一些实际的问题，比如呃我或我的亲人真的必须要死吗？我们能做什么呢？

Lex 02:58:46
你认为它能清楚地回答，还是会诗意地回答？

Andrej 02:58:51
我希望它能给出解决方案。我希望它能像这样，我读过所有这些教科书，我知道你所做的所有这些事情，在我看来，这是我认为接下来应该进行的实验，这里有一些我认为会有帮助的基因疗法，呃，这里是你应该进行的各种实验。

Lex 02:59:05
好吧，让我们去做这个思想实验。好吧，想象一下，死亡实际上是呃，就像幸福的先决条件。所以如果我们成为不死之身，实际上会变得非常不快乐，而且模型能够知道这一点。那么，这应该告诉你这个愚蠢的人类什么呢？是的，你可以成为不朽，但你会变得非常不快乐，如果模型是如果A.G.I.系统试图与你这个人类产生共鸣，它应该告诉你什么？是的，你不必死，但你真的不会喜欢它是，它将是深深的诚实？像有一个星际，什么是艾说像人类要90%的诚实，所以像你要选我要多诚实来回答这些实际问题。

Andrej 02:59:55
顺便说一句，我喜欢《星际》，我觉得它就像整个故事的一个小伙伴，但

Lex 03:00:01
在

Andrej 03:00:02
同时，它就像真的很有趣。这是种

Lex 03:00:03
在某些方面是有限的，对吗？

Andrej 03:00:05
是的，它是有限的，而且我认为这完全没有问题，我不认为，呃，我认为有限的和不完善的A G. I. S.是可以的，而且是合理的。

Lex 03:00:15
这个功能是不是几乎和

Andrej 03:00:17
一个例子，像它的物理体上有一个固定的计算量，它可能只是，即使你可以有一个超级惊人的巨型大脑，超级智能。艾也可以有像你知道的不太聪明的艾，所以你可以以一种高效的方式部署，然后他们并不完美，他们可能会犯错误。

Lex 03:00:35
不，我的意思更像是说你有无限的计算能力，而且有时犯错也是好事。比如为了整合自己？比如说

Andrej 03:00:43
嗯，什么

Lex 03:00:45
是要回到好的威尔狩猎罗宾-威廉斯的角色说像人类的不完美，那是好的东西，对吗？不是吗？不是吗？我们不希望完美，我们希望有缺陷。

Andrej 03:00:58
部分

Lex 03:00:59
两者之间形成联系，因为它感觉是你可以附加到你的感情上的东西，缺陷也是如此，你希望ai是有缺陷的，我不知道，我感觉是一个完美主义者。

Andrej 03:01:11
但你又说好的

Lex 03:01:13
但这不是一个G I C A G。我需要有足够的智慧来给人类提供人类不理解的答案。而我认为完美不是人类无法理解的东西，因为即使是科学也不会给出完美的答案。总是有差距和谜团，我不知道。我不知道人类是否想要完美。

Andrej 03:01:33
是的，我可以想象就像你想象的那样与这种神谕实体进行对话。是的，也许它能告诉你关于你知道的基于我对人类状况的分析。呃，你可能不想要这个，这里有一些可能的东西，但

Lex 03:01:49
每一个愚蠢的人都会说，是的，相信我，我可以给我真相。我可以处理它。

Andrej 03:01:55
但这就是美，比如人们可以选择。所以，但是

Lex 03:01:58
那么我想

Andrej 03:02:01
的

Lex 03:02:01
和孩子们的老棉花糖测试等等。我觉得有太多的人喜欢我不能处理真相。可能包括我自己，像人类的深层真相。我不我不知道我是否能处理它。就像如果有一些黑暗的，如果我们是一个外星科学实验，它意识到，如果它有我

Andrej 03:02:21
我的意思是，这就是矩阵。你知道的一切都在重新开始。

Lex 03:02:26
我不知道，我会谈论什么？我甚至不知道，我

Andrej 03:02:32
我可能会

Lex 03:02:33
一开始，我选择了比较安全的科学问题，这些问题与我个人的生活无关，就像关于物理学和其他方面的问题。

Andrej 03:02:42
上。

Lex 03:02:43
呃，要建立像让我们看看那是什么地方，或者也许看看它是否有幽默感。这是另一个问题。如果它对人类有深入的了解，它是否能够推测出，它是否能够产生呃

Andrej 03:02:57
是的，到

Lex 03:02:57
产生幽默感。

Andrej 03:02:58
是的，我认为这实际上是一个美妙的基准几乎。就像它是否能够，我认为这是一个非常好的观点，基本上

Lex 03:03:04
逗你笑

Andrej 03:03:06
如果它能够像一个非常有效的站立式喜剧演员，正在做一些非常有趣的计算，我认为搞笑是非常困难的。

Lex 03:03:12
是的、

Andrej 03:03:14
因为

Lex 03:03:15
在某种程度上，它很难，就像巡回演出的测试。巡演测试的原意是很难的，因为你必须说服人类，没有什么，这就是为什么喜剧演员会谈论这个。像有这是深深的诚实，因为如果人们忍不住笑，如果他们不笑，这意味着你不有趣，他们笑。这很有趣

Andrej 03:03:36
和你显示你需要大量的知识来创造创造关于像职业、人类状况等等的幽默。然后你需要巧妙地运用它。

Lex 03:03:44
你提到了几部电影，你在推特上提到了我已经看过五次以上的电影，但我准备并愿意继续看《星际斗士》，《接触好会猎》《黑客帝国》《指环王》所有三部《阿凡达》，《第五元素》等等，它继续使

Andrej 03:04:00
它到

Lex 03:04:00
我和女孩。我不打算问

Andrej 03:04:02
关于

Lex 03:04:04
很好

Andrej 03:04:05
嗯

Lex 03:04:07
有哪些跳到你记忆中的东西是你喜欢的，为什么？就像你提到的《黑客帝国》，作为一个电脑人。你为什么喜欢《黑客帝国》？

Andrej 03:04:18
有这么多的属性，使它像美丽有趣。因此，有所有这些哲学问题，但也有一个G.I.S，有模拟，这很酷，还有你知道的黑色你知道的。

Lex 03:04:29
它的外观，它的感觉

安德烈 03:04:31
它的感觉，它的动作，它的子弹时间。这就像在许多方面进行了创新

Lex 03:04:37
然后呃好的意愿好的意愿狩猎。你喜欢那个吗？是的

安德烈 03:04:41
我只是我真的很喜欢这个......受折磨的天才一类的人物，他就像在努力解决他是否有任何责任，或者像如何处理他被赋予的这个礼物，或者像如何思考整个事情，呃

Lex 03:04:55
天才和个人之间也有一种舞蹈，比如说爱另一个人意味着什么，以及爱一个人意味着什么。

Andrej 03:05:01
那里有很多东西，它只是一部美丽的电影

莱克斯03:05:03
然后是父亲的形象，导师的形象，心理医生的形象。

安德烈 03:05:08
就像真的一样... ...它扰乱了你... ...你知道有一些电影就像真的扰乱了你... ...在一个很深的层次上

Lex 03:05:14
你和那部电影有什么关系吗？

Andrej 03:05:16
不

Lex 03:05:18
这不是你的错。正如我所说的，《指环王》。那是不言自明的终结者2。这很有趣。你呢？我经常看那个。那比终结者1好吗？你喜欢吗？你喜欢我

Andrej 03:05:30
我也喜欢终结者1。呃，我更喜欢终结者2，但就像它的表面特性而言

Lex 03:05:39
你认为中国有可能吗？

Andrej 03:05:41
是的。

Lex 03:05:43
就像实际的那种自主武器系统的东西。你担心这些东西吗？

Andrej 03:05:51
正在使用

Lex 03:05:51
为了战争？

Andrej 03:05:53
100%的担心。所以我的意思是，你知道这些对A. Gs的一些恐惧，以及这将如何计划。我的意思是，这将是一个非常强大的实体，可能在某些时候。因此，在很长一段时间内，它们将成为人类手中的工具。你知道人们谈论像对齐A.G.I.S.和如何使问题是像甚至人类都没有对齐。因此，这将被如何使用，以及这将是什么样子，是嗯是令人不安的。所以

Lex 03:06:17
你认为它会缓慢地发生，以至于我们能够作为一个人类文明的一部分？想一想这些问题

Andrej 03:06:25
是的，我希望它发生得足够慢，而且是以一种足够开放的方式，让很多人都能看到并参与其中。我想，只要弄清楚如何处理这种过渡，这将是很有趣的。I

Lex 03:06:36
从核武器中汲取了很多灵感，因为我肯定认为一旦他们发展出核武器，就会完蛋。但是，就像它几乎像呃呃当系统不是那么危险的时候，他们摧毁了人类文明，我们部署它们并吸取教训，然后我们很快，如果它太危险了，我们很快我们可能仍然部署，但非常迅速地学会不使用它们。所以他们会像这样的平衡实现。人类作为一个物种是非常聪明的。有趣的是，我们尽可能多地开发资源，但我们不，我们避免破坏自己。好像是这样、

Andrej 03:07:12
嗯，我不知道，实际上。

Lex 03:07:14
我希望它继续下去。

安德烈 03:07:15
嗯

Lex 03:07:17
I

Andrej 03:07:17
我的意思是，我绝对关注核武器等问题，不仅仅是由于最近的冲突，甚至在此之前，这可能是我对人类的首要关注。

Lex 03:07:27
因此，如果人类自我毁灭或毁灭，你知道，90%的人，那将是由于核弹。I

Andrej 03:07:36
认为是的。呃......这甚至不是全面破坏。对我来说，如果我们重置社会，那就够糟糕的了，这就像可怕的。这将是非常糟糕的。而且我不相信我们离它这么近。

Lex 03:07:47
这就像

Andrej 03:07:47
对我来说太疯狂了。它

Lex 03:07:48
感觉我们可能离这样的事情还有几条推特。是的、

Andrej 03:07:52
基本上它是非常令人不安的，但对我来说已经有很长一段时间了。

Lex 03:07:57
世界各国领导人只要心情不好，就会像嗯一样朝着坏的方向迈出一步，并且由于坏心情的集合而升级，这似乎是不稳定的。它可以升级而无法停止。

Andrej 03:08:18
是的，这只是一个巨大的权力量。然后还随着扩散，基本上我没有看到，我实际上不知道这里的好结果是什么。所以我肯定对它担心得很。然后一个吉是目前不存在的。但我认为在某种程度上会越来越多的

Lex 03:08:34
变成什么

Andrej 03:08:36
喜欢它。A-G-I的危险之处在于，我认为它甚至像稍微糟糕的意义上说，呃，A-G-I有好的结果，然后坏的结果就像一个epsilon的距离，就像一个小小的跑道。所以我认为，资本主义和人类等等将推动使用该技术的积极方式。但是，如果坏的结果只是像一个微小的像翻转的减号一样的距离。那是一个非常糟糕的位置。

Lex 03:09:01
系统的微小扰动就会导致人类的毁灭。这条线走得很奇怪。是的。

Andrej 03:09:09
我认为总的来说，这真的很奇怪，就像我们谈到的这个爆炸中的人类动态一样，只是像疯狂的耦合所承受的

Lex 03:09:15
技术和

Andrej 03:09:17
只是整个动态系统的不稳定性。我认为，说实话，它只是看起来不怎么好。

Lex 03:09:22
是的，这种爆炸可能是破坏性的，也可能是建设性的，而且这两种情况的概率都不为零。我是

Andrej 03:09:28
要我确实感觉到我必须努力保持乐观，等等。而且我觉得即使在这种情况下，我仍然是以乐观为主，但肯定有

Lex 03:09:37
我也是。你认为会成为一个多星球的物种吗？

Andrej 03:09:42
可能，是的，但我不知道它是否是呃未来人类的一个主要特征。呃，在一些星球上可能会有一些人，等等，但我不确定它是否像，是的，它像是我们文化中的一个主要角色，等等。我们

Lex 03:09:55
还是要解决地球上的自我毁灭的驱动力。所以仅仅在MARS上有一个备份是不能解决问题的。

Andrej 03:10:03
所以顺便说一句，我喜欢MARS上的备份，我认为这很了不起。我们绝对应该这样做。我非常感谢你。

Lex 03:10:09
呃，你会去火星吗？

Andrej 03:10:12
我个人呢？不，我确实很喜欢地球。我将

Lex 03:10:15
去MARS吧，我会去的

Andrej 03:10:16
你。我将

Lex 03:10:17
在推特上向您介绍

Andrej 03:10:18
也许最终我会，一旦它足够安全，但我实际上不知道它是否在我的有生之年，除非我可以把它延长很多。我确实认为，例如，很多人可能会消失在虚拟现实和类似的东西中，我认为这可能是人类文化发展的主要推力，如果它能幸存下来的话。因此，它可能不是，只是在物理领域工作和走出去真的很难，我认为最终你的所有经验都在你的大脑中，所以消失在数字领域要容易得多。我认为人们会发现它们更有说服力，更容易、更安全、更有趣。

Lex 03:10:54
所以你有点被虚拟现实的可能世界所吸引，不管是metaverse还是其他一些表现形式的

Andrej 03:11:00
那。

Lex 03:11:01
是的，这真的很有趣。这是呃，我很感兴趣，只是和卡马克谈了很多，目前阻止这一点的东西在哪里？

Andrej 03:11:13
是的，我的意思是说清楚，我认为关于未来的有趣之处在于，嗯，并不是说我有点觉得人类状况的方差在增长，那是正在变化的主要事情。它不像分布的平均值那么多，而是像它的方差。因此，可能会有人在MARS上，也会有人在VR中，还有人在地球上，就像会有这么多的存在方式。所以我觉得我把它看作是一种人类经验的扩散。

Lex 03:11:38
互联网有一些东西可以让你发现那些小团体，他们对你的生物学的一些东西有吸引力，喜欢那种你找到对方的世界。

安德烈03:11:46
我们会有反人类主义者，然后我们会有阿米什人，他们会，一切都会共存。

Lex 03:11:51
最酷的事情是，因为我和一堆互联网社区互动，嗯，他们不知道对方的情况。就像你可以有一个非常快乐的存在，就像有一个非常紧密的社区，而不知道对方的情况。即使你没有感觉到这一点，只是去了乌克兰旅行。有，他们不知道这么多关于美国的事情，你就像你在世界各地旅行时一样，我想你也经历过这个。有一些文化，他们就像他们有自己的东西。他们没有，所以你可以看到这种情况在未来会越来越多，越来越多。我们有小的社区。

Andrej 03:12:25
是的。是的，我想是的，这似乎是，这似乎是现在的情况，我没有看到这种趋势像真的逆转。我认为人们是多样化的，他们能够选择自己的生存道路。我有点喜欢庆祝这一点。嗯，所以

Lex 03:12:39
我们花了这么多时间在虚拟现实的metaverse，或者说你是哪个社区的，你是物理的还是物理现实的？

Andrej 03:12:49
享受或或

Lex 03:12:51
你是否看到在数字世界中汲取了很多乐趣和成就感。

Andrej 03:12:57
是的，我认为目前的虚拟现实并不那么引人注目。

Lex 03:13:00
我做

Andrej 03:13:01
我认为它可以改善很多，但我真的不知道到什么程度，也许你知道，实际上你可以考虑更多奇特的东西，如神经链接或类似的东西。所以，嗯，目前我认为自己主要是一个团队人类的人。我爱自然，我爱和谐，我爱人们，我爱人类，我爱人类的情感。我只想在这个像太阳能朋克的小乌托邦里，那是我的快乐。

Lex 03:13:27
地方。我的

Andrej 03:13:28
快乐的地方就像人一样，我喜欢思考一些很酷的问题，周围是郁郁葱葱的、美丽的动态大自然，在一些有意义的地方秘密地使用高科技

Lex 03:13:38
使用技术来增强对其他人类和自然的爱的地方。是的、

Andrej 03:13:44
我认为技术的使用非常节制。我不喜欢当它在很多方面妨碍了人类的方式。我喜欢的只是人们作为人类的方式，我们有点像稍微进化了，而且更喜欢我认为只是默认的方式。

Lex 03:13:56
人们一直在问我，因为他们知道你喜欢阅读，有没有一些你喜欢的特别的书，因为愚蠢或深刻的原因对你产生影响，你会推荐这些书。你提到了一个至关重要的问题

Andrej 03:14:12
当然有很多。我认为在生物学中是一个例子。重要的问题是一个好问题。尼克-莱恩的任何作品，真的呃，生命的升华，我想说的是像有点更潜在的代表性，就像他一直在谈论的很多事情的总结。我被《自私的基因》影响很深。我认为那是一本非常好的书，帮助我理解利他主义，作为一个例子，它来自哪里。只是意识到，你知道，选择是在牛仔裤的层面上，这对当时的我来说是一个巨大的洞察力，它有点像为我澄清了很多事情。

Lex 03:14:40
你怎么看待 "生物体的想法 "这一说法？

Andrej 03:14:45
喜欢它吗？100%.

Lex 03:14:48
是的。

Andrej 03:14:49
你能走吗？

Lex 03:14:50
围绕着这个概念有一段时间了，那就是思想也有一个进化的过程？

Andrej 03:14:57
绝对有。有像牛仔裤一样的备忘录，他们竞争，他们生活在我们的大脑里。这很美。

Lex 03:15:02
我们这些愚蠢的人类以为自己是生物体吗？有没有可能主要的生物体是思想？是的。

Andrej 03:15:11
我想说的是，这个想法是一种生活在像我们的文明的软件中的思想等等。

Lex 03:15:17
我们认为作为人类，硬件是最基本的东西，我人类是一个硬件实体。但它也可能是软件。

Andrej 03:15:26
对吗？是的。我想说的是，在某些时候需要有一些基础，就像一个物理现实。这

Lex 03:15:36
软件就是这个东西。比如说是这个东西，让那个东西变得很特别？对。

Andrej 03:15:41
是的，我想你是对的。

Lex 03:15:42
但这样一来，克隆可能就特别困难了。就像软件和硬件之间可能存在着我们不甚了解的深度整合。

Andrej 03:15:50
从海洋的角度来看。就像是什么让我变得特别，更像是写在我染色体上的那帮基因吧。对。就像它们是复制单位，我想。还有

Lex 03:15:59
不，但这只是使你特别的东西。当然，现实情况是，使你与众不同的是你的生存能力，是基于基因所构建的硬件上运行的软件。

Andrej 03:16:16
嗯，所以

Lex 03:16:17
软件才是让你生存的东西，而不是硬件。它是一个

Andrej 03:16:21
两者都有一点。你知道，这就像一个第二层。这是一个新的第二层，在大脑之前还没有出现过。它们都是，它们都共同存在。

Lex 03:16:27
但软件也有很多层。我的意思是，它是，它不是，它是一个如此抽象的，呃，在抽象之上的抽象、

Andrej 03:16:35
但如此自私的基因嗯，尼克-莱恩，我想说有时书本就像不够用。我有时喜欢伸手去拿教科书。嗯，我有点觉得书本有时是为了太多一般的消费，他们只是有点像在抽象的水平上太高了，而且不够好。所以我喜欢教科书。我喜欢细胞。我认为细胞是非常酷的。这也是为什么我喜欢尼克-莱恩的写作，因为他很愿意往下走一步，他不愿意、

Lex 03:17:06
呃，是的，他是

Andrej 03:17:07
他愿意去那里，但他也愿意在整个堆栈的排序，所以他会去到很多的细节。但是他又会回来，我认为他基本上有一个我非常欣赏的。这就是

Lex 03:17:18
为什么我喜欢大学，大学早期，甚至高中，只是计算机科学和数学，生物和化学的基础知识的教科书。这些都是他们浓缩的，就像呃，它足够普遍，你可以理解哲学和细节，但也像你得到的家庭作业问题，你可以像你不在的时候一样玩它，编程的东西。而且

Andrej 03:17:43
那么说实话，我也很怀疑教科书，因为以深度学习为例，没有像惊人的教科书，而且这个领域变化非常快。我想这也是事实。还有说呃合成生物学等等。这些书，比如说细胞有点过时了，还有高水平的，比如说实际真正的真理来源是人们在湿润的实验室里与细胞一起工作，你知道，对基因组进行测序，是的，实际工作中与它一起工作，呃我没有那么多接触，也不知道那是什么样子的。因此，我仍然没有完全，我正在阅读细胞，它有点有趣，我正在学习，但它仍然是不够的，我想说在理解什么方面

Lex 03:18:18
这是对主流叙述的简洁概括。是的。但你必须在打破之前学会这一点

安德烈 03:18:25
出

Lex 03:18:26
走向尖端。

Andrej 03:18:27
是的。与这些细胞打交道的实际过程是什么呢？你知道，这有点像一个大规模的烹饪食谱，确保自己的奴隶和增殖，然后你对它们进行测序，运行实验，只是如何工作。我认为这有点像真理的源泉，在一天结束时，什么是真正有用的创造疗法等方面。

Lex 03:18:45
是的，我想知道未来的ai教科书会是什么，因为你知道，有一个人工智能，一个现代的方法其实还没有看，如果它出了最近的版本。最近有一个新的版本。我还看到有一本深度学习的科学书。我在等那些值得推荐的值得看的教科书。

Andrej 03:19:02
它是

Lex 03:19:03
棘手，因为这就像论文和代码。代码代码。

Andrej 03:19:07
说实话，我觉得论文是相当好的，特别是像任何论文的附录附录也是如此。它就像你能看到的最详细的内容一样

Lex 03:19:14
有。它不一定要和其他东西连成一体。你只是描述了你看到的特定事物的一个非常具体的方式。是的。

Andrej 03:19:23
很多时候，论文实际上是很可读的。并非总是如此，但有时摘要中的介绍即使对该领域以外的人来说也是可读的，但这并不总是真的。有时我认为不幸的是，科学家使用复杂的术语，即使没有必要。我认为那是有害的？我认为没有理由

Lex 03:19:39
这一点。而论文有时在不重要的部分比它们需要的要长。是的，附录会很长。但是，论文本身，你知道，看看爱因斯坦，让它变得简单。是的、

安德烈 03:19:50
但我确实遇到过一些论文，我想说的是，比如合成生物学之类的论文，我认为其摘要和介绍是相当可读的，然后你在阅读其余部分时，你并不完全理解，但你能得到一个要点，我认为这很酷。

Lex 03:20:01
你给对机器学习和研究感兴趣的人的建议是什么，但在一般的生活中，对年轻人的建议，高中，大学早期，关于如何有一个他们可以自豪的事业或他们可以自豪的生活。

Andrej 03:20:19
是的，我想我很犹豫要不要给出一般的建议。我认为这真的很难。我已经提到了，比如我提到的一些东西是相当普遍的。我认为像，只关注你花在像一件事上的工作量，只和自己比较，不和自己比较

Lex 03:20:31
给别人。I

安德烈 03:20:32
我认为这些是相当普遍的。

Lex 03:20:33
你怎么挑选的东西、

Andrej 03:20:35
你只是对某件事情有浓厚的兴趣 呃，或者像尝试像找到艺术的最大限度，像你感兴趣的事情

Lex 03:20:42
在那一刻，艺术的最大限度，并坚持下去，你如何不分心，并切换到另一个东西

安德烈 03:20:48
你可以，如果你喜欢 嗯

Lex 03:20:51
如果你每周都重复做一个arg max、

Andrej 03:20:54
不收敛、

Lex 03:20:55
难道你不是

Andrej 03:20:57
可以像低通滤波器自己在像什么一直是你的真实？嗯，但是，是的，我肯定看到它可能很难，但我会说像你要在你最关心的事情上最努力地工作，所以低通滤波器自己，真的在你的过去自省，什么是给你能量的事情，什么是夺走你能量的事情？具体的例子，通常从这些具体的例子中，有时可以出现父母，我喜欢我喜欢事情看起来像这样的一个位置，所以

Lex 03:21:25
这不一定是这个领域，而是你在特定领域所做的那种事情。因此，对你来说，你似乎被实施的东西所激励，建立实际的东西。

Andrej 03:21:34
是的。作为低层次的学习，然后也呃沟通，让其他人能够经历同样的领悟，缩短这种差距，嗯，因为我通常要做太多的工作来理解这个东西，然后我就想，好吧，这实际上就像好吧，我想我得到了它，就像为什么它这么多

Lex 03:21:49
工作、

Andrej 03:21:50
它应该是更少的工作，这给了我很大的挫折感，这就是为什么我有时会去教书。

Lex 03:21:55
那么，除了你现在做的教学，把视频除了潜在的呃教父第二部分，呃将A.G.I.在特斯拉和超越。冷漠的未来是什么？你想明白了吗，还是？没有？我是说，当你看穿战争的迷雾时，那就是我们所有的未来。你，你是否开始看到那个可能的未来的轮廓？

Andrej 03:22:24
至少对我来说，我一直感兴趣的是人工智能，嗯，这可能是我余生要研究的东西，因为我只是非常关心它，实际上我也关心像其他许多问题，比如说衰老，我基本上把它看作是疾病，我也关心它。但我不认为专门去研究它是一个好主意。我实际上不认为人类能够想出答案。我认为正确的做法是忽略这些问题，你解决人工智能，然后用它来解决其他一切问题。而且我认为，这有可能会成功。我认为这是一个非常高的机会，呃，这有点像我的赌注方式。

Lex 03:23:01
至少。因此，当你考虑ai是否对各种应用、各种领域都感兴趣时，你所关注的任何领域都会让你获得洞察力到。一个人的大问题是

Andrej 03:23:13
对我来说是最终的精神问题。我不想在任何一个具体问题上下功夫。有太多的问题了。那么你怎么能同时解决所有的问题呢？你解决的是元问题，对我来说，这只是智力问题，你如何将其自动化？

Lex 03:23:25
是他们很酷的小项目，如档案馆的理智和等等，你在思考世界，毫升世界可以预见的。

Andrej 03:23:36
总有人喜欢一些有趣的副业。档案理智是一个基本上像有太多的档案文件。我怎么能组织它，并推荐论文等等。我转录了你所有的播客。

Lex 03:23:48
你从那段经历中学到了什么？呃，从转录像你这样的消费音频书籍和播客等的过程中。而这里有一个过程，实现了嗯更接近人类水平的表现和注释。

Andrej 03:24:02
是的，我肯定会惊讶地发现，与我熟悉的Siri和其他一些系统相比，Whisper工作得非常好，我想它工作得非常好。呃，这给了我一些能量去尝试它。我想这可能是有趣的随机播客。这对我来说有点不明显，为什么whisper与其他东西相比要好得多，因为我觉得应该有很多激励措施，让很多公司生产转录系统，而且他们已经做了很长时间了。Whisper不是一个超级奇特的模型。它是一个转化器，它采取融化频谱图，你知道，只是输出文本的标记，不是疯狂的呃模型，一切都已经存在了很长时间。我不是100%确定为什么。

Lex 03:24:43
这对我来说也不明显。这让我觉得我错过了什么。

Andrej 03:24:48
有事。是的、

Lex 03:24:49
因为有一个巨大的甚至是谷歌等在YouTube上的转录。是的，这不清楚，但有些也是整合到一个更大的系统，所以用户界面，如何部署和所有这些东西。也许作为一个独立的东西运行它要容易得多，就像一个数量级，比部署到一个大的综合系统，如Youtube转录或嗯任何像会议一样的东西，如zoom有反转录，这是一种蹩脚的。但是，创建界面，检测不同的个人发言者，它能够以引人注目的方式实时显示它，所有这些东西。也许这很难。但这是我唯一的解释，因为我目前为人类转录、人类字幕注释支付了相当多的费用，而且似乎有很大的动力来实现自动化，这非常令人困惑。

Andrej 03:25:48
我认为，我的意思是，我不知道你是否看了一些小道消息的记录，但它们是相当好的。他们很好、

Lex 03:25:53
特别是在棘手的情况下。我见过Uh whispers在超级棘手的案件上的表现，它做得非常好。所以我不知道，播客是很简单的。它就像高质量的音频，而且你通常讲得很清楚。所以我不知道，呃，我也不知道睁开眼睛的计划是什么、

Andrej 03:26:15
但基本上总是有一些有趣的、好玩的项目。稳定的扩散也在开辟大量的实验，我想说的是在视觉领域，生成图像和视频和电影。因此，这将是非常疯狂的。这将会，这将会几乎肯定会成功。当内容创作的成本将下降到零时，这将是非常有趣的。过去需要一个画家几个月来画一个东西，现在它将对着你的手机说话来获得你的视频。

Lex 03:26:43
好莱坞将开始使用这一点来生成场景Um，这就完全打开了。是的。因此，你可以用低于100万美元的价格制作一部像《阿凡达》这样的电影，多

Andrej 03:26:56
少。也许只是通过与你的电话交谈？我的意思是，我知道这听起来有点像

Lex 03:26:59
疯了，然后会有一些投票机制，比如你怎么会有，比如，netflix上会不会有一个完全自动生成的节目LEE。所以

Andrej 03:27:09
潜在的。是的。那它是什么样子的呢？另外，当你可以按需生成，而且是呃，有无限的

Lex 03:27:17
它。是的。哦，所有的合成内容。我的意思是，这很让人惭愧，因为我们把自己当成特殊的人，因为我们能够产生艺术和想法，以及所有这些东西，如果这些可以由Ai以自动化的方式完成。是的。

Andrej 03:27:34
我认为这对我来说很有吸引力，这些关于Ai的预测，以及它将会是什么样子，它将会有什么能力，都是完全颠倒和错误的，50年代和60年代的科幻作品就像是完全不对的。他们想象中的 "i "就像超级计算的改进者，而我们得到的东西可以与你谈论情感。他们可以做艺术。这就好像很奇怪。

Lex 03:27:53
你对这个未来感到兴奋吗？就像混合系统的眼睛，人类的异质系统。而Ai正在谈论情感。Netflix和儿童ai系统。这个词。你看的netflix的东西也是由ai产生的

Andrej 03:28:09
我认为这肯定会很有趣。我认为我是谨慎乐观的，但这并不明显。好吧

Lex 03:28:17
可悲的是，你的大脑和我的大脑是在twitter之前和互联网之前的时代发展的。所以我想知道那些出生在里面的人可能有不同的经历。嗯......就像我一样，也许你还能抵制。而现在出生的人则不会。

Andrej 03:28:38
嗯，我确实觉得人类的可塑性极强。

Lex 03:28:40
是的

Andrej 03:28:41
和

Lex 03:28:42
你可能是对的。生命的意义是什么，安德烈

安德烈 03:28:47
我们我们谈到了排序

Lex 03:28:49
的宇宙与我们人类进行对话，或者与我们创造的系统进行对话，试图为宇宙的创造者注意到我们而回答大学，我们试图创造的系统是允许的，足以。就要回答。

Andrej 03:29:07
我不知道这是否是生命的意义，这对一些人来说就像是生命的意义，我想说的第一层答案是任何人都可以选择自己的生命意义，因为我们是有意识的实体，这是美丽的第一。但我确实认为，如果有人感兴趣的话，生命的更深层意义是沿着这样的思路：这一切到底是什么？以及为什么？如果你看一下基础物理学和量子场理论和标准模型，它们就像非常复杂的，有这样一个你知道的，19个自由参数，我们宇宙的参数，就像所有这些东西是怎么回事，为什么在这里？我可以入侵它，我可以用它工作吗？是否有一个信息给我？我应该创造一个信息吗？所以我认为那里有一些基本的答案，但我认为实际上，如果没有更多的时间，你甚至不能真正在剂量上有所突破。所以对我来说，也有一个很大的问题，就是要诚实地获得更多的时间。是的，这也有点像我所想的那样，也有很多。

Lex 03:30:01
因此，最终或至少是第一种方式来潜入到为什么的问题是试图逃脱。呃，系统，宇宙，然后对于这一点，你有点回溯，说，好吧，对于这一点，这将是一个非常长的时间。因此，从工程的角度来看，白色问题可以归结为我们如何扩展？

Andrej 03:30:24
是的，我认为这是一个问题，第一，从实际情况来看，因为你不能，你不可能在你有的时间内计算出更深层次问题的答案，而且

Lex 03:30:32
这可能是延长你自己的寿命或延长人类文明的寿命

Andrej 03:30:37
的人愿意。没有多少人可能不希望如此，但我认为那些希望如此的人，我认为，我认为这可能是可行的。呃，我不认为，我不知道人们是否完全意识到这一点。我觉得人们认为死亡是不可避免的，但在一天结束时，这是一个物理系统，有些事情会出错。呃，从进化角度讲，这样的事情发生是有道理的。而且肯定会有干预措施来减轻它。

Lex 03:31:04
如果死亡最终被看成是过去发生在人类身上的一件迷人的事情，那就很有意思了。I

Andrej 03:31:12
我不认为这是不可能的。我认为是，我认为是可能的

Lex 03:31:16
而这取决于我们的想象力，试图预测没有死亡的世界是什么样子。我认为价值观会完全改变，这很难。

安德烈 03:31:28
是的，我不，我真的不相信所有这些想法，没有这些就没有意义，没有什么是我不，直觉上被所有这些论点。我认为有很多的意义，有很多的东西可以学习。它们很有趣，很令人兴奋。我想知道，我想计算，我想改善所有人类和生物体的生存状况。

Lex 03:31:49
我们寻找意义的方式可能会改变。有很多人类可能包括我自己，在事物的有限性中找到意义，但这并不意味着这是意义的唯一来源。

Andrej 03:32:00
是的，我确实认为很多人将会这样做，我认为这很好。我喜欢这个想法，人们可以直接选择自己的冒险。像你一样，你生来就是一个有意识的自由实体，是默认的。我喜欢这样想，而且你有你不可剥夺的生活权利

Lex 03:32:17
在追求幸福的过程中。

Andrej 03:32:18
我不知道

Lex 03:32:19
幸福的景象的本质和

Andrej 03:32:23
你可以选择你自己的冒险大部分。而这并不完全正确，但

Lex 03:32:27
我还是很确定我是一个NBC。但嗯，NBC不可能知道自己是NBC。可能有不同程度和层次的意识。我认为没有比这更美的方式了，Andre你是一个不可思议的人。我真的很荣幸。你会和我谈论你为机器学习世界为AI世界所做的一切

Andrej 03:32:49
给

Lex 03:32:50
只是启发人们教育数以百万计的人。这很好，我迫不及待地想看到你接下来做什么。这是我的荣幸，伙计。非常感谢你今天的谈话。

Andrej 03:32:58
谢谢你。

Lex 03:32:59
     
感谢收听与Andrej Karpathy的对话。为了支持这个播客。请在描述中查看我们的赞助商，现在让我把塞缪尔-卡林的一些话留给你。模型的目的不是为了适应数据，而是为了锐化问题。谢谢你的收听，希望下次再见。